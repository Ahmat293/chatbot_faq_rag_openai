{"cells":[{"cell_type":"code","source":["# Corrections"],"metadata":{"id":"jAVTCTNn22Xj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2.1 Word Embeding\n","\n","Les techniques de Word Embedding via le Deep Learning utilisent des réseaux de neurones pour générer des représentations vectorielles denses de mots à partir de grands corpus de textes.\n","\n","Ils apprennent à partir des co-occurrences de mots dans des contextes similaires pour créer des vecteurs qui capturent les relations sémantiques et syntaxiques entre les mots. Les modèles Word Embedding peuvent ensuite être utilisés pour résoudre diverses tâches de NLP, telles que la classification de texte, la traduction automatique, la génération de texte et l'analyse de sentiment.\n","\n","\n","<img src='https://www.nlplanet.org/course-practical-nlp/_images/word_embeddings.png' width=\"600\">\n","\n","\n","1. La couche Embedding va transformer chaque index de mots en vecteur d’embedding. La matrice de l’embedding sera apprise tout au long de l'entrainement du model. Les dimensions résultantes sont :\n","- batch-> Taille du lot,\n","- pad (ou sequence) -> longueur des document,\n","- embedding -> La longueur des vecteurs de mots.\n","\n","2. La couche embeding envoie les vecteurs ensuite au réseau de neurones afin de prédire une classe.\n","\n","3. Pour finir, la rétropropagation va mettre à jour les poids de la matrice d’embedding afin de maximiser la précision du modèle et créer des vecteurs d’embedding qui sont plus pertinents pour la tâche de classification."],"metadata":{"id":"Ij26avLJuaAP"}},{"cell_type":"code","source":["!python -m spacy download fr_core_news_md && pip install tensorflow"],"metadata":{"id":"1LWEb-VEuVJR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"066de493-ca28-423e-9e92-14e8f6bd037d","collapsed":true,"executionInfo":{"status":"ok","timestamp":1747396462432,"user_tz":-120,"elapsed":61135,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fr-core-news-md==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_md-3.8.0/fr_core_news_md-3.8.0-py3-none-any.whl (45.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: fr-core-news-md\n","Successfully installed fr-core-news-md-3.8.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('fr_core_news_md')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n","Collecting tensorflow\n","  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Collecting astunparse>=1.6.0 (from tensorflow)\n","  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n","Collecting flatbuffers>=24.3.25 (from tensorflow)\n","  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Collecting google-pasta>=0.1.1 (from tensorflow)\n","  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n","Collecting libclang>=13.0.0 (from tensorflow)\n","  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n","Collecting tensorboard~=2.19.0 (from tensorflow)\n","  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n","Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n","Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n","  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n","Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n","  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n","Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n","  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n","Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n","  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n","Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n","Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n","Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m117.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m115.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorflow-io-gcs-filesystem, tensorboard-data-server, google-pasta, tensorboard, astunparse, tensorflow\n","Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 google-pasta-0.2.0 libclang-18.1.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 werkzeug-3.1.3 wheel-0.45.1\n"]}]},{"cell_type":"code","source":["import spacy\n","# Create a Tokenizer with the default settings for English :\n","nlp = spacy.load(\"fr_core_news_md\")\n","# Exemple de texte\n","text = \"Machine learning is transforming industries.\"\n","\n","# Transformer le texte en un objet spaCy\n","doc = nlp(text)\n","list(doc)"],"metadata":{"id":"XiKKqNGKuVEV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747396469389,"user_tz":-120,"elapsed":6958,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}},"outputId":"12b99075-02c2-4e04-c2ac-60085d50c9a1"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Machine, learning, is, transforming, industries, .]"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["doc[0].vector"],"metadata":{"id":"fEt8ICOEuVBk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747396469397,"user_tz":-120,"elapsed":6,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}},"outputId":"edee75cb-2e66-4f26-9515-ca2a89e81f24"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 1.3070e+00,  7.4529e-02, -3.8663e-01,  3.0847e+00, -5.6217e-01,\n","        5.2215e-01, -1.2851e+00, -2.2116e+00, -3.4367e-01,  1.1250e+00,\n","       -2.0044e-01, -2.3004e+00, -1.9413e-01,  1.7198e+00, -1.6020e+00,\n","        1.3826e+00,  2.0348e-01, -1.9088e+00,  1.2299e+00,  1.4389e+00,\n","        2.1295e+00,  2.6553e+00,  1.1960e+00,  6.7653e-01, -1.7485e+00,\n","       -5.4685e-01, -1.8492e+00, -2.9083e-01,  8.6535e-02, -1.6107e+00,\n","        2.6295e+00, -2.0036e+00,  6.6789e-01, -3.9585e-01,  1.6796e+00,\n","       -3.7913e-01,  3.9507e-01, -1.0178e+00, -1.0168e+00,  1.5745e+00,\n","        9.8071e-02, -1.1518e+00,  1.8312e+00,  2.8515e-01,  1.2631e+00,\n","       -3.4645e-01, -7.6541e-02,  1.4363e+00,  1.9946e+00,  1.1709e+00,\n","        8.7533e-01, -5.9239e-01, -8.9845e-01, -1.0132e+00,  6.4800e-01,\n","       -1.6358e+00,  1.1647e+00,  5.4266e-01, -1.9492e+00,  3.3216e+00,\n","        9.5798e-01,  1.5116e-01, -1.4555e+00, -1.0148e+00, -7.2329e-01,\n","        1.5446e-01,  1.3199e+00,  1.0911e+00, -9.1015e-01,  2.0859e+00,\n","       -2.1891e+00,  6.9225e-01, -7.7934e-01,  2.4381e+00,  5.9412e-01,\n","       -1.0198e+00, -1.3312e+00, -8.8385e-01,  3.8088e-01, -3.2831e+00,\n","        9.5294e-02, -1.7584e-01,  5.5846e-01,  1.1393e+00, -2.5465e+00,\n","       -2.4744e-01,  1.3479e+00,  2.9996e-01,  5.6940e-02,  1.3247e+00,\n","       -2.5935e-01,  2.4861e-01, -1.5574e-01, -1.3507e-01, -1.4528e+00,\n","       -1.4491e+00, -6.0666e-01,  2.8879e+00,  2.3104e+00, -2.1437e+00,\n","       -2.4270e-02,  1.9252e-01,  5.5811e-01, -1.8451e+00, -1.7929e+00,\n","        2.1975e+00, -2.2332e-01,  1.8924e-01,  2.2097e-01, -3.4061e-01,\n","       -1.3936e+00,  1.0928e+00,  8.3103e-01,  3.4661e-01, -3.3050e-01,\n","        3.4364e-02, -7.6396e-01,  8.1223e-01, -9.2490e-01, -6.9373e-02,\n","        4.7295e-01, -1.6293e+00, -5.3096e-01,  1.6366e+00,  5.7592e-01,\n","        2.6352e+00,  1.5076e-01, -1.2438e+00,  1.9387e-01, -1.4493e+00,\n","       -1.0603e+00, -1.0868e+00,  7.5158e-01,  4.5983e-01, -4.7001e-01,\n","        3.7932e-01,  5.6634e-01,  7.5151e-01,  9.0739e-01, -2.7725e+00,\n","       -3.2450e+00, -1.0969e+00, -1.4756e+00,  4.3706e-01,  1.6098e+00,\n","       -2.0606e+00, -1.0664e+00, -4.1437e-01, -3.2413e+00, -1.0116e+00,\n","       -8.9766e-01,  8.6535e-01,  3.3973e+00, -3.6739e-01,  1.3901e+00,\n","        1.8243e+00,  7.1550e-03,  1.9477e+00,  1.6091e-01,  5.9768e-01,\n","        1.0681e+00,  6.4209e-01,  1.0146e+00, -3.3975e-01, -3.1698e+00,\n","        2.3104e+00,  1.2784e+00,  2.0686e-01,  1.1245e+00,  6.0480e-01,\n","        1.0985e+00, -2.5748e+00,  1.3038e+00, -2.8320e+00,  2.6724e-01,\n","        2.3464e+00,  1.0224e+00,  3.0945e-01, -4.9123e-01,  4.0193e-01,\n","       -1.5739e+00,  9.4966e-01, -8.4860e-01,  1.3425e+00,  1.4567e+00,\n","        2.8852e+00,  1.7049e+00,  9.7348e-03,  2.0407e-01,  4.5679e-01,\n","       -1.1618e+00,  8.3049e-01,  1.8314e+00,  2.0500e+00, -2.4690e+00,\n","        3.1303e+00,  2.9715e-01, -1.9568e+00,  4.0365e-01,  5.2678e-01,\n","        3.3736e+00, -6.3858e-01, -5.9932e-01,  4.7308e-01,  1.7051e+00,\n","       -5.0876e-01,  1.0956e-01,  3.0873e+00,  1.8013e+00, -8.1565e-01,\n","       -1.4016e+00,  4.9113e-01,  3.5510e-01, -2.6487e+00,  1.3142e+00,\n","        1.6594e+00, -8.5600e-01, -1.8549e-01, -1.1925e+00, -1.6425e+00,\n","        2.1135e+00, -3.2673e-01,  1.2950e+00,  7.7867e-01, -1.3352e+00,\n","        7.1862e-01,  1.2201e-01, -2.0454e+00,  7.7675e-01, -3.0466e-01,\n","        1.1744e+00, -1.3859e+00,  6.5562e-01, -1.1416e+00,  3.0789e-01,\n","        3.4968e+00, -1.7257e+00,  7.8789e-01, -9.1317e-01,  1.4533e-01,\n","       -1.6482e+00,  6.4063e-01,  4.0798e-01,  3.1169e+00, -6.1534e-01,\n","       -1.4013e-01, -1.7759e+00, -1.1787e+00,  1.2217e+00, -2.3650e-01,\n","       -1.7162e+00, -9.6483e-01, -1.4446e+00, -2.2158e+00,  1.0609e+00,\n","       -1.2929e-01, -5.4429e-01,  1.3366e+00,  9.4229e-01,  1.2748e+00,\n","       -1.1207e-01,  3.0073e-01, -1.5814e-02,  5.9478e-01,  1.8582e-01,\n","       -9.1214e-01,  6.5392e-01, -2.6240e+00,  1.6521e+00,  8.9432e-01,\n","        9.9979e-01,  2.3944e+00,  1.2798e+00,  1.1789e+00,  1.7330e+00,\n","        5.4727e-01, -6.8308e-01, -1.1479e+00, -1.5933e+00, -1.4902e+00,\n","       -7.1277e-01, -2.0476e-03,  4.4559e-01, -7.9063e-01,  8.5497e-01,\n","        7.6412e-01, -7.5211e-01,  2.9875e+00, -3.1197e+00,  8.0024e-01,\n","       -9.6650e-01,  1.6793e+00, -5.4493e-01, -1.6950e+00,  7.3249e-01,\n","       -2.0476e+00,  1.6181e+00, -4.5374e-01,  2.0904e+00, -4.1885e-01],\n","      dtype=float32)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["len(doc.vector)"],"metadata":{"id":"_sFnMcq2uU_5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747396469428,"user_tz":-120,"elapsed":30,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}},"outputId":"30bdb2ab-7f64-4786-dc54-36ad885d1daf"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["300"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["for token in doc:\n","    print(f\"{token.text} → {len(token.vector)} dimensions\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qQotSmSRXEf9","executionInfo":{"status":"ok","timestamp":1747396475170,"user_tz":-120,"elapsed":20,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}},"outputId":"73af18d1-bf36-4397-9d5b-5a7d53fc71de"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Machine → 300 dimensions\n","learning → 300 dimensions\n","is → 300 dimensions\n","transforming → 300 dimensions\n","industries → 300 dimensions\n",". → 300 dimensions\n"]}]},{"cell_type":"code","source":["print(nlp.pipe_names)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FW_4fUV3-LX_","executionInfo":{"status":"ok","timestamp":1747396476284,"user_tz":-120,"elapsed":15,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}},"outputId":"36e8d3db-ba89-41f1-a687-6d1992d5940f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["['tok2vec', 'morphologizer', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"]}]},{"cell_type":"code","source":["# Obtenir l'embedding d'un mot spécifique\n","word_embedding = doc[0].vector  # Embedding du mot \"Machine\"\n","\n","# Obtenir l'embedding moyen du texte entier (phrase embedding)\n","sentence_embedding = doc.vector\n","\n","# Afficher les dimensions et un aperçu des embeddings\n","print(\"Word Embedding du mot 'Machine' :\", word_embedding[:5])  # Afficher les 5 premières valeurs\n","print(\"Embedding de la phrase complète\", sentence_embedding[:5])  # Afficher les 5 premières valeurs\n","print(\"Embedding dimension:\", len(word_embedding))"],"metadata":{"id":"gvMFP86WuU-c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747396477240,"user_tz":-120,"elapsed":6,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}},"outputId":"1f4ffe9d-4e12-4def-e909-205a95fdf805"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Word Embedding du mot 'Machine' : [ 1.307     0.074529 -0.38663   3.0847   -0.56217 ]\n","Embedding de la phrase complète [-0.01232834  0.15979314 -0.15142666  0.85388    -2.0837533 ]\n","Embedding dimension: 300\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding\n","\n","max_features = 15       # Taille du vocabulaire\n","embedding_dim = 128     # Taille des ebedding\n","maxlen = 100            # Longueure max des textes\n","\n","model = Sequential([Embedding(input_dim=max_features, output_dim=embedding_dim, input_length=maxlen)])"],"metadata":{"id":"_FJUQpvOu0p8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747396496881,"user_tz":-120,"elapsed":17550,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}},"outputId":"4331b74d-fe3c-4cf3-ee3b-c75493459e27"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","metadata":{"id":"JUzLeezUw81b"},"source":["# **2.2 - Recurrent Neural Networks (RNN)**\n","\n","Les **Recurrent Neural Networks (RNN)** sont une classe de réseaux de neurones artificiels conçus pour traiter des **données séquentielles**. Contrairement aux réseaux de neurones traditionnels (perceptrons multicouches, CNN), les RNN possèdent des **connexions récurrentes**, leur permettant de conserver une **mémoire des informations précédentes** et de capturer des relations temporelles.  \n","\n","Ils sont largement utilisés dans des tâches impliquant du texte, de l’audio ou des séries temporelles, telles que :\n","- **Classification de texte** (analyse de sentiments, détection de spam),\n","- **Traduction automatique** (ex : Google Translate),\n","- **Reconnaissance vocale** (ex : Siri, Alexa),\n","- **Génération de texte** (ex : ChatGPT, GPT-4).\n","\n","---\n","\n","## 🔎 **1. Différence entre un réseau classique et un RNN**  \n","\n","### 🏛 Réseau de Neurones Classique (MLP)\n","Un **Multi-Layer Perceptron (MLP)** traite **chaque entrée indépendamment**, sans prendre en compte la notion de séquence. Cela le rend inefficace pour analyser du texte ou de l’audio.\n","\n","<img src='https://quera.fr/wp-content/uploads/2023/12/RNN_representation.png' width=100>\n","\n","---\n","\n","### 🔄 Réseau de Neurones Récurrent (RNN)\n","Un **RNN** introduit une **connexion récurrente** : l’état caché précédent est réutilisé pour influer sur la sortie actuelle. Cela permet de capturer des dépendances temporelles dans les données.\n","\n","<img src='https://quera.fr/wp-content/uploads/2023/12/RNN_types.png' width=600>\n","\n","---\n","\n","## ⚠ **2. Limites des RNN**\n","Bien que puissants, les RNN classiques souffrent de **deux problèmes majeurs** :\n","1. **Disparition ou explosion du gradient** lors de l'entraînement (rendant l’apprentissage instable).\n","2. **Difficulté à capturer des dépendances longues** dans les séquences.\n","\n","👉 Pour pallier ces limites, des variantes comme **LSTM** (Long Short-Term Memory) et **GRU** (Gated Recurrent Unit) ont été développées.\n","\n","---\n","\n","\n","## 📚 **3. Ressources complémentaires**\n","- 📖 [Introduction aux RNN](https://datascientest.com/recurrent-neural-network)\n","- 📖 [Comprendre LSTM & GRU](https://penseeartificielle.fr/comprendre-lstm-gru-fonctionnement-schema/)\n","- 🎥 [Vidéo explicative sur les RNN](https://www.youtube.com/watch?v=3xgYxrNyE54)\n","\n","---"]},{"cell_type":"code","source":["pip install tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"YR9rCjeQnZqJ","executionInfo":{"status":"ok","timestamp":1747396634583,"user_tz":-120,"elapsed":1411,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}},"outputId":"1403da48-fa28-4ecc-99a6-db87ef4f6ed1"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n","Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n","Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"]}]},{"cell_type":"code","source":["!python -m spacy download fr_core_news_sm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nDPzYR9J0lhv","outputId":"05801c62-0717-47ec-9a81-8964201f802f","executionInfo":{"status":"ok","timestamp":1747396643418,"user_tz":-120,"elapsed":4920,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}},"collapsed":true},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fr-core-news-sm==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m118.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: fr-core-news-sm\n","Successfully installed fr-core-news-sm-3.8.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('fr_core_news_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"code","source":["import requests\n","import spacy\n","\n","nlp = spacy.load('fr_core_news_sm')\n","\n","url = \"https://raw.githubusercontent.com/Quera-fr/YOLO-DATASET/refs/heads/main/corpus.txt\"\n","\n","# Récupération du contenu\n","text = requests.get(url).text.lower()\n","\n","\n","# Création du corpus d'entrainement\n","docs = [list(nlp(doc)) for doc in text.replace('  ', '').split('\\n')]\n","docs"],"metadata":{"id":"glZ79iDy0jZz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747396657623,"user_tz":-120,"elapsed":3723,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}},"outputId":"080792cf-6c55-441b-84f6-2a9c553a397b","collapsed":true},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[bonjour, comment, vas, tu, aujourd’hui],\n"," [merci, pour, ton, aide, précieuse, je, suis, reconnaissant],\n"," [nous, allons, au, marché, acheter, des, légumes, frais],\n"," [elle,\n","  cuisine,\n","  un,\n","  gâteau,\n","  au,\n","  chocolat,\n","  pour,\n","  l’,\n","  anniversaire,\n","  de,\n","  sa,\n","  sœur],\n"," [le, chat, dort, sur, le, canapé, en, ronronnant, doucement],\n"," [il, travaille, sur, un, projet, important, pour, son, entreprise],\n"," [nous, regardons, le, coucher, de, soleil, depuis, la, terrasse],\n"," [tu, lis, un, livre, passionnant, sur, l’, histoire, ancienne],\n"," [ils, jouent, au, football, dans, le, parc, avec, leurs, amis],\n"," [j’, écris, une, lettre, à, mon, correspondant, étranger],\n"," [la, voiture, roule, rapidement, sur, l’, autoroute],\n"," [le, vent, souffle, fort, dans, les, arbres, en, automne],\n"," [nous, avons, visité, un, musée, d’, art, moderne, hier],\n"," [elle, danse, gracieusement, sur, la, scène, du, théâtre],\n"," [tu, écoutes, de, la, musique, classique, pour, te, détendre],\n"," [ils,\n","  voyagent,\n","  souvent,\n","  à,\n","  l’,\n","  étranger,\n","  pour,\n","  découvrir,\n","  de,\n","  nouvelles,\n","  cultures],\n"," [je, prépare, un, café, chaud, pour, bien, commencer, la, journée],\n"," [le, bébé, dort, paisiblement, dans, son, berceau],\n"," [nous, faisons, du, vélo, le, long, de, la, rivière],\n"," [elle, chante, une, chanson, douce, pour, endormir, son, enfant],\n"," [tu, as, acheté, du, pain, à, la, boulangerie, ce, matin],\n"," [il, dessine, un, paysage, magnifique, avec, des, crayons, de, couleur],\n"," [nous, apprendrons, une, nouvelle, langue, ensemble, l’, année, prochaine],\n"," [elle, jouait, du, piano, chaque, soir, avant, d’, aller, se, coucher],\n"," [tu, courras, un, marathon, le, mois, prochain],\n"," [ils, regardaient, les, étoiles, dans, le, ciel, dégagé, hier, soir],\n"," [je, construirai, une, maison, en, bois, au, bord, du, lac],\n"," [le, professeur, explique, la, leçon, avec, patience, et, clarté],\n"," [nous,\n","  écoutions,\n","  attentivement,\n","  l’,\n","  histoire,\n","  racontée,\n","  par,\n","  notre,\n","  grand-mère],\n"," [elle, peindra, une, fresque, murale, dans, son, atelier],\n"," [tu, écrivais, toujours, des, poèmes, quand, tu, étais, enfant],\n"," [ils, partiront, en, voyage, après, leurs, examens],\n"," [je, faisais, souvent, du, camping, en, été, avec, mes, cousins],\n"," [le, facteur, apportera, une, lettre, demain, matin],\n"," [nous, avions, une, discussion, intéressante, sur, la, philosophie],\n"," [elle, visitera, paris, pendant, les, vacances],\n"," [tu, avais, déjà, goûté, ce, plat, avant, aujourd’hui],\n"," [ils, marcheront, sur, la, plage, au, coucher, du, soleil],\n"," [j’, avais, oublié, mon, parapluie, à, la, maison],\n"," [le, chien, jouera, dans, le, jardin, toute, la, journée],\n"," [nous, apprendrons, les, règles, de, grammaire, en, cours],\n"," [elle, finissait, son, dessin, lorsqu’, on, l’, a, appelée],\n"," [tu, regarderas, ce, film, avec, nous, demain, soir],\n"," [ils, réparaient, la, voiture, quand, la, pluie, a, commencé],\n"," [je, nagerai, dans, la, piscine, pendant, les, vacances],\n"," [le, vent, soufflait, fort, hier, soir, pendant, l’, orage],\n"," [nous, avions, toujours, rêvé, de, faire, le, tour, du, monde],\n"," [elle, changera, de, travail, à, la, fin, du, mois],\n"," [tu, lisais, un, livre, quand, le, téléphone, a, sonné],\n"," [ils, apprendront, à, programmer, en, python, cette, année],\n"," [je, cuisinerai, un, plat, traditionnel, pour, mes, amis],\n"," [le, médecin, examinait, le, patient, avec, attention],\n"," [nous, verrons, un, feu, d’, artifice, à, la, fête, nationale],\n"," [elle, posait, une, question, difficile, à, son, professeur],\n"," [tu, écriras, une, dissertation, sur, ce, sujet, demain],\n"," [ils, travaillaient, tard, pour, terminer, leur, projet],\n"," [je, prendrai, un, avion, pour, londres, la, semaine, prochaine],\n"," [le, soleil, brillait, fort, cet, après-midi],\n"," [nous, apprendrons, à, jouer, d’, un, instrument, de, musique],\n"," [elle, chantait, dans, la, chorale, de, l’, école],\n"," [tu, mangeras, des, fruits, après, le, repas],\n"," [ils, attendaient, le, bus, sous, la, pluie],\n"," [je, visiterai, un, château, médiéval, pendant, les, vacances],\n"," [le, chat, sautait, sur, la, table, pour, attraper, la, nourriture],\n"," [nous, jouerons, aux, échecs, ce, week, -, end],\n"," [elle, voyageait, souvent, en, train, pour, aller, voir, ses, parents],\n"," [tu, écouteras, la, radio, pendant, que, tu, cuisines],\n"," [ils, construiront, une, bibliothèque, pour, la, ville],\n"," [je, réparais, mon, vélo, quand, tu, es, arrivé],\n"," [le, vent, apportera, de, la, fraîcheur, cet, été],\n"," [nous, marcherons, ensemble, dans, la, forêt],\n"," [elle, tricotait, une, écharpe, pour, son, frère],\n"," [tu, regarderas, les, étoiles, avec, un, télescope],\n"," [ils, planteront, des, arbres, dans, le, parc, municipal],\n"," [je, m’, endormais, souvent, en, écoutant, de, la, musique],\n"," [le, professeur, enseignera, une, nouvelle, leçon, demain],\n"," [nous, lirons, un, roman, captivant, en, classe],\n"," [elle, s’, habillait, élégamment, pour, la, soirée],\n"," [tu, apprendras, à, conduire, dès, que, tu, auras, l’, âge],\n"," [ils, couraient, dans, le, stade, lors, de, l’, entraînement],\n"," [je, chanterai, à, la, fête, de, l’, école],\n"," [le, chien, aboyait, quand, quelqu’, un, approchait, de, la, maison],\n"," [nous, danserons, toute, la, nuit, lors, du, mariage],\n"," [elle, jouait, de, la, guitare, dans, un, groupe, de, musique],\n"," [tu, parleras, anglais, couramment, après, plusieurs, années, de, pratique],\n"," [ils, écrivaient, des, lettres, à, leurs, amis, lointains],\n"," [je, pêcherai, dans, la, rivière, pendant, l’, été],\n"," [le, soleil, se, couchait, lentement, derrière, les, montagnes],\n"," [nous, apprendrons, les, bases, de, la, photographie, en, cours],\n"," [elle, dessinait, des, portraits, de, ses, amis],\n"," [tu, fabriqueras, un, cerf, -, volant, avec, du, papier, coloré],\n"," [ils, décoraient, la, maison, pour, noël],\n"," [je, regarderai, un, documentaire, sur, la, nature, ce, soir],\n"," [le, vent, soufflait, en, rafales, près, de, la, côte],\n"," [nous, ramasserons, des, coquillages, sur, la, plage],\n"," [elle, récita, un, poème, devant, toute, la, classe],\n"," [tu, comprendras, mieux, cette, leçon, après, la, révision],\n"," [ils, aideront, à, la, construction, d’, une, école, en, afrique],\n"," [je, voyagerai, à, travers, l’, europe, en, train],\n"," [le, chat, chassait, une, souris, dans, le, jardin],\n"," [nous, apprendrons, la, couture, avec, notre, grand-mère],\n"," [elle, expliquait, le, problème, en, détail],\n"," [tu, reconnaîtras, cette, mélodie, immédiatement],\n"," [ils, peignaient, les, murs, de, leur, nouvelle, maison],\n"," [je, porterai, un, manteau, chaud, en, hiver],\n"," [le, facteur, livrait, le, courrier, chaque, matin],\n"," [nous, écouterons, un, concert, en, plein, air],\n"," [elle, racontait, une, histoire, drôle, pour, détendre, l’, atmosphère],\n"," [tu, choisiras, un, livre, dans, la, bibliothèque],\n"," [ils, nageaient, dans, la, mer, sous, un, beau, soleil],\n"," [je, visiterai, le, musée, d’, art, contemporain, demain],\n"," [le, vent, balayait, les, feuilles, mortes, sur, la, route],\n"," [nous, apprendrons, à, jouer, au, tennis, cet, été],\n"," [elle, décorait, le, gâteau, avec, de, la, crème, chantilly],\n"," [tu, rencontreras, de, nouvelles, personnes, à, cette, conférence],\n"," [ils, chantaient, en, chœur, lors, du, festival],\n"," [je, me, promènerai, au, bord, du, fleuve, au, printemps],\n"," [le, boulanger, préparait, du, pain, frais, chaque, matin],\n"," [nous, regarderons, un, film, en, famille, dimanche, soir],\n"," [elle, admirait, les, étoiles, dans, le, ciel, dégagé],\n"," [tu, apprendras, à, danser, avec, un, professeur],\n"," [ils, escaladeront, une, montagne, en, été],\n"," [je, planterai, des, fleurs, dans, mon, jardin, au, printemps],\n"," [le, cuisinier, préparait, un, repas, gastronomique, pour, ses, invités],\n"," [nous, aiderons, nos, voisins, à, déménager],\n"," [elle, cousait, une, robe, pour, l’, été],\n"," [tu, apprécieras, ce, spectacle, de, danse, traditionnelle],\n"," [ils, observeront, les, oiseaux, avec, des, jumelles],\n"," [je, construirai, un, meuble, en, bois, avec, mon, père],\n"," [le, peintre, ajoutait, les, dernières, touches, à, son, tableau],\n"," [nous, visiterons, un, zoo, pour, voir, les, animaux, sauvages],\n"," [je, comprends, parfaitement, cette, situation, et, j’, y, réfléchis, encore],\n"," [comprends,\n","  -,\n","  tu,\n","  ce,\n","  que,\n","  je,\n","  veux,\n","  dire,\n","  ou,\n","  dois,\n","  -je,\n","  reformuler,\n","  ma,\n","  pensée],\n"," [ne, comprenais, -, tu, pas, déjà, cette, règle, avant, d’, arriver, ici],\n"," [nous, devons, apprendre, à, écouter, les, autres, avec, attention],\n"," [devrons,\n","  -nous,\n","  vraiment,\n","  suivre,\n","  cette,\n","  règle,\n","  ou,\n","  pourrons,\n","  -nous,\n","  l’,\n","  adapter],\n"," [ne, devions, -nous, pas, être, déjà, partis, avant, que, la, nuit, tombe],\n"," [elle, cherche, une, solution, efficace, pour, résoudre, ce, problème],\n"," [cherchera,\n","  -t,\n","  -elle,\n","  un,\n","  nouveau,\n","  travail,\n","  après,\n","  avoir,\n","  terminé,\n","  ses,\n","  études],\n"," [n’,\n","  aurait,\n","  -elle,\n","  pas,\n","  déjà,\n","  trouvé,\n","  un,\n","  emploi,\n","  si,\n","  elle,\n","  avait,\n","  mieux,\n","  préparé,\n","  son,\n","  entretien],\n"," [tu, vois, le, soleil, qui, se, lève, derrière, les, montagnes],\n"," [verrais,\n","  -,\n","  tu,\n","  cette,\n","  scène,\n","  différemment,\n","  si,\n","  tu,\n","  connaissais,\n","  toute,\n","  l’,\n","  histoire],\n"," [ne,\n","  voyais,\n","  -,\n","  tu,\n","  pas,\n","  déjà,\n","  les,\n","  signes,\n","  avant,\n","  qu’,\n","  ils,\n","  ne,\n","  deviennent,\n","  évidents],\n"," [il, construit, un, abri, pour, protéger, ses, animaux, du, froid],\n"," [construira, -t, -il, une, nouvelle, maison, ou, rénovera, -t, -il, celle-ci],\n"," [ne,\n","  construisait,\n","  -il,\n","  pas,\n","  déjà,\n","  quelque,\n","  chose,\n","  d’,\n","  autre,\n","  avant,\n","  ce,\n","  projet],\n"," [nous, espérons, un, avenir, meilleur, pour, tous, les, peuples, du, monde],\n"," [espérez, -vous, vraiment, que, cette, situation, s’, améliore, rapidement],\n"," [n’,\n","  espériez,\n","  -vous,\n","  pas,\n","  secrètement,\n","  un,\n","  autre,\n","  résultat,\n","  de,\n","  cette,\n","  expérience],\n"," [ils,\n","  courent,\n","  chaque,\n","  matin,\n","  pour,\n","  garder,\n","  la,\n","  forme,\n","  et,\n","  rester,\n","  en,\n","  bonne,\n","  santé],\n"," [courront, -ils, encore, l’, hiver, prochain, malgré, le, froid, glacial],\n"," [ne,\n","  couraient,\n","  -ils,\n","  pas,\n","  plus,\n","  souvent,\n","  avant,\n","  que,\n","  leur,\n","  emploi,\n","  du,\n","  temps,\n","  ne,\n","  change],\n"," [je, chante, dans, une, chorale, tous, les, dimanches, avec, enthousiasme],\n"," [chanteras,\n","  -,\n","  tu,\n","  devant,\n","  tout,\n","  le,\n","  public,\n","  lors,\n","  du,\n","  spectacle,\n","  de,\n","  fin,\n","  d’,\n","  année],\n"," [ne,\n","  chantais,\n","  -,\n","  tu,\n","  pas,\n","  déjà,\n","  cette,\n","  chanson,\n","  lorsque,\n","  nous,\n","  étions,\n","  enfants],\n"," [tu, choisis, toujours, les, meilleures, destinations, pour, voyager],\n"," [choisirais, -, tu, une, autre, option, si, celle-ci, ne, fonctionnait, pas],\n"," [ne,\n","  choisissais,\n","  -,\n","  tu,\n","  pas,\n","  systématiquement,\n","  les,\n","  mêmes,\n","  couleurs,\n","  auparavant],\n"," [elle, écrit, une, lettre, à, son, ami, parti, vivre, à, l’, étranger],\n"," [écrira,\n","  -t,\n","  -elle,\n","  un,\n","  livre,\n","  un,\n","  jour,\n","  pour,\n","  raconter,\n","  son,\n","  incroyable,\n","  aventure],\n"," [n’,\n","  écrivait,\n","  -elle,\n","  pas,\n","  déjà,\n","  de,\n","  petites,\n","  histoires,\n","  dans,\n","  son,\n","  journal,\n","  intime],\n"," [nous, voyons, les, étoiles, briller, dans, le, ciel, dégagé, cette, nuit],\n"," [verrons, -nous, un, jour, une, autre, planète, habitable, dans, l’, univers],\n"," [ne,\n","  voyions,\n","  -nous,\n","  pas,\n","  déjà,\n","  les,\n","  premiers,\n","  indices,\n","  de,\n","  cette,\n","  découverte],\n"," [ils,\n","  prennent,\n","  des,\n","  décisions,\n","  importantes,\n","  pour,\n","  leur,\n","  entreprise,\n","  chaque,\n","  jour],\n"," [prendront,\n","  -ils,\n","  en,\n","  compte,\n","  toutes,\n","  les,\n","  suggestions,\n","  des,\n","  employés,\n","  avant,\n","  de,\n","  trancher],\n"," [ne,\n","  prenaient,\n","  -ils,\n","  pas,\n","  déjà,\n","  ces,\n","  précautions,\n","  avant,\n","  l’,\n","  arrivée,\n","  du,\n","  problème],\n"," [je, travaille, avec, passion, sur, chaque, projet, que, j’, entreprends],\n"," [travailleras, -, tu, avec, moi, sur, ce, nouveau, projet, ambitieux],\n"," [ne, travaillais, -, tu, pas, déjà, sur, un, sujet, similaire, auparavant],\n"," [tu, aides, souvent, tes, amis, lorsqu’, ils, ont, besoin, de, toi],\n"," [aideras, -, tu, ton, voisin, à, déménager, ce, week, -, end],\n"," [n’, aidais, -, tu, pas, déjà, quelqu’, un, d’, autre, avant, de, venir, ici],\n"," [elle, apprend, de, nouvelles, compétences, pour, évoluer, dans, son, métier],\n"," [apprendra,\n","  -t,\n","  -elle,\n","  plus,\n","  vite,\n","  si,\n","  elle,\n","  suit,\n","  des,\n","  cours,\n","  supplémentaires],\n"," [n’, apprenait, -elle, pas, déjà, cette, langue, avant, de, déménager],\n"," [nous,\n","  comprenons,\n","  mieux,\n","  cette,\n","  problématique,\n","  après,\n","  plusieurs,\n","  explications],\n"," [comprendrons, -nous, un, jour, tous, les, mystères, de, l’, univers],\n"," [ne,\n","  comprenions,\n","  -nous,\n","  pas,\n","  déjà,\n","  ce,\n","  concept,\n","  avant,\n","  qu’,\n","  il,\n","  ne,\n","  soit,\n","  expliqué],\n"," [ils,\n","  découvrent,\n","  de,\n","  nouvelles,\n","  cultures,\n","  en,\n","  voyageant,\n","  à,\n","  travers,\n","  le,\n","  monde],\n"," [découvriront, -ils, bientôt, une, île, encore, inconnue],\n"," [ne,\n","  découvraient,\n","  -ils,\n","  pas,\n","  déjà,\n","  des,\n","  indices,\n","  sur,\n","  ce,\n","  phénomène,\n","  il,\n","  y,\n","  a,\n","  des,\n","  années],\n"," [je, cherche, constamment, des, solutions, aux, défis, que, je, rencontre],\n"," [chercheras, -, tu, une, nouvelle, opportunité, professionnelle, bientôt],\n"," [ne,\n","  cherchais,\n","  -,\n","  tu,\n","  pas,\n","  déjà,\n","  une,\n","  alternative,\n","  avant,\n","  de,\n","  choisir,\n","  cette,\n","  option],\n"," [tu, bois, toujours, un, café, avant, de, commencer, ta, journée],\n"," [boiras, -, tu, du, thé, à, la, place, si, je, t’, en, prépare, un],\n"," [ne,\n","  buvais,\n","  -,\n","  tu,\n","  pas,\n","  plutôt,\n","  du,\n","  chocolat,\n","  chaud,\n","  quand,\n","  nous,\n","  étions,\n","  enfants],\n"," [elle, ouvre, la, porte, pour, laisser, entrer, la, lumière, du, jour],\n"," [ouvrira, -t, -elle, son, propre, commerce, un, jour],\n"," [n’, ouvrait, -elle, pas, toujours, la, fenêtre, chaque, matin, auparavant],\n"," [nous,\n","  écrivons,\n","  ensemble,\n","  une,\n","  histoire,\n","  pleine,\n","  d’,\n","  aventures,\n","  et,\n","  de,\n","  rebondissements],\n"," [écrirons,\n","  -nous,\n","  un,\n","  jour,\n","  un,\n","  livre,\n","  qui,\n","  inspirera,\n","  des,\n","  milliers,\n","  de,\n","  lecteurs],\n"," [n’, écrivions, -nous, pas, déjà, un, projet, similaire, l’, an, dernier],\n"," [ils,\n","  parlent,\n","  plusieurs,\n","  langues,\n","  et,\n","  communiquent,\n","  aisément,\n","  avec,\n","  les,\n","  étrangers],\n"," [parleront, -ils, bientôt, une, nouvelle, langue, pour, leur, travail],\n"," [ne,\n","  parlaient,\n","  -ils,\n","  pas,\n","  déjà,\n","  couramment,\n","  espagnol,\n","  avant,\n","  d’,\n","  apprendre,\n","  l’,\n","  italien],\n"," [je,\n","  ressens,\n","  une,\n","  grande,\n","  joie,\n","  à,\n","  l’,\n","  idée,\n","  de,\n","  revoir,\n","  mes,\n","  amis,\n","  après,\n","  tant,\n","  d’,\n","  années],\n"," [ressentiras,\n","  -,\n","  tu,\n","  la,\n","  même,\n","  émotion,\n","  lorsque,\n","  tu,\n","  retrouveras,\n","  ta,\n","  famille],\n"," [ne,\n","  ressentais,\n","  -,\n","  tu,\n","  pas,\n","  déjà,\n","  cette,\n","  excitation,\n","  avant,\n","  même,\n","  d’,\n","  acheter,\n","  ton,\n","  billet],\n"," [tu, oublies, souvent, où, tu, as, mis, tes, affaires],\n"," [oublieras, -, tu, encore, ton, sac, demain, matin],\n"," [n’, oubliais, -, tu, pas, déjà, tes, clés, chaque, semaine, auparavant],\n"," [elle, voyage, souvent, pour, découvrir, de, nouveaux, paysages],\n"," [voyagera, -t, -elle, un, jour, dans, l’, espace],\n"," [ne, voyageait, -elle, pas, déjà, souvent, avant, de, s’, installer, ici],\n"," [nous,\n","  changeons,\n","  nos,\n","  habitudes,\n","  pour,\n","  adopter,\n","  un,\n","  mode,\n","  de,\n","  vie,\n","  plus,\n","  sain],\n"," [changerons, -nous, un, jour, totalement, notre, manière, de, consommer],\n"," [ne,\n","  changions,\n","  -nous,\n","  pas,\n","  déjà,\n","  progressivement,\n","  avant,\n","  cette,\n","  prise,\n","  de,\n","  conscience],\n"," [ils, regardent, les, nuages, défiler, dans, le, ciel, avec, émerveillement],\n"," [regarderont, -ils, un, film, ce, soir, ensemble],\n"," [ne, regardaient, -ils, pas, déjà, cette, série, la, semaine, dernière],\n"," [je, construis, un, projet, ambitieux, avec, mon, équipe],\n"," [construiras, -, tu, un, jour, la, maison, de, tes, rêves],\n"," [ne,\n","  construisais,\n","  -,\n","  tu,\n","  pas,\n","  déjà,\n","  un,\n","  plan,\n","  avant,\n","  de,\n","  commencer,\n","  ce,\n","  chantier],\n"," [tu, fermes, toujours, la, porte, à, clé, avant, de, partir],\n"," [fermerez, -vous, la, boutique, plus, tôt, aujourd’hui],\n"," [ne,\n","  fermaient,\n","  -ils,\n","  pas,\n","  déjà,\n","  la,\n","  fenêtre,\n","  avant,\n","  que,\n","  la,\n","  pluie,\n","  ne,\n","  commence],\n"," [elle, prépare, un, repas, délicieux, pour, toute, sa, famille],\n"," [préparera, -t, -elle, un, festin, pour, les, fêtes, de, fin, d’, année],\n"," [ne, préparait, -elle, pas, déjà, ce, plat, la, semaine, dernière],\n"," [nous, progressons, chaque, jour, en, apprenant, de, nos, erreurs],\n"," [progresserons, -nous, plus, rapidement, avec, une, meilleure, organisation],\n"," [ne,\n","  progressions,\n","  -nous,\n","  pas,\n","  déjà,\n","  avant,\n","  de,\n","  suivre,\n","  cette,\n","  nouvelle,\n","  méthode],\n"," [ils, écoutent, attentivement, chaque, mot, du, discours],\n"," [écouteront, -ils, avec, autant, d’, attention, la, prochaine, fois],\n"," [n’,\n","  écoutaient,\n","  -ils,\n","  pas,\n","  déjà,\n","  les,\n","  conseils,\n","  avant,\n","  de,\n","  prendre,\n","  cette,\n","  décision],\n"," [je, vis, chaque, instant, avec, intensité, et, passion],\n"," [verras, -, tu, la, beauté, de, la, vie, dans, chaque, détail],\n"," [ne,\n","  voyais,\n","  -,\n","  tu,\n","  pas,\n","  déjà,\n","  cette,\n","  vérité,\n","  avant,\n","  qu’,\n","  on,\n","  te,\n","  l’,\n","  explique],\n"," [tu, t’, amuses, toujours, en, jouant, avec, tes, amis],\n"," [t’, amuseras, -, tu, autant, la, prochaine, fois],\n"," [ne, t’, amusais, -, tu, pas, déjà, avant, même, que, la, fête, commence],\n"," [elle, éclaire, la, pièce, en, allumant, une, bougie],\n"," [éclairera, -t, -elle, notre, chemin, avec, sa, lampe, torche],\n"," [n’,\n","  éclairait,\n","  -elle,\n","  pas,\n","  déjà,\n","  la,\n","  salle,\n","  avant,\n","  que,\n","  l’,\n","  électricité,\n","  ne,\n","  revienne],\n"," [nous, explorons, chaque, recoin, de, cette, île, mystérieuse],\n"," [explorerons, -nous, bientôt, un, nouveau, territoire, inconnu],\n"," [ne,\n","  explorions,\n","  -nous,\n","  pas,\n","  déjà,\n","  ce,\n","  concept,\n","  avant,\n","  que,\n","  cette,\n","  découverte,\n","  ne,\n","  soit,\n","  faite],\n"," [bonjour, comment, allez, vous],\n"," [bonsoir, j’, espère, que, vous, passez, une, bonne, soirée],\n"," [salut, comment, se, passe, votre, journée],\n"," [enchanté, de, faire, votre, connaissance],\n"," [bienvenue, chez, nous, installez, vous, confortablement],\n"," [je, vous, remercie, infiniment, pour, votre, aide, précieuse],\n"," [merci, beaucoup, pour, votre, gentillesse, et, votre, soutien],\n"," [je, tiens, à, exprimer, toute, ma, gratitude, pour, votre, générosité],\n"," [avec, tous, mes, remerciements, pour, votre, patience],\n"," [je, vous, suis, reconnaissant, pour, tout, ce, que, vous, avez, fait],\n"," [pardonnez, moi, je, ne, voulais, pas, vous, déranger],\n"," [excusez, moi, pour, mon, retard, j’, ai, été, retenu],\n"," [je, suis, désolé, si, mes, propos, vous, ont, offensé],\n"," [veuillez, m’, excuser, pour, cette, erreur],\n"," [je, vous, prie, d’, accepter, mes, plus, sincères, excuses],\n"," [je, vous, souhaite, une, excellente, journée],\n"," [passez, une, agréable, soirée],\n"," [bonne, nuit, reposez, vous, bien],\n"," [bon, appétit, profitez, de, votre, repas],\n"," [bonne, chance, pour, votre, entretien, je, crois, en, vous],\n"," [tous, mes, vœux, de, bonheur, et, de, réussite, pour, votre, avenir],\n"," [j’, espère, que, tout, se, passera, bien, pour, vous],\n"," [je, vous, adresse, mes, plus, sincères, félicitations],\n"," [bravo, pour, votre, succès, vous, l’, avez, bien, mérité],\n"," [félicitations, pour, cette, belle, performance],\n"," [je, suis, heureux, pour, vous, c’, est, une, belle, réussite],\n"," [toutes, mes, félicitations, pour, cette, excellente, nouvelle],\n"," [je, vous, présente, mes, condoléances, en, ces, moments, difficiles],\n"," [je, suis, de, tout, cœur, avec, vous, dans, cette, épreuve],\n"," [toutes, mes, pensées, vont, vers, vous, et, votre, famille],\n"," [je, partage, votre, douleur, et, vous, envoie, tout, mon, soutien],\n"," [prenez, soin, de, vous, et, de, vos, proches],\n"," [si,\n","  je,\n","  peux,\n","  faire,\n","  quoi,\n","  que,\n","  ce,\n","  soit,\n","  pour,\n","  vous,\n","  aider,\n","  faites,\n","  le,\n","  moi,\n","  savoir],\n"," [puis, je, vous, aider, d’, une, quelconque, manière],\n"," [n’, hésitez, pas, à, me, solliciter, en, cas, de, besoin],\n"," [si, vous, avez, la, moindre, question, je, reste, disponible],\n"," [serait, il, possible, d’, avoir, un, renseignement],\n"," [pourriez, vous, me, donner, plus, de, détails, sur, ce, sujet],\n"," [j’, aimerais, prendre, rendez, vous, à, votre, convenance],\n"," [auriez, vous, la, gentillesse, de, me, transmettre, ces, informations],\n"," [puis, je, vous, emprunter, un, stylo, s’, il, vous, plaît],\n"," [je, vous, en, prie, faites, comme, chez, vous],\n"," [après, vous, je, vous, laisse, passer, en, premier],\n"," [ce, fut, un, plaisir, de, discuter, avec, vous],\n"," [je, vous, remercie, de, votre, attention],\n"," [je, vous, souhaite, une, bonne, continuation],\n"," [prenez, soin, de, vous, et, à, bientôt],\n"," [à, très, bientôt, j’, espère],\n"," [au, revoir, et, à, la, prochaine],\n"," [je, vous, souhaite, une, belle, et, agréable, journée],\n"," [passez, un, excellent, week, end],\n"," [que, cette, journée, vous, apporte, beaucoup, de, joie],\n"," [j’, espère, que, vous, avez, passé, une, bonne, nuit],\n"," [comment, puis, je, vous, aider, aujourd’hui],\n"," [que, puis, je, faire, pour, vous],\n"," [puis, je, vous, offrir, un, café, ou, un, thé],\n"," [voulez, vous, que, je, vous, accompagne],\n"," [souhaitez, vous, un, renseignement, particulier],\n"," [c’, est, avec, plaisir, que, je, vous, rends, service],\n"," [je, suis, ravi, de, pouvoir, vous, aider],\n"," [je, vous, écoute, dites, moi, en, quoi, je, peux, être, utile],\n"," [je, suis, à, votre, disposition, pour, toute, demande],\n"," [je, vous, assure, que, je, ferai, de, mon, mieux, pour, vous, satisfaire],\n"," [vous, pouvez, compter, sur, moi, pour, vous, assister],\n"," [je, reste, à, votre, disposition, pour, toute, autre, question],\n"," [ne, vous, inquiétez, pas, tout, va, bien, se, passer],\n"," [je, vous, souhaite, beaucoup, de, courage, pour, cette, épreuve],\n"," [gardez,\n","  confiance,\n","  en,\n","  vous,\n","  vous,\n","  avez,\n","  toutes,\n","  les,\n","  capacités,\n","  pour,\n","  réussir],\n"," [chaque, effort, que, vous, faites, vous, rapproche, de, votre, objectif],\n"," [n’,\n","  abandonnez,\n","  jamais,\n","  chaque,\n","  difficulté,\n","  est,\n","  une,\n","  opportunité,\n","  d’,\n","  apprendre],\n"," [je, crois, en, vous, continuez, sur, cette, voie],\n"," [restez, positif, et, ne, baissez, pas, les, bras],\n"," [ne, vous, découragez, pas, tout, finit, par, s’, arranger],\n"," [tout, problème, a, une, solution, il, suffit, de, la, chercher],\n"," [vous, faites, du, très, bon, travail, continuez, ainsi],\n"," [vous, avez, énormément, progressé, félicitations],\n"," [vous,\n","  méritez,\n","  cette,\n","  réussite,\n","  vous,\n","  avez,\n","  travaillé,\n","  dur,\n","  pour,\n","  y,\n","  arriver],\n"," [je, suis, impressionné, par, votre, talent, et, votre, détermination],\n"," [ce, que, vous, faites, est, remarquable, continuez, ainsi],\n"," [vous, pouvez, être, fier, de, vous, votre, succès, est, mérité],\n"," [prenez, soin, de, votre, santé, c’, est, ce, qui, compte, le, plus],\n"," [n’, oubliez, pas, de, prendre, du, temps, pour, vous],\n"," [accordez, vous, du, repos, vous, en, avez, bien, besoin],\n"," [respirez, profondément, et, détendez, vous, tout, ira, bien],\n"," [restez, serein, et, gérez, la, situation, avec, calme],\n"," [il, n’, y, a, pas, de, problème, que, du, positif, à, tirer],\n"," [tout, arrive, pour, une, raison, gardez, confiance, en, l’, avenir],\n"," [chaque, jour, est, une, nouvelle, opportunité, de, progresser],\n"," [le, succès, est, une, question, de, persévérance, et, de, travail],\n"," [vous, êtes, une, source, d’, inspiration, pour, ceux, qui, vous, entourent],\n"," [votre, gentillesse, et, votre, bienveillance, font, la, différence],\n"," [merci, pour, votre, patience, et, votre, compréhension],\n"," [je, suis, touché, par, votre, générosité, et, votre, soutien],\n"," [je, tiens, à, vous, exprimer, toute, ma, reconnaissance],\n"," [merci, infiniment, pour, le, temps, que, vous, m’, avez, accordé],\n"," [j’, apprécie, énormément, votre, aide, précieuse],\n"," [votre, aide, m’, a, été, d’, un, grand, secours, encore, merci],\n"," [avec, toute, ma, gratitude, pour, votre, bienveillance],\n"," [vous, êtes, une, personne, formidable, merci, d’, être, là],\n"," [je, suis, ravi, d’, avoir, pu, vous, aider],\n"," [ce, fut, un, plaisir, de, travailler, avec, vous],\n"," [j’, ai, appris, beaucoup, grâce, à, vous, merci, pour, tout],\n"," [nos, échanges, ont, été, très, enrichissants, merci],\n"," [je, vous, souhaite, tout, le, succès, que, vous, méritez],\n"," [que, votre, avenir, soit, rempli, de, bonheur, et, de, prospérité],\n"," [je, vous, envoie, mes, meilleures, pensées, et, encouragements],\n"," [soyez, heureux, et, épanoui, chaque, jour],\n"," [vivez, pleinement, chaque, instant, et, profitez, de, la, vie],\n"," [que, cette, nouvelle, aventure, vous, apporte, de, belles, expériences],\n"," [je, vous, souhaite, tout, le, meilleur, pour, vos, projets, futurs],\n"," [j’, espère, que, nous, aurons, bientôt, l’, occasion, de, nous, revoir],\n"," [n’,\n","  hésitez,\n","  pas,\n","  à,\n","  me,\n","  contacter,\n","  si,\n","  vous,\n","  avez,\n","  besoin,\n","  de,\n","  quoi,\n","  que,\n","  ce,\n","  soit],\n"," [j’, espère, que, nous, pourrons, travailler, ensemble, à, nouveau],\n"," [j’, ai, été, ravi, de, vous, rencontrer, et, d’, échanger, avec, vous],\n"," [je, vous, souhaite, un, excellent, voyage, profitez, bien],\n"," [reposez, vous, bien, et, prenez, du, temps, pour, vous],\n"," [je, vous, souhaite, un, prompt, rétablissement, prenez, soin, de, vous],\n"," [si, vous, avez, besoin, de, quoi, que, ce, soit, je, suis, là],\n"," [restez, en, contact, et, donnez, moi, de, vos, nouvelles],\n"," [je, vous, envoie, toute, mon, énergie, positive],\n"," [je, vous, souhaite, une, merveilleuse, journée, remplie, de, bonheur],\n"," [à, très, vite, et, prenez, bien, soin, de, vous]]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# Création du vocabulaire\n","vocabulaire = sorted(set([token.text for token in nlp(text.replace('\\n', ' ').replace('  ', ''))]))\n","\n","# Création des tokens\n","tokens = [[list(vocabulaire).index(token.text) +1 for token in doc] for doc in docs]\n","\n","len(vocabulaire)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1luOK0EwzL5b","outputId":"38579e75-6135-4793-e69a-2c437ce178ce","executionInfo":{"status":"ok","timestamp":1747396672651,"user_tz":-120,"elapsed":348,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}}},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1079"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["vocabulaire"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vG3lbhp3_bl9","executionInfo":{"status":"ok","timestamp":1747396674107,"user_tz":-120,"elapsed":23,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}},"outputId":"855931e4-6464-4b0b-a3f6-180bd6833b8c","collapsed":true},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['-',\n"," '-elle',\n"," '-il',\n"," '-ils',\n"," '-je',\n"," '-nous',\n"," '-t',\n"," '-vous',\n"," 'a',\n"," 'abandonnez',\n"," 'aboyait',\n"," 'abri',\n"," 'accepter',\n"," 'accompagne',\n"," 'accordez',\n"," 'accordé',\n"," 'acheter',\n"," 'acheté',\n"," 'adapter',\n"," 'admirait',\n"," 'adopter',\n"," 'adresse',\n"," 'affaires',\n"," 'afrique',\n"," 'agréable',\n"," 'ai',\n"," 'aidais',\n"," 'aide',\n"," 'aider',\n"," 'aideras',\n"," 'aiderons',\n"," 'aideront',\n"," 'aides',\n"," 'aimerais',\n"," 'ainsi',\n"," 'air',\n"," 'aisément',\n"," 'ajoutait',\n"," 'aller',\n"," 'allez',\n"," 'allons',\n"," 'allumant',\n"," 'alternative',\n"," 'ambitieux',\n"," 'ami',\n"," 'amis',\n"," 'amusais',\n"," 'amuseras',\n"," 'amuses',\n"," 'améliore',\n"," 'an',\n"," 'ancienne',\n"," 'anglais',\n"," 'animaux',\n"," 'anniversaire',\n"," 'année',\n"," 'années',\n"," 'appelée',\n"," 'apporte',\n"," 'apportera',\n"," 'apprenait',\n"," 'apprenant',\n"," 'apprend',\n"," 'apprendra',\n"," 'apprendras',\n"," 'apprendre',\n"," 'apprendrons',\n"," 'apprendront',\n"," 'appris',\n"," 'approchait',\n"," 'apprécie',\n"," 'apprécieras',\n"," 'appétit',\n"," 'après',\n"," 'après-midi',\n"," 'arbres',\n"," 'arranger',\n"," 'arrive',\n"," 'arriver',\n"," 'arrivé',\n"," 'arrivée',\n"," 'art',\n"," 'artifice',\n"," 'as',\n"," 'assister',\n"," 'assure',\n"," 'atelier',\n"," 'atmosphère',\n"," 'attendaient',\n"," 'attention',\n"," 'attentivement',\n"," 'attraper',\n"," 'au',\n"," 'aujourd’hui',\n"," 'auparavant',\n"," 'aurait',\n"," 'auras',\n"," 'auriez',\n"," 'aurons',\n"," 'autant',\n"," 'automne',\n"," 'autoroute',\n"," 'autre',\n"," 'autres',\n"," 'aux',\n"," 'avais',\n"," 'avait',\n"," 'avant',\n"," 'avec',\n"," 'avenir',\n"," 'aventure',\n"," 'aventures',\n"," 'avez',\n"," 'avion',\n"," 'avions',\n"," 'avoir',\n"," 'avons',\n"," 'baissez',\n"," 'balayait',\n"," 'bases',\n"," 'beau',\n"," 'beaucoup',\n"," 'beauté',\n"," 'belle',\n"," 'belles',\n"," 'berceau',\n"," 'besoin',\n"," 'bibliothèque',\n"," 'bien',\n"," 'bientôt',\n"," 'bienveillance',\n"," 'bienvenue',\n"," 'billet',\n"," 'boiras',\n"," 'bois',\n"," 'bon',\n"," 'bonheur',\n"," 'bonjour',\n"," 'bonne',\n"," 'bonsoir',\n"," 'bord',\n"," 'bougie',\n"," 'boulanger',\n"," 'boulangerie',\n"," 'boutique',\n"," 'bras',\n"," 'bravo',\n"," 'brillait',\n"," 'briller',\n"," 'bus',\n"," 'buvais',\n"," 'bébé',\n"," 'café',\n"," 'calme',\n"," 'camping',\n"," 'canapé',\n"," 'capacités',\n"," 'captivant',\n"," 'cas',\n"," 'ce',\n"," 'celle-ci',\n"," 'cerf',\n"," 'ces',\n"," 'cet',\n"," 'cette',\n"," 'ceux',\n"," 'chance',\n"," 'change',\n"," 'changeons',\n"," 'changera',\n"," 'changerons',\n"," 'changions',\n"," 'chanson',\n"," 'chantaient',\n"," 'chantais',\n"," 'chantait',\n"," 'chante',\n"," 'chanterai',\n"," 'chanteras',\n"," 'chantier',\n"," 'chantilly',\n"," 'chaque',\n"," 'chassait',\n"," 'chat',\n"," 'chaud',\n"," 'chemin',\n"," 'cherchais',\n"," 'cherche',\n"," 'chercher',\n"," 'cherchera',\n"," 'chercheras',\n"," 'chez',\n"," 'chien',\n"," 'chocolat',\n"," 'choisir',\n"," 'choisirais',\n"," 'choisiras',\n"," 'choisis',\n"," 'choisissais',\n"," 'chorale',\n"," 'chose',\n"," 'château',\n"," 'chœur',\n"," 'ciel',\n"," 'clarté',\n"," 'classe',\n"," 'classique',\n"," 'clé',\n"," 'clés',\n"," 'coloré',\n"," 'comme',\n"," 'commence',\n"," 'commencer',\n"," 'commencé',\n"," 'comment',\n"," 'commerce',\n"," 'communiquent',\n"," 'comprenais',\n"," 'comprendras',\n"," 'comprendrons',\n"," 'comprends',\n"," 'comprenions',\n"," 'comprenons',\n"," 'compréhension',\n"," 'compte',\n"," 'compter',\n"," 'compétences',\n"," 'concept',\n"," 'concert',\n"," 'condoléances',\n"," 'conduire',\n"," 'confiance',\n"," 'confortablement',\n"," 'conférence',\n"," 'connaissais',\n"," 'connaissance',\n"," 'conscience',\n"," 'conseils',\n"," 'consommer',\n"," 'constamment',\n"," 'construction',\n"," 'construira',\n"," 'construirai',\n"," 'construiras',\n"," 'construiront',\n"," 'construis',\n"," 'construisais',\n"," 'construisait',\n"," 'construit',\n"," 'contact',\n"," 'contacter',\n"," 'contemporain',\n"," 'continuation',\n"," 'continuez',\n"," 'convenance',\n"," 'coquillages',\n"," 'correspondant',\n"," 'couchait',\n"," 'coucher',\n"," 'couleur',\n"," 'couleurs',\n"," 'courage',\n"," 'couraient',\n"," 'couramment',\n"," 'courent',\n"," 'courras',\n"," 'courrier',\n"," 'courront',\n"," 'cours',\n"," 'cousait',\n"," 'cousins',\n"," 'couture',\n"," 'crayons',\n"," 'crois',\n"," 'crème',\n"," 'cuisine',\n"," 'cuisinerai',\n"," 'cuisines',\n"," 'cuisinier',\n"," 'cultures',\n"," 'côte',\n"," 'cœur',\n"," 'c’',\n"," 'dans',\n"," 'danse',\n"," 'danser',\n"," 'danserons',\n"," 'de',\n"," 'demain',\n"," 'demande',\n"," 'depuis',\n"," 'dernier',\n"," 'dernière',\n"," 'dernières',\n"," 'derrière',\n"," 'des',\n"," 'dessin',\n"," 'dessinait',\n"," 'dessine',\n"," 'destinations',\n"," 'devant',\n"," 'deviennent',\n"," 'devions',\n"," 'devons',\n"," 'devrons',\n"," 'difficile',\n"," 'difficiles',\n"," 'difficulté',\n"," 'différemment',\n"," 'différence',\n"," 'dimanche',\n"," 'dimanches',\n"," 'dire',\n"," 'discours',\n"," 'discussion',\n"," 'discuter',\n"," 'disponible',\n"," 'disposition',\n"," 'dissertation',\n"," 'dites',\n"," 'documentaire',\n"," 'dois',\n"," 'donner',\n"," 'donnez',\n"," 'dort',\n"," 'douce',\n"," 'doucement',\n"," 'douleur',\n"," 'drôle',\n"," 'du',\n"," 'dur',\n"," 'dès',\n"," 'décision',\n"," 'décisions',\n"," 'décoraient',\n"," 'décorait',\n"," 'découragez',\n"," 'découverte',\n"," 'découvraient',\n"," 'découvrent',\n"," 'découvrir',\n"," 'découvriront',\n"," 'défiler',\n"," 'défis',\n"," 'dégagé',\n"," 'déjà',\n"," 'délicieux',\n"," 'déménager',\n"," 'déranger',\n"," 'désolé',\n"," 'détail',\n"," 'détails',\n"," 'détendez',\n"," 'détendre',\n"," 'détermination',\n"," 'd’',\n"," 'efficace',\n"," 'effort',\n"," 'elle',\n"," 'emploi',\n"," 'employés',\n"," 'emprunter',\n"," 'en',\n"," 'enchanté',\n"," 'encore',\n"," 'encouragements',\n"," 'end',\n"," 'endormais',\n"," 'endormir',\n"," 'enfant',\n"," 'enfants',\n"," 'enrichissants',\n"," 'enseignera',\n"," 'ensemble',\n"," 'enthousiasme',\n"," 'entourent',\n"," 'entraînement',\n"," 'entreprends',\n"," 'entreprise',\n"," 'entrer',\n"," 'entretien',\n"," 'envoie',\n"," 'erreur',\n"," 'erreurs',\n"," 'es',\n"," 'escaladeront',\n"," 'espace',\n"," 'espagnol',\n"," 'espère',\n"," 'espérez',\n"," 'espériez',\n"," 'espérons',\n"," 'est',\n"," 'et',\n"," 'europe',\n"," 'examens',\n"," 'examinait',\n"," 'excellent',\n"," 'excellente',\n"," 'excitation',\n"," 'excuser',\n"," 'excuses',\n"," 'excusez',\n"," 'explications',\n"," 'expliquait',\n"," 'explique',\n"," 'expliqué',\n"," 'explorerons',\n"," 'explorions',\n"," 'explorons',\n"," 'exprimer',\n"," 'expérience',\n"," 'expériences',\n"," 'fabriqueras',\n"," 'facteur',\n"," 'faire',\n"," 'faisais',\n"," 'faisons',\n"," 'fait',\n"," 'faite',\n"," 'faites',\n"," 'famille',\n"," 'fenêtre',\n"," 'ferai',\n"," 'fermaient',\n"," 'fermerez',\n"," 'fermes',\n"," 'festin',\n"," 'festival',\n"," 'feu',\n"," 'feuilles',\n"," 'fier',\n"," 'film',\n"," 'fin',\n"," 'finissait',\n"," 'finit',\n"," 'fleurs',\n"," 'fleuve',\n"," 'fois',\n"," 'fonctionnait',\n"," 'font',\n"," 'football',\n"," 'forme',\n"," 'formidable',\n"," 'fort',\n"," 'forêt',\n"," 'frais',\n"," 'fraîcheur',\n"," 'fresque',\n"," 'froid',\n"," 'fruits',\n"," 'frère',\n"," 'fut',\n"," 'futurs',\n"," 'félicitations',\n"," 'fête',\n"," 'fêtes',\n"," 'garder',\n"," 'gardez',\n"," 'gastronomique',\n"," 'gentillesse',\n"," 'glacial',\n"," 'goûté',\n"," 'gracieusement',\n"," 'grammaire',\n"," 'grand',\n"," 'grand-mère',\n"," 'grande',\n"," 'gratitude',\n"," 'groupe',\n"," 'grâce',\n"," 'guitare',\n"," 'gâteau',\n"," 'générosité',\n"," 'gérez',\n"," 'habillait',\n"," 'habitable',\n"," 'habitudes',\n"," 'heureux',\n"," 'hier',\n"," 'histoire',\n"," 'histoires',\n"," 'hiver',\n"," 'hésitez',\n"," 'ici',\n"," 'idée',\n"," 'il',\n"," 'ils',\n"," 'immédiatement',\n"," 'important',\n"," 'importantes',\n"," 'impressionné',\n"," 'inconnu',\n"," 'inconnue',\n"," 'incroyable',\n"," 'indices',\n"," 'infiniment',\n"," 'informations',\n"," 'inquiétez',\n"," 'inspiration',\n"," 'inspirera',\n"," 'installer',\n"," 'installez',\n"," 'instant',\n"," 'instrument',\n"," 'intensité',\n"," 'intime',\n"," 'intéressante',\n"," 'invités',\n"," 'ira',\n"," 'italien',\n"," 'jamais',\n"," 'jardin',\n"," 'je',\n"," 'joie',\n"," 'jouait',\n"," 'jouant',\n"," 'jouent',\n"," 'jouer',\n"," 'jouera',\n"," 'jouerons',\n"," 'jour',\n"," 'journal',\n"," 'journée',\n"," 'jumelles',\n"," 'j’',\n"," 'la',\n"," 'lac',\n"," 'laisse',\n"," 'laisser',\n"," 'lampe',\n"," 'langue',\n"," 'langues',\n"," 'le',\n"," 'lecteurs',\n"," 'lentement',\n"," 'les',\n"," 'lettre',\n"," 'lettres',\n"," 'leur',\n"," 'leurs',\n"," 'leçon',\n"," 'lirons',\n"," 'lis',\n"," 'lisais',\n"," 'livrait',\n"," 'livre',\n"," 'lointains',\n"," 'londres',\n"," 'long',\n"," 'lors',\n"," 'lorsque',\n"," 'lorsqu’',\n"," 'lumière',\n"," 'là',\n"," 'lève',\n"," 'légumes',\n"," 'l’',\n"," 'ma',\n"," 'magnifique',\n"," 'maison',\n"," 'malgré',\n"," 'mangeras',\n"," 'manière',\n"," 'manteau',\n"," 'marathon',\n"," 'marcherons',\n"," 'marcheront',\n"," 'marché',\n"," 'mariage',\n"," 'matin',\n"," 'me',\n"," 'meilleur',\n"," 'meilleure',\n"," 'meilleures',\n"," 'mer',\n"," 'merci',\n"," 'merveilleuse',\n"," 'mes',\n"," 'meuble',\n"," 'mieux',\n"," 'milliers',\n"," 'mis',\n"," 'mode',\n"," 'moderne',\n"," 'moi',\n"," 'moindre',\n"," 'mois',\n"," 'moments',\n"," 'mon',\n"," 'monde',\n"," 'montagne',\n"," 'montagnes',\n"," 'mortes',\n"," 'mot',\n"," 'municipal',\n"," 'murale',\n"," 'murs',\n"," 'musique',\n"," 'musée',\n"," 'mystères',\n"," 'mystérieuse',\n"," 'médecin',\n"," 'médiéval',\n"," 'mélodie',\n"," 'méritez',\n"," 'mérité',\n"," 'méthode',\n"," 'métier',\n"," 'même',\n"," 'mêmes',\n"," 'm’',\n"," 'nageaient',\n"," 'nagerai',\n"," 'nationale',\n"," 'nature',\n"," 'ne',\n"," 'nos',\n"," 'notre',\n"," 'nourriture',\n"," 'nous',\n"," 'nouveau',\n"," 'nouveaux',\n"," 'nouvelle',\n"," 'nouvelles',\n"," 'noël',\n"," 'nuages',\n"," 'nuit',\n"," 'n’',\n"," 'objectif',\n"," 'observeront',\n"," 'occasion',\n"," 'offensé',\n"," 'offrir',\n"," 'oiseaux',\n"," 'on',\n"," 'ont',\n"," 'opportunité',\n"," 'option',\n"," 'orage',\n"," 'organisation',\n"," 'ou',\n"," 'oubliais',\n"," 'oublieras',\n"," 'oublies',\n"," 'oubliez',\n"," 'oublié',\n"," 'ouvrait',\n"," 'ouvre',\n"," 'ouvrira',\n"," 'où',\n"," 'pain',\n"," 'paisiblement',\n"," 'papier',\n"," 'par',\n"," 'parapluie',\n"," 'parc',\n"," 'pardonnez',\n"," 'parents',\n"," 'parfaitement',\n"," 'paris',\n"," 'parlaient',\n"," 'parlent',\n"," 'parleras',\n"," 'parleront',\n"," 'partage',\n"," 'parti',\n"," 'particulier',\n"," 'partir',\n"," 'partiront',\n"," 'partis',\n"," 'pas',\n"," 'passe',\n"," 'passer',\n"," 'passera',\n"," 'passez',\n"," 'passion',\n"," 'passionnant',\n"," 'passé',\n"," 'patience',\n"," 'patient',\n"," 'paysage',\n"," 'paysages',\n"," 'peignaient',\n"," 'peindra',\n"," 'peintre',\n"," 'pendant',\n"," 'pensée',\n"," 'pensées',\n"," 'performance',\n"," 'personne',\n"," 'personnes',\n"," 'persévérance',\n"," 'petites',\n"," 'peuples',\n"," 'peux',\n"," 'philosophie',\n"," 'photographie',\n"," 'phénomène',\n"," 'piano',\n"," 'piscine',\n"," 'pièce',\n"," 'place',\n"," 'plage',\n"," 'plaisir',\n"," 'plan',\n"," 'planterai',\n"," 'planteront',\n"," 'planète',\n"," 'plat',\n"," 'plaît',\n"," 'plein',\n"," 'pleine',\n"," 'pleinement',\n"," 'pluie',\n"," 'plus',\n"," 'plusieurs',\n"," 'plutôt',\n"," 'porte',\n"," 'porterai',\n"," 'portraits',\n"," 'posait',\n"," 'positif',\n"," 'positive',\n"," 'possible',\n"," 'pour',\n"," 'pourriez',\n"," 'pourrons',\n"," 'pouvez',\n"," 'pouvoir',\n"," 'poème',\n"," 'poèmes',\n"," 'pratique',\n"," 'premier',\n"," 'premiers',\n"," 'prenaient',\n"," 'prendrai',\n"," 'prendre',\n"," 'prendront',\n"," 'prenez',\n"," 'prennent',\n"," 'prie',\n"," 'printemps',\n"," 'prise',\n"," 'problème',\n"," 'problématique',\n"," 'prochain',\n"," 'prochaine',\n"," 'proches',\n"," 'professeur',\n"," 'professionnelle',\n"," 'profitez',\n"," 'profondément',\n"," 'programmer',\n"," 'progresser',\n"," 'progresserons',\n"," 'progressions',\n"," 'progressivement',\n"," 'progressons',\n"," 'progressé',\n"," 'projet',\n"," 'projets',\n"," 'prompt',\n"," 'promènerai',\n"," 'propos',\n"," 'propre',\n"," 'prospérité',\n"," 'protéger',\n"," 'près',\n"," 'précautions',\n"," 'précieuse',\n"," 'préparait',\n"," 'prépare',\n"," 'préparera',\n"," 'préparé',\n"," 'présente',\n"," 'pu',\n"," 'public',\n"," 'puis',\n"," 'python',\n"," 'père',\n"," 'pêcherai',\n"," 'quand',\n"," 'que',\n"," 'quelconque',\n"," 'quelque',\n"," 'quelqu’',\n"," 'question',\n"," 'qui',\n"," 'quoi',\n"," 'qu’',\n"," 'racontait',\n"," 'raconter',\n"," 'racontée',\n"," 'radio',\n"," 'rafales',\n"," 'raison',\n"," 'ramasserons',\n"," 'rapidement',\n"," 'rapproche',\n"," 'ravi',\n"," 'rebondissements',\n"," 'recoin',\n"," 'reconnaissance',\n"," 'reconnaissant',\n"," 'reconnaîtras',\n"," 'reformuler',\n"," 'regardaient',\n"," 'regardent',\n"," 'regarderai',\n"," 'regarderas',\n"," 'regarderons',\n"," 'regarderont',\n"," 'regardons',\n"," 'remarquable',\n"," 'remercie',\n"," 'remerciements',\n"," 'rempli',\n"," 'remplie',\n"," 'rencontre',\n"," 'rencontrer',\n"," 'rencontreras',\n"," 'rendez',\n"," 'rends',\n"," 'renseignement',\n"," 'repas',\n"," 'repos',\n"," 'reposez',\n"," 'respirez',\n"," 'ressens',\n"," 'ressentais',\n"," 'ressentiras',\n"," 'reste',\n"," 'rester',\n"," 'restez',\n"," 'retard',\n"," 'retenu',\n"," 'retrouveras',\n"," 'revienne',\n"," 'revoir',\n"," 'rivière',\n"," 'robe',\n"," 'roman',\n"," 'ronronnant',\n"," 'roule',\n"," 'route',\n"," 'règle',\n"," 'règles',\n"," 'récita',\n"," 'réfléchis',\n"," 'rénovera',\n"," 'réparaient',\n"," 'réparais',\n"," 'résoudre',\n"," 'résultat',\n"," 'rétablissement',\n"," 'réussir',\n"," 'réussite',\n"," 'révision',\n"," 'rêves',\n"," 'rêvé',\n"," 'sa',\n"," 'sac',\n"," 'sain',\n"," 'salle',\n"," 'salut',\n"," 'santé',\n"," 'satisfaire',\n"," 'sautait',\n"," 'sauvages',\n"," 'savoir',\n"," 'scène',\n"," 'se',\n"," 'secours',\n"," 'secrètement',\n"," 'semaine',\n"," 'serait',\n"," 'serein',\n"," 'service',\n"," 'ses',\n"," 'si',\n"," 'signes',\n"," 'similaire',\n"," 'sincères',\n"," 'situation',\n"," 'soin',\n"," 'soir',\n"," 'soirée',\n"," 'soit',\n"," 'soleil',\n"," 'solliciter',\n"," 'solution',\n"," 'solutions',\n"," 'son',\n"," 'sonné',\n"," 'soufflait',\n"," 'souffle',\n"," 'souhaite',\n"," 'souhaitez',\n"," 'source',\n"," 'souris',\n"," 'sous',\n"," 'soutien',\n"," 'souvent',\n"," 'soyez',\n"," 'spectacle',\n"," 'stade',\n"," 'stylo',\n"," 'succès',\n"," 'suffit',\n"," 'suggestions',\n"," 'suis',\n"," 'suit',\n"," 'suivre',\n"," 'sujet',\n"," 'supplémentaires',\n"," 'sur',\n"," 'systématiquement',\n"," 'série',\n"," 'sœur',\n"," 's’',\n"," 'ta',\n"," 'table',\n"," 'tableau',\n"," 'talent',\n"," 'tant',\n"," 'tard',\n"," 'te',\n"," 'temps',\n"," 'tennis',\n"," 'terminer',\n"," 'terminé',\n"," 'terrasse',\n"," 'territoire',\n"," 'tes',\n"," 'thé',\n"," 'théâtre',\n"," 'tiens',\n"," 'tirer',\n"," 'toi',\n"," 'tombe',\n"," 'ton',\n"," 'torche',\n"," 'totalement',\n"," 'touches',\n"," 'touché',\n"," 'toujours',\n"," 'tour',\n"," 'tous',\n"," 'tout',\n"," 'toute',\n"," 'toutes',\n"," 'traditionnel',\n"," 'traditionnelle',\n"," 'train',\n"," 'trancher',\n"," 'transmettre',\n"," 'travail',\n"," 'travaillaient',\n"," 'travaillais',\n"," 'travaille',\n"," 'travailler',\n"," 'travailleras',\n"," 'travaillé',\n"," 'travers',\n"," 'tricotait',\n"," 'trouvé',\n"," 'très',\n"," 'tu',\n"," 'télescope',\n"," 'téléphone',\n"," 'tôt',\n"," 't’',\n"," 'un',\n"," 'une',\n"," 'univers',\n"," 'utile',\n"," 'va',\n"," 'vacances',\n"," 'vas',\n"," 'venir',\n"," 'vent',\n"," 'verrais',\n"," 'verras',\n"," 'verrons',\n"," 'vers',\n"," 'veuillez',\n"," 'veux',\n"," 'vie',\n"," 'ville',\n"," 'vis',\n"," 'visitera',\n"," 'visiterai',\n"," 'visiterons',\n"," 'visité',\n"," 'vite',\n"," 'vivez',\n"," 'vivre',\n"," 'voie',\n"," 'voir',\n"," ...]"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["tokens"],"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"p4AOWHD9XyJ5","executionInfo":{"status":"ok","timestamp":1747396677736,"user_tz":-120,"elapsed":32,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}},"outputId":"767f8ee2-724b-4a2d-fc43-25926d17f6f6"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[138, 215, 980, 969, 94],\n"," [577, 726, 942, 28, 771, 514, 912, 805],\n"," [621, 41, 93, 569, 17, 296, 557, 447],\n"," [359, 276, 974, 473, 93, 194, 726, 558, 55, 288, 862, 920],\n"," [534, 184, 325, 917, 534, 156, 363, 844, 327],\n"," [487, 961, 917, 974, 761, 490, 726, 894, 379],\n"," [621, 814, 534, 259, 288, 890, 291, 527, 933],\n"," [969, 544, 974, 547, 678, 917, 558, 481, 52],\n"," [488, 518, 93, 442, 284, 534, 657, 109, 541, 46],\n"," [526, 1052, 975, 538, 1029, 590, 257, 1071],\n"," [527, 1004, 845, 799, 917, 558, 102],\n"," [534, 982, 897, 445, 284, 537, 76, 363, 101],\n"," [621, 117, 995, 974, 600, 356, 82, 585, 480],\n"," [359, 285, 464, 917, 527, 872, 330, 937],\n"," [969, 1047, 288, 527, 599, 207, 726, 928, 354],\n"," [488, 1015, 904, 1029, 558, 1071, 726, 341, 288, 625, 280],\n"," [514, 773, 974, 153, 185, 726, 129, 213, 527, 524],\n"," [534, 152, 325, 653, 284, 894, 126],\n"," [621, 418, 330, 1023, 534, 550, 288, 527, 841],\n"," [359, 177, 975, 173, 326, 726, 369, 894, 370],\n"," [969, 84, 18, 330, 652, 1029, 527, 144, 160, 571],\n"," [487, 299, 974, 682, 560, 109, 296, 273, 288, 260],\n"," [621, 67, 975, 624, 532, 374, 558, 56, 748],\n"," [359, 516, 330, 700, 182, 887, 108, 356, 39, 873, 259],\n"," [969, 266, 974, 566, 534, 588, 747],\n"," [488, 808, 537, 1070, 284, 534, 204, 345, 480, 887],\n"," [514, 243, 975, 561, 363, 135, 93, 141, 330, 528],\n"," [534, 750, 406, 527, 542, 109, 680, 394, 205],\n"," [621, 1048, 91, 558, 481, 794, 655, 619, 467],\n"," [359, 685, 975, 449, 597, 284, 894, 87],\n"," [969, 1055, 947, 296, 732, 783, 969, 1068, 370],\n"," [488, 670, 363, 1012, 74, 541, 396],\n"," [514, 417, 904, 330, 155, 363, 1074, 109, 579, 271],\n"," [534, 415, 60, 975, 538, 289, 571],\n"," [621, 115, 975, 315, 508, 917, 527, 697],\n"," [359, 992, 661, 687, 537, 979],\n"," [969, 106, 346, 463, 160, 710, 108, 94],\n"," [488, 568, 917, 527, 704, 93, 259, 330, 890],\n"," [526, 106, 647, 590, 656, 1029, 527, 561],\n"," [534, 193, 520, 284, 534, 513, 951, 527, 524],\n"," [621, 67, 537, 848, 288, 465, 363, 269],\n"," [359, 435, 894, 297, 553, 636, 558, 9, 58],\n"," [969, 811, 160, 433, 109, 621, 289, 887],\n"," [488, 852, 527, 1004, 783, 527, 715, 9, 214],\n"," [514, 614, 284, 527, 701, 687, 537, 979],\n"," [534, 982, 896, 445, 480, 887, 687, 558, 640],\n"," [621, 115, 947, 861, 288, 416, 534, 948, 330, 591],\n"," [359, 170, 288, 958, 1029, 527, 434, 330, 588],\n"," [969, 545, 974, 547, 783, 534, 971, 9, 895],\n"," [488, 68, 1029, 754, 363, 780, 165, 56],\n"," [514, 277, 974, 710, 953, 726, 579, 46],\n"," [534, 603, 397, 534, 681, 109, 90],\n"," [621, 985, 974, 430, 356, 83, 1029, 527, 456, 615],\n"," [359, 722, 975, 788, 306, 1029, 894, 750],\n"," [969, 1050, 975, 319, 917, 160, 915, 289],\n"," [488, 959, 927, 726, 931, 540, 761],\n"," [514, 737, 974, 114, 726, 549, 527, 876, 748],\n"," [534, 890, 148, 445, 164, 75],\n"," [621, 67, 1029, 519, 356, 974, 505, 288, 599],\n"," [359, 176, 284, 527, 200, 288, 558, 1038],\n"," [969, 563, 296, 451, 74, 534, 826],\n"," [488, 89, 534, 150, 902, 527, 715],\n"," [514, 993, 974, 202, 604, 687, 537, 979],\n"," [534, 184, 869, 917, 527, 923, 726, 92, 527, 620],\n"," [621, 521, 105, 1034, 160, 1026, 1, 367],\n"," [359, 1013, 904, 363, 955, 726, 39, 1000, 880, 659],\n"," [969, 1044, 527, 795, 687, 784, 969, 278],\n"," [488, 245, 975, 128, 726, 527, 990],\n"," [514, 853, 590, 1023, 783, 969, 385, 80],\n"," [534, 982, 60, 288, 527, 448, 164, 1074],\n"," [621, 567, 374, 284, 527, 446],\n"," [359, 966, 975, 1033, 726, 894, 452],\n"," [969, 811, 537, 1070, 109, 974, 970],\n"," [488, 708, 296, 76, 284, 534, 657, 596],\n"," [514, 612, 368, 904, 363, 1040, 288, 527, 599],\n"," [534, 750, 373, 975, 624, 542, 289],\n"," [621, 543, 974, 843, 158, 363, 206],\n"," [359, 921, 476, 1060, 726, 527, 888],\n"," [969, 65, 1029, 231, 332, 784, 969, 97, 558, 1030],\n"," [488, 263, 284, 534, 907, 551, 288, 558, 377],\n"," [514, 178, 1029, 527, 456, 288, 558, 1038],\n"," [534, 193, 11, 783, 787, 974, 70, 288, 527, 561],\n"," [621, 287, 951, 527, 628, 551, 330, 570],\n"," [359, 516, 288, 527, 472, 284, 974, 470, 288, 599],\n"," [969, 664, 53, 264, 74, 717, 57, 288, 733],\n"," [488, 1054, 296, 539, 1029, 541, 46, 548],\n"," [514, 782, 284, 527, 841, 687, 558, 1074],\n"," [534, 890, 873, 258, 536, 295, 537, 593],\n"," [621, 67, 537, 120, 288, 527, 698, 363, 269],\n"," [359, 298, 296, 721, 288, 880, 46],\n"," [969, 414, 974, 162, 1, 1005, 109, 330, 654, 210],\n"," [488, 335, 527, 561, 726, 626],\n"," [514, 810, 974, 321, 917, 527, 616, 160, 887],\n"," [534, 982, 896, 363, 796, 769, 288, 527, 281],\n"," [621, 798, 296, 256, 917, 527, 704],\n"," [359, 849, 974, 731, 301, 951, 527, 206],\n"," [969, 219, 581, 165, 542, 74, 527, 859],\n"," [488, 32, 1029, 527, 241, 356, 975, 1038, 363, 24],\n"," [514, 1018, 1029, 965, 558, 395, 363, 955],\n"," [534, 184, 183, 975, 901, 284, 534, 513],\n"," [621, 67, 527, 272, 109, 619, 467],\n"," [359, 405, 534, 745, 363, 351],\n"," [969, 806, 165, 605, 489],\n"," [488, 684, 537, 598, 288, 540, 624, 561],\n"," [514, 720, 974, 565, 185, 363, 483],\n"," [534, 415, 546, 534, 267, 182, 571],\n"," [621, 1045, 974, 229, 363, 712, 36],\n"," [359, 792, 975, 481, 329, 726, 354, 558, 88],\n"," [969, 197, 974, 547, 284, 527, 128],\n"," [488, 613, 284, 527, 576, 902, 974, 121, 890],\n"," [514, 993, 534, 600, 356, 82, 252, 289],\n"," [534, 982, 119, 537, 431, 594, 917, 527, 846],\n"," [621, 67, 1029, 519, 93, 930, 164, 1074],\n"," [359, 336, 534, 473, 109, 288, 527, 275, 181],\n"," [969, 822, 288, 625, 692, 1029, 165, 234],\n"," [488, 174, 363, 203, 551, 330, 429],\n"," [514, 572, 764, 93, 141, 330, 438, 93, 743],\n"," [534, 143, 772, 330, 652, 447, 182, 571],\n"," [621, 812, 974, 433, 363, 422, 311, 887],\n"," [359, 20, 537, 1070, 284, 534, 204, 345],\n"," [969, 65, 1029, 286, 109, 974, 750],\n"," [488, 386, 975, 592, 363, 1074],\n"," [514, 707, 296, 437, 284, 590, 513, 93, 743],\n"," [534, 279, 772, 974, 826, 460, 726, 880, 509],\n"," [621, 31, 618, 1003, 1029, 348],\n"," [359, 270, 975, 842, 726, 558, 1074],\n"," [969, 72, 160, 906, 288, 285, 954],\n"," [488, 631, 537, 635, 109, 296, 525],\n"," [514, 243, 974, 580, 363, 135, 109, 590, 781],\n"," [534, 686, 38, 537, 294, 945, 1029, 894, 924],\n"," [621, 994, 974, 1028, 726, 1000, 537, 54, 870],\n"," [514, 221, 660, 165, 885, 394, 526, 1027, 850, 365],\n"," [221, 1, 969, 160, 784, 514, 988, 313, 642, 322, 5, 807, 559, 688],\n"," [617, 218, 1, 969, 672, 346, 165, 847, 108, 356, 79, 485],\n"," [621, 304, 66, 1029, 1043, 537, 104, 109, 90],\n"," [305, 6, 1022, 914, 165, 847, 642, 728, 6, 558, 19],\n"," [617, 303, 6, 672, 1078, 346, 671, 108, 784, 527, 628, 941],\n"," [359, 188, 975, 892, 357, 726, 854, 160, 745],\n"," [190, 7, 2, 974, 622, 958, 74, 116, 932, 880, 1073],\n"," [629, 96, 2, 672, 346, 967, 974, 360, 881, 359, 107, 581, 775, 894, 381],\n"," [969, 1001, 534, 890, 789, 873, 556, 295, 537, 593],\n"," [983, 1, 969, 165, 872, 309, 881, 969, 235, 951, 558, 481],\n"," [617, 1019, 1, 969, 672, 346, 537, 882, 108, 791, 488, 617, 302, 1075],\n"," [487, 249, 974, 12, 726, 768, 880, 54, 330, 450],\n"," [242, 7, 3, 975, 624, 561, 642, 851, 7, 3, 161],\n"," [617, 248, 3, 672, 346, 786, 201, 356, 103, 108, 160, 761],\n"," [621, 392, 974, 110, 573, 726, 949, 537, 695, 330, 591],\n"," [390, 8, 1022, 784, 165, 885, 921, 50, 799],\n"," [629, 391, 8, 672, 875, 974, 103, 855, 288, 165, 412],\n"," [488, 265, 182, 571, 726, 458, 527, 443, 394, 834, 363, 139, 867],\n"," [268, 4, 365, 558, 483, 747, 562, 534, 450, 462],\n"," [617, 263, 4, 672, 716, 904, 108, 784, 540, 360, 330, 929, 617, 168],\n"," [514, 177, 284, 975, 200, 949, 537, 312, 109, 375],\n"," [179, 1, 969, 301, 950, 534, 778, 551, 330, 906, 288, 434, 356, 56],\n"," [617, 175, 1, 969, 672, 346, 165, 173, 552, 621, 1069, 371],\n"," [969, 198, 947, 537, 575, 300, 726, 1016],\n"," [196, 1, 969, 975, 103, 639, 881, 161, 617, 440, 672],\n"," [617, 199, 1, 969, 672, 918, 537, 611, 261, 95],\n"," [359, 1053, 975, 538, 1029, 894, 45, 667, 998, 1029, 558, 1071],\n"," [1049, 7, 2, 974, 547, 974, 522, 726, 793, 894, 495, 111],\n"," [629, 1056, 2, 672, 346, 288, 694, 482, 284, 894, 523, 507],\n"," [621, 1021, 537, 1070, 149, 284, 534, 204, 345, 165, 628],\n"," [985, 6, 974, 522, 975, 103, 709, 477, 284, 558, 976],\n"," [617, 1020, 6, 672, 346, 537, 735, 496, 288, 165, 338],\n"," [488, 741, 296, 334, 491, 726, 540, 379, 182, 522],\n"," [739, 4, 363, 225, 952, 537, 911, 296, 361, 108, 288, 956],\n"," [617, 736, 4, 672, 346, 163, 770, 108, 558, 81, 330, 745],\n"," [514, 961, 109, 677, 917, 182, 761, 784, 526, 378],\n"," [963, 1, 969, 109, 586, 917, 160, 622, 761, 44],\n"," [617, 960, 1, 969, 672, 346, 917, 974, 915, 883, 95],\n"," [969, 33, 904, 935, 46, 553, 488, 637, 127, 288, 940],\n"," [30, 1, 969, 942, 1002, 1029, 348, 160, 1026, 1, 367],\n"," [629, 27, 1, 969, 672, 346, 787, 974, 356, 103, 108, 288, 981, 485],\n"," [359, 63, 288, 625, 227, 726, 1076, 284, 894, 609],\n"," [64, 7, 2, 716, 996, 881, 359, 913, 296, 269, 916],\n"," [629, 61, 2, 672, 346, 165, 532, 108, 288, 348],\n"," [621, 223, 581, 165, 746, 74, 717, 404],\n"," [220, 6, 974, 522, 949, 537, 601, 288, 558, 976],\n"," [617, 222, 6, 672, 346, 160, 228, 108, 791, 487, 617, 889, 407],\n"," [488, 340, 288, 625, 280, 363, 1014, 1029, 965, 534, 591],\n"," [342, 4, 130, 975, 1079, 365, 494],\n"," [617, 339, 4, 672, 346, 296, 496, 917, 160, 699, 487, 1027, 9, 296, 57],\n"," [514, 188, 240, 296, 893, 105, 344, 784, 514, 820],\n"," [191, 1, 969, 975, 624, 638, 751, 130],\n"," [617, 187, 1, 969, 672, 346, 975, 43, 108, 288, 195, 165, 639],\n"," [969, 135, 947, 974, 153, 108, 288, 213, 922, 524],\n"," [134, 1, 969, 330, 936, 1029, 527, 703, 881, 514, 973, 363, 773, 974],\n"," [617, 151, 1, 969, 672, 718, 330, 194, 185, 783, 621, 1069, 371],\n"," [359, 649, 527, 719, 726, 530, 380, 527, 554, 330, 522],\n"," [650, 7, 2, 894, 766, 216, 974, 522],\n"," [629, 648, 2, 672, 947, 527, 423, 182, 571, 95],\n"," [621, 1058, 374, 975, 481, 713, 356, 112, 394, 288, 802],\n"," [1051, 6, 974, 522, 974, 547, 789, 501, 296, 582, 288, 535],\n"," [629, 1057, 6, 672, 346, 974, 761, 883, 558, 51, 292],\n"," [488, 663, 717, 533, 394, 217, 37, 109, 537, 1072],\n"," [665, 4, 130, 975, 624, 532, 726, 540, 958],\n"," [617, 662, 4, 672, 346, 264, 388, 108, 356, 66, 558, 511],\n"," [514,\n","  830,\n","  975,\n","  468,\n","  515,\n","  1029,\n","  558,\n","  486,\n","  288,\n","  840,\n","  579,\n","  46,\n","  74,\n","  926,\n","  356,\n","  57],\n"," [832, 1, 969, 527, 610, 1062, 552, 969, 838, 922, 422],\n"," [617, 831, 1, 969, 672, 346, 165, 400, 108, 610, 356, 17, 942, 133],\n"," [969, 645, 904, 651, 969, 84, 583, 935, 23],\n"," [644, 1, 969, 365, 942, 863, 289, 571],\n"," [629, 643, 1, 969, 672, 346, 935, 209, 182, 876, 95],\n"," [359, 1012, 904, 726, 341, 288, 623, 683],\n"," [1017, 7, 2, 974, 522, 284, 558, 387],\n"," [617, 1013, 2, 672, 346, 904, 108, 288, 921, 502, 485],\n"," [621, 169, 618, 478, 726, 21, 974, 584, 288, 989, 716, 864],\n"," [171, 6, 974, 522, 944, 619, 564, 288, 239],\n"," [617, 172, 6, 672, 346, 758, 108, 165, 744, 288, 237],\n"," [488, 809, 537, 627, 343, 284, 534, 204, 109, 1061],\n"," [813, 4, 974, 433, 160, 887, 374],\n"," [617, 808, 4, 672, 346, 165, 919, 527, 876, 293],\n"," [514, 246, 974, 761, 44, 109, 590, 1067],\n"," [244, 1, 969, 974, 522, 527, 561, 288, 935, 860],\n"," [617, 247, 1, 969, 672, 346, 974, 706, 108, 288, 213, 160, 180],\n"," [969, 427, 947, 527, 719, 1029, 208, 108, 288, 669],\n"," [426, 8, 527, 145, 716, 972, 94],\n"," [617, 425, 4, 672, 346, 527, 423, 108, 784, 527, 715, 617, 212],\n"," [359, 773, 974, 826, 347, 726, 951, 862, 422],\n"," [774, 7, 2, 974, 428, 726, 537, 457, 288, 434, 356, 56],\n"," [617, 772, 2, 672, 346, 160, 710, 527, 876, 293],\n"," [621, 759, 182, 522, 363, 62, 288, 618, 384],\n"," [756, 6, 716, 799, 109, 975, 574, 641],\n"," [617, 757, 6, 672, 346, 108, 288, 914, 165, 624, 608],\n"," [488, 1042, 91, 182, 595, 330, 314],\n"," [1046, 4, 109, 100, 356, 90, 527, 748, 439],\n"," [629, 1039, 4, 672, 346, 537, 238, 108, 288, 738, 165, 333],\n"," [514, 991, 182, 504, 109, 506, 394, 677],\n"," [984, 1, 969, 527, 123, 288, 527, 989, 284, 182, 351],\n"," [617, 1019, 1, 969, 672, 346, 165, 1024, 108, 791, 636, 928, 558, 406],\n"," [969, 973, 49, 947, 363, 517, 109, 935, 46],\n"," [973, 48, 1, 969, 100, 527, 748, 439],\n"," [617, 973, 47, 1, 969, 672, 346, 108, 610, 784, 527, 456, 212],\n"," [359, 1036, 527, 702, 363, 42, 975, 142],\n"," [1037, 7, 2, 619, 186, 109, 862, 531, 943],\n"," [629, 1035, 2, 672, 346, 527, 865, 108, 784, 558, 1059, 617, 839],\n"," [621, 410, 182, 803, 288, 165, 1079, 602],\n"," [408, 6, 130, 974, 622, 934, 493],\n"," [617, 409, 6, 672, 346, 160, 228, 108, 784, 165, 338, 617, 889, 420],\n"," [138, 215, 40, 1011],\n"," [140, 526, 389, 784, 1011, 676, 975, 139, 888],\n"," [866, 215, 873, 673, 1008, 524],\n"," [364, 288, 416, 1008, 236],\n"," [132, 192, 621, 503, 1011, 233],\n"," [514, 1011, 816, 497, 726, 1008, 28, 771],\n"," [577, 122, 726, 1008, 461, 394, 1008, 903],\n"," [514, 938, 1029, 411, 951, 559, 469, 726, 1008, 474],\n"," [109, 949, 579, 817, 726, 1008, 680],\n"," [514, 1011, 912, 805, 726, 950, 160, 784, 1011, 113, 419],\n"," [658, 586, 514, 617, 1009, 672, 1011, 349],\n"," [403, 586, 726, 590, 836, 526, 26, 1074, 837],\n"," [514, 912, 350, 881, 579, 765, 1011, 637, 633],\n"," [987, 612, 401, 726, 165, 383],\n"," [514, 1011, 742, 356, 13, 579, 716, 884, 402],\n"," [514, 1011, 898, 975, 399, 524],\n"," [676, 975, 25, 888],\n"," [139, 628, 828, 1011, 129],\n"," [136, 73, 752, 288, 1008, 826],\n"," [139, 167, 726, 1008, 381, 514, 274, 363, 1011],\n"," [949, 579, 1025, 288, 137, 394, 288, 858, 726, 1008, 110],\n"," [526, 389, 784, 950, 873, 675, 129, 726, 1011],\n"," [514, 1011, 22, 579, 716, 884, 455],\n"," [147, 726, 1008, 909, 1011, 558, 113, 129, 607],\n"," [455, 726, 165, 124, 690],\n"," [514, 912, 479, 726, 1011, 283, 393, 975, 124, 858],\n"," [952, 579, 455, 726, 165, 399, 624],\n"," [514, 1011, 776, 579, 230, 363, 163, 589, 307],\n"," [514, 912, 288, 950, 282, 109, 1011, 284, 165, 1066],\n"," [952, 579, 689, 1006, 986, 1011, 394, 1008, 422],\n"," [514, 666, 1008, 328, 394, 1011, 382, 950, 590, 903],\n"," [740, 886, 288, 1011, 394, 288, 1007, 749],\n"," [881, 514, 696, 416, 790, 784, 160, 889, 726, 1011, 29, 421, 534, 586, 871],\n"," [779, 514, 1011, 29, 356, 975, 785, 564],\n"," [629, 484, 672, 1029, 572, 891, 363, 159, 288, 127],\n"," [881, 1011, 113, 527, 587, 788, 514, 833, 317],\n"," [877, 487, 725, 356, 116, 974, 825],\n"," [727, 1011, 572, 323, 716, 288, 352, 917, 160, 915],\n"," [526, 34, 738, 823, 1011, 1029, 1008, 255],\n"," [98, 1011, 527, 461, 288, 572, 957, 163, 498],\n"," [779, 514, 1011, 362, 974, 908, 921, 487, 1011, 711],\n"," [514, 1011, 363, 742, 421, 211, 192, 1011],\n"," [74, 1011, 514, 1011, 529, 674, 363, 734],\n"," [160, 453, 974, 705, 288, 316, 109, 1011],\n"," [514, 1011, 816, 288, 1008, 90],\n"," [514, 1011, 898, 975, 139, 253],\n"," [740, 886, 288, 1011, 394, 1029, 130],\n"," [1029, 968, 130, 526, 389],\n"," [93, 840, 394, 1029, 527, 748],\n"," [514, 1011, 898, 975, 124, 394, 25, 524],\n"," [676, 974, 398, 1026, 367],\n"," [784, 165, 524, 1011, 59, 122, 288, 515],\n"," [526, 389, 784, 1011, 113, 679, 975, 139, 628],\n"," [215, 779, 514, 1011, 29, 94],\n"," [784, 779, 514, 416, 726, 1011],\n"," [779, 514, 1011, 634, 974, 153, 642, 974, 936],\n"," [1010, 1011, 784, 514, 1011, 14],\n"," [899, 1011, 974, 825, 668],\n"," [283, 393, 109, 705, 784, 514, 1011, 824, 879],\n"," [514, 912, 801, 288, 730, 1011, 29],\n"," [514, 1011, 1041, 320, 586, 363, 790, 514, 696, 1078, 977],\n"," [514, 912, 1029, 1008, 318, 726, 951, 290],\n"," [514, 1011, 86, 784, 514, 424, 288, 590, 581, 726, 1011, 868],\n"," [1011, 729, 226, 917, 586, 726, 1011, 85],\n"," [514, 833, 1029, 1008, 318, 726, 951, 103, 788],\n"," [617, 1011, 499, 672, 950, 978, 129, 873, 674],\n"," [514, 1011, 898, 122, 288, 262, 726, 165, 1066],\n"," [459, 232, 363, 1011, 1011, 113, 952, 537, 157, 726, 857],\n"," [182, 358, 784, 1011, 421, 1011, 800, 288, 1008, 630],\n"," [629, 10, 512, 182, 308, 393, 975, 638, 356, 66],\n"," [514, 274, 363, 1011, 254, 917, 165, 999],\n"," [835, 723, 394, 617, 118, 672, 537, 146],\n"," [617, 1011, 337, 672, 950, 436, 655, 921, 77],\n"," [950, 745, 9, 975, 892, 487, 910, 288, 527, 189],\n"," [1011, 421, 330, 968, 136, 958, 254, 35],\n"," [1011, 113, 1064, 760, 455],\n"," [1011, 606, 165, 858, 1011, 113, 964, 331, 726, 1027, 79],\n"," [514, 912, 492, 655, 1008, 925, 394, 1008, 355],\n"," [160, 784, 1011, 421, 393, 815, 254, 35],\n"," [1011, 729, 1078, 432, 288, 1011, 1008, 909, 393, 607],\n"," [740, 886, 288, 1008, 867, 283, 393, 160, 789, 225, 534, 716],\n"," [629, 646, 672, 288, 738, 330, 929, 726, 1011],\n"," [15, 1011, 330, 827, 1011, 363, 113, 129, 127],\n"," [829, 753, 394, 353, 1011, 950, 510, 129],\n"," [835, 878, 394, 475, 527, 885, 109, 154],\n"," [487, 629, 1027, 9, 672, 288, 745, 784, 330, 723, 1029, 939],\n"," [950, 78, 726, 975, 797, 459, 232, 363, 558, 110],\n"," [182, 522, 393, 975, 624, 638, 288, 755],\n"," [534, 909, 393, 975, 788, 288, 693, 394, 288, 958],\n"," [1011, 1077, 975, 900, 356, 500, 726, 166, 789, 1011, 376],\n"," [1008, 461, 394, 1008, 131, 441, 527, 310],\n"," [577, 726, 1008, 680, 394, 1008, 224],\n"," [514, 912, 946, 655, 1008, 474, 394, 1008, 903],\n"," [514, 938, 1029, 1011, 411, 951, 559, 804],\n"," [577, 497, 726, 534, 929, 784, 1011, 612, 113, 16],\n"," [526, 71, 1064, 1008, 28, 771],\n"," [1008, 28, 612, 9, 1074, 356, 974, 466, 874, 365, 577],\n"," [109, 951, 559, 469, 726, 1008, 131],\n"," [1011, 1077, 975, 691, 444, 577, 356, 1078, 555],\n"," [514, 912, 801, 356, 116, 777, 1011, 29],\n"," [160, 453, 974, 705, 288, 962, 109, 1011],\n"," [526, 26, 69, 122, 471, 1029, 1011, 577, 726, 950],\n"," [618, 1032, 637, 1074, 968, 372, 577],\n"," [514, 1011, 898, 950, 534, 909, 784, 1011, 606],\n"," [784, 1008, 110, 889, 818, 288, 137, 394, 288, 767],\n"," [514, 1011, 382, 579, 575, 689, 394, 366],\n"," [905, 479, 394, 1065, 182, 522],\n"," [997, 714, 182, 504, 394, 752, 288, 527, 989],\n"," [784, 165, 624, 111, 1011, 59, 288, 125, 413],\n"," [514, 1011, 898, 950, 534, 573, 726, 1007, 762, 454],\n"," [526, 389, 784, 621, 99, 130, 558, 632, 288, 621, 840],\n"," [629, 484, 672, 1029, 572, 251, 881, 1011, 113, 127, 288, 790, 784, 160, 889],\n"," [526, 389, 784, 621, 728, 962, 374, 1029, 622],\n"," [526, 26, 1074, 801, 288, 1011, 821, 394, 356, 1031, 109, 1011],\n"," [514, 1011, 898, 974, 398, 1012, 752, 129],\n"," [828, 1011, 129, 394, 740, 330, 929, 726, 1011],\n"," [514, 1011, 898, 974, 763, 856, 740, 886, 288, 1011],\n"," [881, 1011, 113, 127, 288, 790, 784, 160, 889, 514, 912, 555],\n"," [835, 363, 250, 394, 324, 586, 288, 1007, 625],\n"," [514, 1011, 382, 951, 590, 1063, 724],\n"," [514, 1011, 898, 975, 578, 524, 819, 288, 137],\n"," [1029, 968, 996, 394, 740, 129, 886, 288, 1011]]"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# Fonction permettant d'indexer un texte\n","\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","def tokenizer(text:str, len_padding=15):\n","    return pad_sequences([[list(vocabulaire).index(token.text)+1 for token in nlp(text.lower())]], len_padding, padding='post')\n","\n","tokenizer('Bonjour le chat touches totalement')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aJHfXMaW9L6G","outputId":"06e012c2-61ad-44e5-cc9c-777b34a7bcd7","executionInfo":{"status":"ok","timestamp":1747396684088,"user_tz":-120,"elapsed":25,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}}},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[138, 534, 184, 945, 944,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0]], dtype=int32)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# Fonction permettant de décoder une liste d'index\n","\n","def decoder(tokens):\n","    return [list(vocabulaire)[int(u)-1] for u in tokens if u !=0]\n","\n","decoder([359,276,974,473,93,194,726,558,55,288,862])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yz46nsEe_S7f","outputId":"64b2dd56-f2e5-4924-f229-602a45c91297","executionInfo":{"status":"ok","timestamp":1747396685656,"user_tz":-120,"elapsed":21,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}}},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['elle',\n"," 'cuisine',\n"," 'un',\n"," 'gâteau',\n"," 'au',\n"," 'chocolat',\n"," 'pour',\n"," 'l’',\n"," 'anniversaire',\n"," 'de',\n"," 'sa']"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.DataFrame([doc[:-1] for doc in tokens]).fillna(0).astype(int)\n","df['target'] = [doc[-1] for doc in tokens]\n","\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"cmRQTCAm4PvX","outputId":"bb63733c-1e19-4e40-8942-adcf3587a141","executionInfo":{"status":"ok","timestamp":1747396687855,"user_tz":-120,"elapsed":74,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}}},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        0     1    2    3    4     5    6     7    8    9   10  11  12  13  \\\n","0     138   215  980  969    0     0    0     0    0    0    0   0   0   0   \n","1     577   726  942   28  771   514  912     0    0    0    0   0   0   0   \n","2     621    41   93  569   17   296  557     0    0    0    0   0   0   0   \n","3     359   276  974  473   93   194  726   558   55  288  862   0   0   0   \n","4     534   184  325  917  534   156  363   844    0    0    0   0   0   0   \n","..    ...   ...  ...  ...  ...   ...  ...   ...  ...  ...  ...  ..  ..  ..   \n","356   881  1011  113  127  288   790  784   160  889  514  912   0   0   0   \n","357   835   363  250  394  324   586  288  1007    0    0    0   0   0   0   \n","358   514  1011  382  951  590  1063    0     0    0    0    0   0   0   0   \n","359   514  1011  898  975  578   524  819   288    0    0    0   0   0   0   \n","360  1029   968  996  394  740   129  886   288    0    0    0   0   0   0   \n","\n","     14  target  \n","0     0      94  \n","1     0     805  \n","2     0     447  \n","3     0     920  \n","4     0     327  \n","..   ..     ...  \n","356   0     555  \n","357   0     625  \n","358   0     724  \n","359   0     137  \n","360   0    1011  \n","\n","[361 rows x 16 columns]"],"text/html":["\n","  <div id=\"df-c0f68020-4041-4cc3-b11c-faab7aef46b3\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>138</td>\n","      <td>215</td>\n","      <td>980</td>\n","      <td>969</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>94</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>577</td>\n","      <td>726</td>\n","      <td>942</td>\n","      <td>28</td>\n","      <td>771</td>\n","      <td>514</td>\n","      <td>912</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>805</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>621</td>\n","      <td>41</td>\n","      <td>93</td>\n","      <td>569</td>\n","      <td>17</td>\n","      <td>296</td>\n","      <td>557</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>447</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>359</td>\n","      <td>276</td>\n","      <td>974</td>\n","      <td>473</td>\n","      <td>93</td>\n","      <td>194</td>\n","      <td>726</td>\n","      <td>558</td>\n","      <td>55</td>\n","      <td>288</td>\n","      <td>862</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>920</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>534</td>\n","      <td>184</td>\n","      <td>325</td>\n","      <td>917</td>\n","      <td>534</td>\n","      <td>156</td>\n","      <td>363</td>\n","      <td>844</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>327</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>356</th>\n","      <td>881</td>\n","      <td>1011</td>\n","      <td>113</td>\n","      <td>127</td>\n","      <td>288</td>\n","      <td>790</td>\n","      <td>784</td>\n","      <td>160</td>\n","      <td>889</td>\n","      <td>514</td>\n","      <td>912</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>555</td>\n","    </tr>\n","    <tr>\n","      <th>357</th>\n","      <td>835</td>\n","      <td>363</td>\n","      <td>250</td>\n","      <td>394</td>\n","      <td>324</td>\n","      <td>586</td>\n","      <td>288</td>\n","      <td>1007</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>625</td>\n","    </tr>\n","    <tr>\n","      <th>358</th>\n","      <td>514</td>\n","      <td>1011</td>\n","      <td>382</td>\n","      <td>951</td>\n","      <td>590</td>\n","      <td>1063</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>724</td>\n","    </tr>\n","    <tr>\n","      <th>359</th>\n","      <td>514</td>\n","      <td>1011</td>\n","      <td>898</td>\n","      <td>975</td>\n","      <td>578</td>\n","      <td>524</td>\n","      <td>819</td>\n","      <td>288</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>137</td>\n","    </tr>\n","    <tr>\n","      <th>360</th>\n","      <td>1029</td>\n","      <td>968</td>\n","      <td>996</td>\n","      <td>394</td>\n","      <td>740</td>\n","      <td>129</td>\n","      <td>886</td>\n","      <td>288</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1011</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>361 rows × 16 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0f68020-4041-4cc3-b11c-faab7aef46b3')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c0f68020-4041-4cc3-b11c-faab7aef46b3 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c0f68020-4041-4cc3-b11c-faab7aef46b3');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-05b3d4e7-1e35-4fbe-93e6-328a9f80c0b4\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-05b3d4e7-1e35-4fbe-93e6-328a9f80c0b4')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-05b3d4e7-1e35-4fbe-93e6-328a9f80c0b4 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_e12a94f6-911a-43c4-9fda-16bcf8bcdeff\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_e12a94f6-911a-43c4-9fda-16bcf8bcdeff button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 361,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 233,\n        \"min\": 15,\n        \"max\": 1051,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          244,\n          1049,\n          403\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 371,\n        \"min\": 1,\n        \"max\": 1077,\n        \"num_unique_values\": 237,\n        \"samples\": [\n          188,\n          1015,\n          274\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 369,\n        \"min\": 1,\n        \"max\": 1078,\n        \"num_unique_values\": 134,\n        \"samples\": [\n          110,\n          365,\n          572\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 288,\n        \"min\": 0,\n        \"max\": 1074,\n        \"num_unique_values\": 190,\n        \"samples\": [\n          475,\n          691,\n          109\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 298,\n        \"min\": 0,\n        \"max\": 1079,\n        \"num_unique_values\": 186,\n        \"samples\": [\n          394,\n          393,\n          131\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 321,\n        \"min\": 0,\n        \"max\": 1071,\n        \"num_unique_values\": 179,\n        \"samples\": [\n          346,\n          726,\n          712\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 6,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 347,\n        \"min\": 0,\n        \"max\": 1079,\n        \"num_unique_values\": 160,\n        \"samples\": [\n          583,\n          564,\n          952\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 7,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 347,\n        \"min\": 0,\n        \"max\": 1078,\n        \"num_unique_values\": 130,\n        \"samples\": [\n          312,\n          847,\n          619\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 8,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 289,\n        \"min\": 0,\n        \"max\": 1026,\n        \"num_unique_values\": 76,\n        \"samples\": [\n          527,\n          793,\n          456\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 9,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 261,\n        \"min\": 0,\n        \"max\": 1078,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          0,\n          356,\n          51\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 10,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 185,\n        \"min\": 0,\n        \"max\": 1069,\n        \"num_unique_values\": 37,\n        \"samples\": [\n          487,\n          495,\n          628\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 11,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 151,\n        \"min\": 0,\n        \"max\": 1069,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0,\n          456,\n          160\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 12,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 126,\n        \"min\": 0,\n        \"max\": 981,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          74,\n          558,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 13,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 76,\n        \"min\": 0,\n        \"max\": 926,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0,\n          894,\n          160\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 14,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18,\n        \"min\": 0,\n        \"max\": 356,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          356,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 313,\n        \"min\": 14,\n        \"max\": 1075,\n        \"num_unique_values\": 260,\n        \"samples\": [\n          396,\n          771\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["# Entrainement : Many-to-One -> `return_sequences`\n","\n","---\n","\n"],"metadata":{"id":"Leh5uNLmb1yD"}},{"cell_type":"code","source":["from tensorflow.keras.utils import to_categorical\n","\n","X = df.drop(['target'], axis=1)\n","y = df.target\n","y = to_categorical(y, len(vocabulaire)+1)\n","\n","\n","X.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J0WTmLKnI-64","outputId":"482cfd84-ac61-4f90-ef2e-bfcbadc8ba41","executionInfo":{"status":"ok","timestamp":1747396690540,"user_tz":-120,"elapsed":19,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}}},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(361, 15)"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n","\n","embedding_dim = 128                         # Taille des embedding\n","maxlen = X.shape[1]                         # Nombre max de token des documents\n","len_vocabulaire = len(vocabulaire)+1        # Taille du vocabulaire\n","\n","model = Sequential()\n","\n","# Couche d'ebedding\n","model.add(Embedding(input_dim=len_vocabulaire, output_dim=embedding_dim, input_length=maxlen))\n","\n","# Couche RNN\n","model.add(SimpleRNN(64, activation='relu'))\n","\n","# Couche d'activation\n","model.add(Dense(len_vocabulaire, activation='softmax'))\n","\n","# Compilation du modèle : metrics=['accuracy', 'recall']\n","model.compile(optimizer='adam',metrics=['accuracy', 'recall'], loss=\"categorical_crossentropy\")\n","\n","# Entrainement : (X, y, epochs=200, batch_size=64)\n","model.summary()\n","\n","model.fit(X, y, epochs=200, batch_size=64)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"clgvzwDhHcTM","outputId":"0be36c22-c928-4f4a-9d25-64a05fde579f","collapsed":true,"executionInfo":{"status":"ok","timestamp":1747396714386,"user_tz":-120,"elapsed":22066,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}}},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_1\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 6.9852 - recall: 0.0000e+00\n","Epoch 2/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0025 - loss: 6.9636 - recall: 0.0000e+00    \n","Epoch 3/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 6.8692 - recall: 0.0000e+00\n","Epoch 4/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0026 - loss: 6.3869 - recall: 0.0000e+00    \n","Epoch 5/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0143 - loss: 5.8779 - recall: 0.0000e+00\n","Epoch 6/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0253 - loss: 5.6058 - recall: 0.0000e+00\n","Epoch 7/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0269 - loss: 5.5006 - recall: 0.0000e+00    \n","Epoch 8/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0433 - loss: 5.4028 - recall: 0.0000e+00\n","Epoch 9/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0356 - loss: 5.3811 - recall: 0.0000e+00\n","Epoch 10/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0327 - loss: 5.3265 - recall: 0.0000e+00\n","Epoch 11/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0386 - loss: 5.2616 - recall: 0.0000e+00\n","Epoch 12/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0429 - loss: 5.1945 - recall: 0.0000e+00\n","Epoch 13/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0239 - loss: 5.3028 - recall: 0.0000e+00    \n","Epoch 14/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0318 - loss: 5.1652 - recall: 0.0000e+00\n","Epoch 15/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0297 - loss: 5.0645 - recall: 0.0000e+00\n","Epoch 16/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0247 - loss: 4.8659 - recall: 0.0000e+00\n","Epoch 17/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0542 - loss: 4.7945 - recall: 0.0043    \n","Epoch 18/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0626 - loss: 4.6037 - recall: 0.0000e+00\n","Epoch 19/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0478 - loss: 4.4221 - recall: 0.0117    \n","Epoch 20/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0858 - loss: 4.1747 - recall: 0.0289\n","Epoch 21/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1118 - loss: 3.9353 - recall: 0.0401\n","Epoch 22/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1337 - loss: 3.8314 - recall: 0.0284\n","Epoch 23/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1265 - loss: 3.6754 - recall: 0.0339\n","Epoch 24/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1728 - loss: 3.5079 - recall: 0.0413\n","Epoch 25/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1612 - loss: 3.4317 - recall: 0.0718\n","Epoch 26/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1602 - loss: 3.3424 - recall: 0.0568\n","Epoch 27/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1778 - loss: 3.2138 - recall: 0.0772\n","Epoch 28/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2320 - loss: 3.0269 - recall: 0.1005\n","Epoch 29/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1980 - loss: 3.0161 - recall: 0.1119\n","Epoch 30/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2233 - loss: 2.9322 - recall: 0.0884\n","Epoch 31/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2747 - loss: 2.7316 - recall: 0.1195\n","Epoch 32/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2795 - loss: 2.7163 - recall: 0.1471\n","Epoch 33/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2854 - loss: 2.7039 - recall: 0.1575\n","Epoch 34/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3287 - loss: 2.4404 - recall: 0.1613\n","Epoch 35/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3198 - loss: 2.4925 - recall: 0.1521\n","Epoch 36/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4246 - loss: 2.0854 - recall: 0.2096\n","Epoch 37/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4198 - loss: 2.0517 - recall: 0.2233\n","Epoch 38/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4294 - loss: 2.0179 - recall: 0.2491\n","Epoch 39/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4712 - loss: 1.9250 - recall: 0.2573\n","Epoch 40/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5040 - loss: 1.7941 - recall: 0.3019\n","Epoch 41/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4765 - loss: 1.7622 - recall: 0.2969\n","Epoch 42/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5775 - loss: 1.5936 - recall: 0.3615\n","Epoch 43/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5533 - loss: 1.6285 - recall: 0.2964\n","Epoch 44/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5578 - loss: 1.5953 - recall: 0.3269\n","Epoch 45/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5981 - loss: 1.4189 - recall: 0.3643\n","Epoch 46/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6127 - loss: 1.3682 - recall: 0.3892\n","Epoch 47/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6484 - loss: 1.2965 - recall: 0.3739\n","Epoch 48/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6474 - loss: 1.2819 - recall: 0.3990\n","Epoch 49/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6451 - loss: 1.2073 - recall: 0.4130\n","Epoch 50/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6119 - loss: 1.2642 - recall: 0.3831\n","Epoch 51/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6912 - loss: 1.0750 - recall: 0.4960\n","Epoch 52/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7332 - loss: 0.9144 - recall: 0.5555\n","Epoch 53/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7884 - loss: 0.7624 - recall: 0.5852\n","Epoch 54/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8331 - loss: 0.6473 - recall: 0.6731\n","Epoch 55/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8436 - loss: 0.6260 - recall: 0.6756\n","Epoch 56/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8461 - loss: 0.5721 - recall: 0.7001\n","Epoch 57/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8838 - loss: 0.4389 - recall: 0.7833\n","Epoch 58/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8972 - loss: 0.4666 - recall: 0.7910\n","Epoch 59/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8630 - loss: 0.4470 - recall: 0.7629\n","Epoch 60/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9042 - loss: 0.4028 - recall: 0.7973\n","Epoch 61/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8673 - loss: 0.4501 - recall: 0.7811\n","Epoch 62/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8971 - loss: 0.4295 - recall: 0.7979\n","Epoch 63/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9030 - loss: 0.3522 - recall: 0.8329\n","Epoch 64/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8456 - loss: 0.5398 - recall: 0.7632\n","Epoch 65/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8467 - loss: 0.5268 - recall: 0.7725\n","Epoch 66/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8410 - loss: 0.6133 - recall: 0.7153\n","Epoch 67/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8411 - loss: 0.5411 - recall: 0.7212\n","Epoch 68/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8534 - loss: 0.6198 - recall: 0.7583\n","Epoch 69/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7848 - loss: 0.5925 - recall: 0.7096\n","Epoch 70/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8833 - loss: 0.4699 - recall: 0.8009\n","Epoch 71/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8773 - loss: 0.4689 - recall: 0.7823\n","Epoch 72/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8861 - loss: 0.4220 - recall: 0.8114\n","Epoch 73/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9204 - loss: 0.2958 - recall: 0.8628\n","Epoch 74/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9282 - loss: 0.2941 - recall: 0.8789\n","Epoch 75/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9194 - loss: 0.3454 - recall: 0.8615\n","Epoch 76/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9528 - loss: 0.2234 - recall: 0.9149\n","Epoch 77/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9456 - loss: 0.2221 - recall: 0.9258\n","Epoch 78/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9693 - loss: 0.1712 - recall: 0.9610\n","Epoch 79/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9564 - loss: 0.1521 - recall: 0.9489\n","Epoch 80/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9760 - loss: 0.1176 - recall: 0.9551\n","Epoch 81/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9784 - loss: 0.1081 - recall: 0.9653\n","Epoch 82/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9941 - loss: 0.0525 - recall: 0.9887\n","Epoch 83/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9938 - loss: 0.0552 - recall: 0.9865\n","Epoch 84/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9941 - loss: 0.0472 - recall: 0.9844\n","Epoch 85/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9923 - loss: 0.0381 - recall: 0.9898\n","Epoch 86/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0190 - recall: 1.0000\n","Epoch 87/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0174 - recall: 1.0000\n","Epoch 88/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0144 - recall: 1.0000\n","Epoch 89/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0109 - recall: 1.0000\n","Epoch 90/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0092 - recall: 1.0000\n","Epoch 91/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0077 - recall: 1.0000\n","Epoch 92/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0068 - recall: 1.0000\n","Epoch 93/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0062 - recall: 1.0000\n","Epoch 94/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0062 - recall: 1.0000\n","Epoch 95/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0046 - recall: 1.0000\n","Epoch 96/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0046 - recall: 1.0000\n","Epoch 97/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0046 - recall: 1.0000\n","Epoch 98/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0039 - recall: 1.0000\n","Epoch 99/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0040 - recall: 1.0000\n","Epoch 100/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0033 - recall: 1.0000\n","Epoch 101/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0032 - recall: 1.0000\n","Epoch 102/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0032 - recall: 1.0000\n","Epoch 103/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0027 - recall: 1.0000\n","Epoch 104/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0027 - recall: 1.0000\n","Epoch 105/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0030 - recall: 1.0000\n","Epoch 106/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0027 - recall: 1.0000\n","Epoch 107/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0023 - recall: 1.0000\n","Epoch 108/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0024 - recall: 1.0000\n","Epoch 109/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0023 - recall: 1.0000\n","Epoch 110/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0020 - recall: 1.0000\n","Epoch 111/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0021 - recall: 1.0000\n","Epoch 112/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0020 - recall: 1.0000\n","Epoch 113/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0020 - recall: 1.0000\n","Epoch 114/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0020 - recall: 1.0000\n","Epoch 115/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0018 - recall: 1.0000\n","Epoch 116/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0015 - recall: 1.0000\n","Epoch 117/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0018 - recall: 1.0000\n","Epoch 118/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0017 - recall: 1.0000\n","Epoch 119/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0015 - recall: 1.0000\n","Epoch 120/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0016 - recall: 1.0000\n","Epoch 121/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0016 - recall: 1.0000\n","Epoch 122/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0014 - recall: 1.0000\n","Epoch 123/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0013 - recall: 1.0000\n","Epoch 124/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0013 - recall: 1.0000    \n","Epoch 125/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0013 - recall: 1.0000\n","Epoch 126/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0012 - recall: 1.0000    \n","Epoch 127/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0014 - recall: 1.0000\n","Epoch 128/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0012 - recall: 1.0000\n","Epoch 129/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0012 - recall: 1.0000\n","Epoch 130/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0011 - recall: 1.0000    \n","Epoch 131/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0011 - recall: 1.0000\n","Epoch 132/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0011 - recall: 1.0000\n","Epoch 133/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0010 - recall: 1.0000    \n","Epoch 134/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0010 - recall: 1.0000\n","Epoch 135/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0010 - recall: 1.0000    \n","Epoch 136/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 9.2182e-04 - recall: 1.0000\n","Epoch 137/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 8.8112e-04 - recall: 1.0000\n","Epoch 138/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 8.5078e-04 - recall: 1.0000\n","Epoch 139/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 8.7353e-04 - recall: 1.0000\n","Epoch 140/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 8.7309e-04 - recall: 1.0000\n","Epoch 141/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 8.1229e-04 - recall: 1.0000\n","Epoch 142/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 8.5414e-04 - recall: 1.0000\n","Epoch 143/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 8.2615e-04 - recall: 1.0000\n","Epoch 144/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 8.1670e-04 - recall: 1.0000\n","Epoch 145/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.9732e-04 - recall: 1.0000\n","Epoch 146/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 7.4812e-04 - recall: 1.0000\n","Epoch 147/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 7.8845e-04 - recall: 1.0000\n","Epoch 148/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.7544e-04 - recall: 1.0000\n","Epoch 149/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 7.8697e-04 - recall: 1.0000\n","Epoch 150/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1576e-04 - recall: 1.0000\n","Epoch 151/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.5685e-04 - recall: 1.0000\n","Epoch 152/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.8780e-04 - recall: 1.0000\n","Epoch 153/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.6069e-04 - recall: 1.0000\n","Epoch 154/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.3546e-04 - recall: 1.0000\n","Epoch 155/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 6.3034e-04 - recall: 1.0000\n","Epoch 156/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.3978e-04 - recall: 1.0000\n","Epoch 157/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.3409e-04 - recall: 1.0000\n","Epoch 158/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 6.0371e-04 - recall: 1.0000\n","Epoch 159/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.8597e-04 - recall: 1.0000\n","Epoch 160/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.4632e-04 - recall: 1.0000\n","Epoch 161/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.6023e-04 - recall: 1.0000\n","Epoch 162/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.3501e-04 - recall: 1.0000\n","Epoch 163/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.4372e-04 - recall: 1.0000\n","Epoch 164/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.7213e-04 - recall: 1.0000\n","Epoch 165/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.0193e-04 - recall: 1.0000\n","Epoch 166/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.1566e-04 - recall: 1.0000\n","Epoch 167/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.1311e-04 - recall: 1.0000\n","Epoch 168/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.8008e-04 - recall: 1.0000\n","Epoch 169/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.0509e-04 - recall: 1.0000\n","Epoch 170/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.5377e-04 - recall: 1.0000\n","Epoch 171/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 5.1169e-04 - recall: 1.0000\n","Epoch 172/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.8598e-04 - recall: 1.0000\n","Epoch 173/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6358e-04 - recall: 1.0000\n","Epoch 174/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.3831e-04 - recall: 1.0000\n","Epoch 175/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.7709e-04 - recall: 1.0000\n","Epoch 176/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.3724e-04 - recall: 1.0000\n","Epoch 177/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.2080e-04 - recall: 1.0000\n","Epoch 178/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.8929e-04 - recall: 1.0000\n","Epoch 179/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.8456e-04 - recall: 1.0000\n","Epoch 180/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.7897e-04 - recall: 1.0000\n","Epoch 181/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.2097e-04 - recall: 1.0000\n","Epoch 182/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.0464e-04 - recall: 1.0000\n","Epoch 183/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.1999e-04 - recall: 1.0000\n","Epoch 184/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.0179e-04 - recall: 1.0000\n","Epoch 185/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.6492e-04 - recall: 1.0000\n","Epoch 186/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.6156e-04 - recall: 1.0000\n","Epoch 187/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.4093e-04 - recall: 1.0000\n","Epoch 188/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.4779e-04 - recall: 1.0000\n","Epoch 189/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.7328e-04 - recall: 1.0000\n","Epoch 190/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.7598e-04 - recall: 1.0000\n","Epoch 191/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.7348e-04 - recall: 1.0000\n","Epoch 192/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.7706e-04 - recall: 1.0000\n","Epoch 193/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.4771e-04 - recall: 1.0000\n","Epoch 194/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.5031e-04 - recall: 1.0000\n","Epoch 195/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.4711e-04 - recall: 1.0000\n","Epoch 196/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.0089e-04 - recall: 1.0000\n","Epoch 197/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.3101e-04 - recall: 1.0000\n","Epoch 198/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.2216e-04 - recall: 1.0000\n","Epoch 199/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 2.9851e-04 - recall: 1.0000\n","Epoch 200/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 3.4001e-04 - recall: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7d8edd908c50>"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["model.layers[0].weights[0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yOcOwFzmIeDP","executionInfo":{"status":"ok","timestamp":1747396724935,"user_tz":-120,"elapsed":41,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}},"outputId":"c9a8823d-6003-40bd-8c03-8347f32ab320"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([1080, 128])"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["model.predict([X.iloc[0]])[0].argmax()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J3wajK7yIDyg","executionInfo":{"status":"ok","timestamp":1747396727068,"user_tz":-120,"elapsed":219,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}},"outputId":"6cceb937-bbc9-4b9a-f7c4-24c170dbc5e6"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n","Expected: keras_tensor\n","Received: inputs=('Tensor(shape=(15, 1))',)\n","  warnings.warn(msg)\n"]},{"output_type":"execute_result","data":{"text/plain":["np.int64(378)"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["decoder([805])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YLIeqI1QIDwK","executionInfo":{"status":"ok","timestamp":1747396735451,"user_tz":-120,"elapsed":7,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}},"outputId":"44e9a5be-9bd8-469d-e8f2-d6c155af6497"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['reconnaissant']"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["# Prédiction du dernier token de la phrase :\n","model.predict(tokenizer(\"Merci pour ton aide précieuse je suis\"))[0].argmax()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"asmCDfkwEvHY","executionInfo":{"status":"ok","timestamp":1747396739084,"user_tz":-120,"elapsed":200,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}},"outputId":"f89a4683-fcb8-4932-fbd8-b77a73fbcb49"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["np.int64(805)"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["# Prediction\n","pred = int(model.predict(tokenizer(\"Ils marcheront sur la plage au coucher du\"))[0].argmax())\n","\n","pred, decoder([pred])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N4Etvs5WQXr3","outputId":"ebea8167-75fd-4c36-d6dd-85e3123d9c15","executionInfo":{"status":"ok","timestamp":1747396741116,"user_tz":-120,"elapsed":96,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}}},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["(890, ['soleil'])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["# Ebedding :\n","model.layers[0].weights[0][pred]"],"metadata":{"id":"JFNYA6Lia734","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b65df31c-9b7c-493f-a638-a10d18dbaa43","executionInfo":{"status":"ok","timestamp":1746727347843,"user_tz":-120,"elapsed":8,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(128,), dtype=float32, numpy=\n","array([-0.00019031, -0.00683109,  0.04762146, -0.03460345,  0.0497084 ,\n","       -0.00340807,  0.0151017 , -0.00716244, -0.01554974,  0.03925351,\n","        0.02844049,  0.02700752,  0.01169491,  0.04011467, -0.04467226,\n","        0.02864448, -0.00483494, -0.04888181, -0.04602342,  0.04020976,\n","       -0.00485398, -0.00034581,  0.00269315,  0.00586943, -0.03904753,\n","        0.00547781,  0.037617  ,  0.02786915,  0.03180167, -0.04296201,\n","        0.00554694, -0.02502289, -0.04369149, -0.03376988, -0.01446557,\n","       -0.03049045, -0.02862791,  0.0297378 ,  0.02559842,  0.02622784,\n","       -0.00562866,  0.04472219,  0.02383938, -0.04094596, -0.00738872,\n","        0.02014278, -0.0191857 ,  0.03357245,  0.0096483 ,  0.04354373,\n","        0.04559005,  0.03904149, -0.00670252,  0.03609719, -0.02171155,\n","       -0.03353643,  0.03342955,  0.02638227,  0.04522074,  0.01620921,\n","        0.00191028, -0.03949716, -0.00385728,  0.03751451,  0.03203592,\n","       -0.03834267, -0.04611597, -0.00735406, -0.02581997, -0.01263786,\n","       -0.01294968, -0.00587155, -0.01877449,  0.03575045, -0.04232775,\n","       -0.01021202,  0.01743844,  0.0435777 ,  0.03064137,  0.00138355,\n","       -0.01883457, -0.00123508,  0.00201835,  0.00384364,  0.01172044,\n","       -0.01258909,  0.00955201, -0.00838908,  0.0009401 ,  0.01079217,\n","        0.01030047,  0.04461685,  0.01326958,  0.00604917, -0.00838579,\n","       -0.00464259,  0.03646417,  0.00600018, -0.04675894, -0.01665779,\n","        0.04257352,  0.00966445,  0.03541121,  0.04331375,  0.00456504,\n","        0.03100816,  0.00394102,  0.03474245, -0.00415851,  0.01011043,\n","        0.03078926,  0.00521604,  0.02212253,  0.00217498, -0.01576317,\n","        0.04240621,  0.04472605,  0.0326272 ,  0.01520877, -0.04492931,\n","       -0.03165095,  0.02457475,  0.03090941,  0.01652693, -0.02302703,\n","       -0.01729701,  0.0305278 , -0.01951176], dtype=float32)>"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["# Many to Many"],"metadata":{"id":"OR1VwdTObnsV"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n","\n","embedding_dim = 128                         # Taille des embedding\n","maxlen = X.shape[1]                         # Nombre max de token des documents\n","len_vocabulaire = len(vocabulaire)+1        # Taille du vocabulaire\n","\n","# 🔹 Transformation des données (Many-to-Many)\n","X = df.drop(['target'], axis=1).values\n","y = df.values[:, 1:]  # Décalage des targets (Many-to-Many)\n","y = tf.keras.utils.to_categorical(y, num_classes=len_vocabulaire)  # Encodage One-Hot"],"metadata":{"id":"HM28liIbeZHK","executionInfo":{"status":"ok","timestamp":1747396747980,"user_tz":-120,"elapsed":48,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"skUJagXqemRX","executionInfo":{"status":"ok","timestamp":1747396750018,"user_tz":-120,"elapsed":8,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}},"outputId":"bdff4374-faef-41f5-cf39-a5cda250b380"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(361, 15, 1080)"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","\n","\n","# 🔹 Transformation des données (Many-to-Many)\n","X = df.drop(['target'], axis=1).values\n","y = df.values[:, 1:]  # Décalage des targets (Many-to-Many)\n","y = tf.keras.utils.to_categorical(y, num_classes=len_vocabulaire)  # Encodage One-Hot\n","\n","# 🔹 Modèle Many-to-Many\n","model = Sequential([\n","    Embedding(input_dim=len_vocabulaire, output_dim=embedding_dim, input_length=maxlen),  # Embedding\n","    SimpleRNN(64, activation='relu', return_sequences=True),  # RNN Many-to-Many\n","    Dense(len_vocabulaire, activation='softmax')  # Prédiction d’une séquence complète\n","])\n","\n","# 🔹 Compilation\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# 🔹 Résumé du modèle\n","model.summary()\n","\n","# 🔹 Entraînement\n","model.fit(X, y, epochs=200, batch_size=64)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"JH1mJN9Aa7b8","outputId":"2c9665e8-0a0f-45dd-d7dc-c5d00298e127","executionInfo":{"status":"ok","timestamp":1747396807614,"user_tz":-120,"elapsed":56078,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}},"collapsed":true},"execution_count":28,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_2\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.2209 - loss: 6.9478\n","Epoch 2/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.4354 - loss: 6.6549\n","Epoch 3/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4690 - loss: 5.7109\n","Epoch 4/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.4667 - loss: 5.0797\n","Epoch 5/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4561 - loss: 4.5538\n","Epoch 6/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4601 - loss: 4.1056\n","Epoch 7/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4596 - loss: 3.7517\n","Epoch 8/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4661 - loss: 3.5787\n","Epoch 9/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4697 - loss: 3.5006\n","Epoch 10/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4645 - loss: 3.4644\n","Epoch 11/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4660 - loss: 3.3951\n","Epoch 12/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4603 - loss: 3.3792\n","Epoch 13/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4762 - loss: 3.2905\n","Epoch 14/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4801 - loss: 3.2556\n","Epoch 15/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4886 - loss: 3.2011\n","Epoch 16/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4774 - loss: 3.2189\n","Epoch 17/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4782 - loss: 3.1876\n","Epoch 18/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4951 - loss: 3.0799\n","Epoch 19/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.4864 - loss: 3.1097\n","Epoch 20/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4879 - loss: 3.0395\n","Epoch 21/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4974 - loss: 2.9848\n","Epoch 22/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4994 - loss: 2.9178\n","Epoch 23/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5027 - loss: 2.8895\n","Epoch 24/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5097 - loss: 2.8185\n","Epoch 25/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5021 - loss: 2.8335\n","Epoch 26/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5017 - loss: 2.8140\n","Epoch 27/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5117 - loss: 2.7128\n","Epoch 28/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5059 - loss: 2.7162\n","Epoch 29/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5130 - loss: 2.6465\n","Epoch 30/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5266 - loss: 2.5631\n","Epoch 31/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5245 - loss: 2.5460\n","Epoch 32/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5238 - loss: 2.5372\n","Epoch 33/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5214 - loss: 2.5197\n","Epoch 34/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5371 - loss: 2.3982\n","Epoch 35/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5405 - loss: 2.3664\n","Epoch 36/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5397 - loss: 2.3624\n","Epoch 37/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5444 - loss: 2.3752\n","Epoch 38/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5518 - loss: 2.2921\n","Epoch 39/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5482 - loss: 2.2692\n","Epoch 40/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5588 - loss: 2.1685\n","Epoch 41/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5601 - loss: 2.1232\n","Epoch 42/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5602 - loss: 2.0814\n","Epoch 43/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5664 - loss: 2.0327\n","Epoch 44/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5780 - loss: 1.9551\n","Epoch 45/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5791 - loss: 1.9152\n","Epoch 46/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5876 - loss: 1.8606\n","Epoch 47/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5991 - loss: 1.7919\n","Epoch 48/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6042 - loss: 1.7479\n","Epoch 49/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6106 - loss: 1.7213\n","Epoch 50/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6213 - loss: 1.6847\n","Epoch 51/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6339 - loss: 1.6205\n","Epoch 52/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6325 - loss: 1.5958\n","Epoch 53/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6448 - loss: 1.5474\n","Epoch 54/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6548 - loss: 1.4982\n","Epoch 55/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6724 - loss: 1.4400\n","Epoch 56/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6821 - loss: 1.4156\n","Epoch 57/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6917 - loss: 1.3560\n","Epoch 58/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6963 - loss: 1.3485\n","Epoch 59/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7024 - loss: 1.3019\n","Epoch 60/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7146 - loss: 1.2511\n","Epoch 61/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7211 - loss: 1.2114\n","Epoch 62/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7345 - loss: 1.1622\n","Epoch 63/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7400 - loss: 1.1264\n","Epoch 64/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7590 - loss: 1.0596\n","Epoch 65/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7583 - loss: 1.0650\n","Epoch 66/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7698 - loss: 1.0171\n","Epoch 67/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7718 - loss: 0.9993\n","Epoch 68/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7864 - loss: 0.9563\n","Epoch 69/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7870 - loss: 0.9330\n","Epoch 70/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7975 - loss: 0.8928\n","Epoch 71/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8031 - loss: 0.8663\n","Epoch 72/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8098 - loss: 0.8331\n","Epoch 73/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8186 - loss: 0.8127\n","Epoch 74/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8197 - loss: 0.7919\n","Epoch 75/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8307 - loss: 0.7640\n","Epoch 76/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8371 - loss: 0.7249\n","Epoch 77/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8389 - loss: 0.7165\n","Epoch 78/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8374 - loss: 0.7062\n","Epoch 79/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8480 - loss: 0.6826\n","Epoch 80/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8499 - loss: 0.6580\n","Epoch 81/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8591 - loss: 0.6348\n","Epoch 82/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8572 - loss: 0.6243\n","Epoch 83/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8544 - loss: 0.6302\n","Epoch 84/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8718 - loss: 0.5761\n","Epoch 85/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8769 - loss: 0.5628\n","Epoch 86/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8794 - loss: 0.5497\n","Epoch 87/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8856 - loss: 0.5265\n","Epoch 88/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8841 - loss: 0.5278\n","Epoch 89/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8899 - loss: 0.5135\n","Epoch 90/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8961 - loss: 0.4902\n","Epoch 91/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8995 - loss: 0.4802\n","Epoch 92/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9012 - loss: 0.4752\n","Epoch 93/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9002 - loss: 0.4661\n","Epoch 94/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9040 - loss: 0.4501\n","Epoch 95/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9044 - loss: 0.4426\n","Epoch 96/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4267\n","Epoch 97/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9078 - loss: 0.4290\n","Epoch 98/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9162 - loss: 0.4060\n","Epoch 99/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9153 - loss: 0.4110\n","Epoch 100/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9150 - loss: 0.3997\n","Epoch 101/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9128 - loss: 0.3956\n","Epoch 102/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9201 - loss: 0.3799\n","Epoch 103/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9181 - loss: 0.3857\n","Epoch 104/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9229 - loss: 0.3686\n","Epoch 105/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9207 - loss: 0.3722\n","Epoch 106/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9205 - loss: 0.3691\n","Epoch 107/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9224 - loss: 0.3598\n","Epoch 108/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9192 - loss: 0.3749\n","Epoch 109/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9169 - loss: 0.3695\n","Epoch 110/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9216 - loss: 0.3589\n","Epoch 111/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9261 - loss: 0.3511\n","Epoch 112/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9259 - loss: 0.3429\n","Epoch 113/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9261 - loss: 0.3330\n","Epoch 114/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9312 - loss: 0.3276\n","Epoch 115/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9305 - loss: 0.3248\n","Epoch 116/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9313 - loss: 0.3194\n","Epoch 117/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9318 - loss: 0.3113\n","Epoch 118/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9378 - loss: 0.3025\n","Epoch 119/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9345 - loss: 0.3066\n","Epoch 120/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9346 - loss: 0.3020\n","Epoch 121/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9371 - loss: 0.2979\n","Epoch 122/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9370 - loss: 0.2925\n","Epoch 123/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9349 - loss: 0.2868\n","Epoch 124/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9372 - loss: 0.2851\n","Epoch 125/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9391 - loss: 0.2714\n","Epoch 126/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9391 - loss: 0.2725\n","Epoch 127/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9388 - loss: 0.2690\n","Epoch 128/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9374 - loss: 0.2730\n","Epoch 129/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9405 - loss: 0.2590\n","Epoch 130/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9376 - loss: 0.2652\n","Epoch 131/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9408 - loss: 0.2582\n","Epoch 132/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9393 - loss: 0.2581\n","Epoch 133/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9423 - loss: 0.2512\n","Epoch 134/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9403 - loss: 0.2548\n","Epoch 135/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9403 - loss: 0.2500\n","Epoch 136/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9393 - loss: 0.2488\n","Epoch 137/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9401 - loss: 0.2479\n","Epoch 138/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9418 - loss: 0.2466\n","Epoch 139/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9397 - loss: 0.2449\n","Epoch 140/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9400 - loss: 0.2437\n","Epoch 141/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9418 - loss: 0.2379\n","Epoch 142/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9418 - loss: 0.2383\n","Epoch 143/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9438 - loss: 0.2337\n","Epoch 144/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9425 - loss: 0.2334\n","Epoch 145/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9430 - loss: 0.2277\n","Epoch 146/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9431 - loss: 0.2301\n","Epoch 147/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9438 - loss: 0.2250\n","Epoch 148/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9418 - loss: 0.2258\n","Epoch 149/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9431 - loss: 0.2236\n","Epoch 150/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9418 - loss: 0.2286\n","Epoch 151/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9414 - loss: 0.2249\n","Epoch 152/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9431 - loss: 0.2194\n","Epoch 153/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9445 - loss: 0.2188\n","Epoch 154/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9447 - loss: 0.2195\n","Epoch 155/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9431 - loss: 0.2181\n","Epoch 156/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9431 - loss: 0.2152\n","Epoch 157/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9417 - loss: 0.2197\n","Epoch 158/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9433 - loss: 0.2132\n","Epoch 159/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9431 - loss: 0.2128\n","Epoch 160/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9446 - loss: 0.2080\n","Epoch 161/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9441 - loss: 0.2126\n","Epoch 162/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9455 - loss: 0.2064\n","Epoch 163/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9457 - loss: 0.2062\n","Epoch 164/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9457 - loss: 0.2033\n","Epoch 165/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9414 - loss: 0.2117\n","Epoch 166/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9461 - loss: 0.2028\n","Epoch 167/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9429 - loss: 0.2094\n","Epoch 168/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9460 - loss: 0.2021\n","Epoch 169/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9458 - loss: 0.1964\n","Epoch 170/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9453 - loss: 0.1987\n","Epoch 171/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9440 - loss: 0.2034\n","Epoch 172/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9447 - loss: 0.1969\n","Epoch 173/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9435 - loss: 0.2012\n","Epoch 174/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9436 - loss: 0.1978\n","Epoch 175/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9427 - loss: 0.1958\n","Epoch 176/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9437 - loss: 0.1952\n","Epoch 177/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9482 - loss: 0.1947\n","Epoch 178/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9439 - loss: 0.1983\n","Epoch 179/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9466 - loss: 0.1914\n","Epoch 180/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9439 - loss: 0.1969\n","Epoch 181/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9465 - loss: 0.1907\n","Epoch 182/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9466 - loss: 0.1871\n","Epoch 183/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9419 - loss: 0.1974\n","Epoch 184/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9441 - loss: 0.1954\n","Epoch 185/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9444 - loss: 0.1939\n","Epoch 186/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9461 - loss: 0.1922\n","Epoch 187/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9445 - loss: 0.1887\n","Epoch 188/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9432 - loss: 0.1943\n","Epoch 189/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9427 - loss: 0.1919\n","Epoch 190/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9449 - loss: 0.1917\n","Epoch 191/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9415 - loss: 0.1926\n","Epoch 192/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9473 - loss: 0.1844\n","Epoch 193/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9457 - loss: 0.1890\n","Epoch 194/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9436 - loss: 0.1927\n","Epoch 195/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9451 - loss: 0.1863\n","Epoch 196/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9447 - loss: 0.1891\n","Epoch 197/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9434 - loss: 0.1868\n","Epoch 198/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9441 - loss: 0.1914\n","Epoch 199/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9438 - loss: 0.1860\n","Epoch 200/200\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9422 - loss: 0.1926\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7d8ed9e655d0>"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["[decoder([int(u.argmax())]) for u in  model.predict(np.array([X[0]]))[0]]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NIcFoFIdglFW","executionInfo":{"status":"ok","timestamp":1747396858744,"user_tz":-120,"elapsed":205,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}},"outputId":"118fcdbd-cede-434b-dea6-540c1f27caa8"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["[['comment'],\n"," ['allez'],\n"," ['tu'],\n"," [],\n"," [],\n"," [],\n"," [],\n"," [],\n"," [],\n"," [],\n"," [],\n"," [],\n"," [],\n"," [],\n"," ['aujourd’hui']]"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["# Prediction\n","model.predict(X[0:1])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2jbLT_4Ih_eG","executionInfo":{"status":"ok","timestamp":1747396868423,"user_tz":-120,"elapsed":114,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}},"outputId":"ef147d63-27ba-481b-bb07-5049bece5d78"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[[1.3465857e-08, 2.7935870e-03, 3.8191179e-06, ...,\n","         1.4138608e-08, 2.9719756e-08, 2.3972358e-08],\n","        [1.5297674e-08, 3.0216723e-04, 1.4676792e-08, ...,\n","         2.3775694e-17, 1.2588710e-08, 3.5339863e-08],\n","        [1.1889202e-02, 5.6887726e-09, 3.5658886e-13, ...,\n","         7.0685011e-27, 6.0435774e-08, 1.0100800e-07],\n","        ...,\n","        [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n","         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n","        [9.9888164e-01, 0.0000000e+00, 0.0000000e+00, ...,\n","         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n","        [6.5453709e-16, 1.4817241e-27, 0.0000000e+00, ...,\n","         0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]], dtype=float32)"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["decoder([int(u.argmax()) for u in model.predict(X[:1])[0]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4k5wWfI9a7Wg","outputId":"05bc018a-73d3-47d2-c7ee-8d6e9204b39d","executionInfo":{"status":"ok","timestamp":1747396871074,"user_tz":-120,"elapsed":96,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}}},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["['comment', 'allez', 'tu', 'aujourd’hui']"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["model.predict(X[:1])[0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fZwG2numSIGE","outputId":"73d32ff2-79c5-4f00-80db-06e82e8be33b","executionInfo":{"status":"ok","timestamp":1747396877671,"user_tz":-120,"elapsed":97,"user":{"displayName":"Ahmat Adam","userId":"01498063049773447284"}}},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["(15, 1080)"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":[],"metadata":{"id":"Cn7mGYJxYclT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZAyL9_52YciL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Consignes du Projet : Prédiction du Token Suivant dans un Corpus de Texte**\n","\n","---\n","\n","#### **Objectif du Projet**  \n","L'objectif de ce projet est d'entraîner un modèle de deep learning capable de **prédire un token aléatoire dans une phrase**, et non plus seulement le dernier mot d'une phrase.  \n","\n","---\n","\n","#### **Données et Prétraitement**  \n","\n","Le corpus utilisé est récupéré à partir d'un fichier texte brut disponible en ligne via :  \n","📄 **URL du corpus** : [Lien du fichier](https://raw.githubusercontent.com/Quera-fr/YOLO-DATASET/refs/heads/main/corpus.txt)\n","\n","##### **1️⃣ Chargement et Nettoyage des Données**\n","- **Téléchargement** du corpus et conversion en **minuscule**.\n","- **Tokenization** des phrases en utilisant un moteur NLP.\n","- **Création d’un vocabulaire** : une liste unique des tokens présents dans le corpus.\n","\n","##### **2️⃣ Modification du Pipeline de Feature Engineering**\n","👉 **Changement par rapport au code initial** :  \n","- **Au lieu de toujours prédire le dernier mot de la phrase**, on sélectionne **un token aléatoire** dans chaque phrase.\n","- La phrase est tronquée à cet endroit.\n","- **Padding** est ajouté pour uniformiser la longueur des séquences.\n","\n","##### **3️⃣ Construction du Jeu de Données**\n","- **Features (`X`)** : Partie de la phrase avant le token sélectionné, **remplie avec du padding** si nécessaire.  \n","- **Target (`y`)** : Le **token suivant aléatoire**, retiré de la phrase.\n","\n","---\n","\n","#### **Pipeline d'Entraînement**\n","1️⃣ **Prétraitement**  \n","   - Récupération des données et tokenization  \n","   - Construction du vocabulaire et conversion en indices numériques  \n","   - Sélection aléatoire du token cible et **création des séquences** avec padding  \n","\n","2️⃣ **Modélisation**  \n","   - Création d’un **modèle RNN/LSTM** avec une couche `Embedding` pour gérer le vocabulaire.  \n","   - Ajout d’une **couche LSTM** récurrente pour apprendre le contexte des tokens.  \n","   - Une **couche Dense softmax** pour prédire le token suivant parmi le vocabulaire.\n","\n","3️⃣ **Entraînement et Évaluation**  \n","   - Compilation avec **Adam** et une fonction de perte **categorical cross-entropy**.  \n","   - Vérification de la **performance du modèle** (perplexité, précision).  \n","   - Visualisation des prédictions sur un sous-ensemble de phrases du corpus.\n"],"metadata":{"id":"VjNeB0aLZ0Nc"}},{"cell_type":"code","source":["data = pd.DataFrame(tokens)\n","data[16] = 0"],"metadata":{"id":"nmFsDptClksv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"id":"9vkLqi3Nseh6","executionInfo":{"status":"ok","timestamp":1745328664520,"user_tz":-120,"elapsed":55,"user":{"displayName":"Kévin Duranty","userId":"17936416485008719452"}},"outputId":"ef1b5384-5e94-465a-831b-30c6a5603cad"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       0     1    2    3      4       5      6       7       8      9      10  \\\n","0     138   215  980  969   94.0     NaN    NaN     NaN     NaN    NaN    NaN   \n","1     577   726  942   28  771.0   514.0  912.0   805.0     NaN    NaN    NaN   \n","2     621    41   93  569   17.0   296.0  557.0   447.0     NaN    NaN    NaN   \n","3     359   276  974  473   93.0   194.0  726.0   558.0    55.0  288.0  862.0   \n","4     534   184  325  917  534.0   156.0  363.0   844.0   327.0    NaN    NaN   \n","..    ...   ...  ...  ...    ...     ...    ...     ...     ...    ...    ...   \n","356   881  1011  113  127  288.0   790.0  784.0   160.0   889.0  514.0  912.0   \n","357   835   363  250  394  324.0   586.0  288.0  1007.0   625.0    NaN    NaN   \n","358   514  1011  382  951  590.0  1063.0  724.0     NaN     NaN    NaN    NaN   \n","359   514  1011  898  975  578.0   524.0  819.0   288.0   137.0    NaN    NaN   \n","360  1029   968  996  394  740.0   129.0  886.0   288.0  1011.0    NaN    NaN   \n","\n","        11  12  13  14  15  16  \n","0      NaN NaN NaN NaN NaN   0  \n","1      NaN NaN NaN NaN NaN   0  \n","2      NaN NaN NaN NaN NaN   0  \n","3    920.0 NaN NaN NaN NaN   0  \n","4      NaN NaN NaN NaN NaN   0  \n","..     ...  ..  ..  ..  ..  ..  \n","356  555.0 NaN NaN NaN NaN   0  \n","357    NaN NaN NaN NaN NaN   0  \n","358    NaN NaN NaN NaN NaN   0  \n","359    NaN NaN NaN NaN NaN   0  \n","360    NaN NaN NaN NaN NaN   0  \n","\n","[361 rows x 17 columns]"],"text/html":["\n","  <div id=\"df-3bbd890f-0c7d-4075-af8d-b10444815738\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>138</td>\n","      <td>215</td>\n","      <td>980</td>\n","      <td>969</td>\n","      <td>94.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>577</td>\n","      <td>726</td>\n","      <td>942</td>\n","      <td>28</td>\n","      <td>771.0</td>\n","      <td>514.0</td>\n","      <td>912.0</td>\n","      <td>805.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>621</td>\n","      <td>41</td>\n","      <td>93</td>\n","      <td>569</td>\n","      <td>17.0</td>\n","      <td>296.0</td>\n","      <td>557.0</td>\n","      <td>447.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>359</td>\n","      <td>276</td>\n","      <td>974</td>\n","      <td>473</td>\n","      <td>93.0</td>\n","      <td>194.0</td>\n","      <td>726.0</td>\n","      <td>558.0</td>\n","      <td>55.0</td>\n","      <td>288.0</td>\n","      <td>862.0</td>\n","      <td>920.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>534</td>\n","      <td>184</td>\n","      <td>325</td>\n","      <td>917</td>\n","      <td>534.0</td>\n","      <td>156.0</td>\n","      <td>363.0</td>\n","      <td>844.0</td>\n","      <td>327.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>356</th>\n","      <td>881</td>\n","      <td>1011</td>\n","      <td>113</td>\n","      <td>127</td>\n","      <td>288.0</td>\n","      <td>790.0</td>\n","      <td>784.0</td>\n","      <td>160.0</td>\n","      <td>889.0</td>\n","      <td>514.0</td>\n","      <td>912.0</td>\n","      <td>555.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>357</th>\n","      <td>835</td>\n","      <td>363</td>\n","      <td>250</td>\n","      <td>394</td>\n","      <td>324.0</td>\n","      <td>586.0</td>\n","      <td>288.0</td>\n","      <td>1007.0</td>\n","      <td>625.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>358</th>\n","      <td>514</td>\n","      <td>1011</td>\n","      <td>382</td>\n","      <td>951</td>\n","      <td>590.0</td>\n","      <td>1063.0</td>\n","      <td>724.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>359</th>\n","      <td>514</td>\n","      <td>1011</td>\n","      <td>898</td>\n","      <td>975</td>\n","      <td>578.0</td>\n","      <td>524.0</td>\n","      <td>819.0</td>\n","      <td>288.0</td>\n","      <td>137.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>360</th>\n","      <td>1029</td>\n","      <td>968</td>\n","      <td>996</td>\n","      <td>394</td>\n","      <td>740.0</td>\n","      <td>129.0</td>\n","      <td>886.0</td>\n","      <td>288.0</td>\n","      <td>1011.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>361 rows × 17 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3bbd890f-0c7d-4075-af8d-b10444815738')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3bbd890f-0c7d-4075-af8d-b10444815738 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3bbd890f-0c7d-4075-af8d-b10444815738');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ef3fb72e-b37e-47d8-9734-f0c28d7d32a1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ef3fb72e-b37e-47d8-9734-f0c28d7d32a1')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ef3fb72e-b37e-47d8-9734-f0c28d7d32a1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_50fbfbf0-ef69-4c8a-8289-6acd2e262efd\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_50fbfbf0-ef69-4c8a-8289-6acd2e262efd button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('data');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data","summary":"{\n  \"name\": \"data\",\n  \"rows\": 361,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 233,\n        \"min\": 15,\n        \"max\": 1051,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          244,\n          1049,\n          403\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 371,\n        \"min\": 1,\n        \"max\": 1077,\n        \"num_unique_values\": 237,\n        \"samples\": [\n          188,\n          1015,\n          274\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 369,\n        \"min\": 1,\n        \"max\": 1078,\n        \"num_unique_values\": 134,\n        \"samples\": [\n          110,\n          365,\n          572\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 285,\n        \"min\": 1,\n        \"max\": 1074,\n        \"num_unique_values\": 190,\n        \"samples\": [\n          475,\n          691,\n          109\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 286.80041368159715,\n        \"min\": 1.0,\n        \"max\": 1079.0,\n        \"num_unique_values\": 194,\n        \"samples\": [\n          579.0,\n          326.0,\n          139.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 293.05892445901674,\n        \"min\": 14.0,\n        \"max\": 1074.0,\n        \"num_unique_values\": 194,\n        \"samples\": [\n          526.0,\n          894.0,\n          253.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 6,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 301.32243475984524,\n        \"min\": 1.0,\n        \"max\": 1079.0,\n        \"num_unique_values\": 192,\n        \"samples\": [\n          826.0,\n          710.0,\n          750.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 7,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 322.3800547752589,\n        \"min\": 9.0,\n        \"max\": 1078.0,\n        \"num_unique_values\": 188,\n        \"samples\": [\n          366.0,\n          290.0,\n          356.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 8,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 293.98182768310505,\n        \"min\": 6.0,\n        \"max\": 1066.0,\n        \"num_unique_values\": 142,\n        \"samples\": [\n          113.0,\n          579.0,\n          296.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 9,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 312.1830242568852,\n        \"min\": 1.0,\n        \"max\": 1078.0,\n        \"num_unique_values\": 105,\n        \"samples\": [\n          3.0,\n          840.0,\n          66.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 10,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 296.25453583025524,\n        \"min\": 5.0,\n        \"max\": 1073.0,\n        \"num_unique_values\": 64,\n        \"samples\": [\n          110.0,\n          1029.0,\n          862.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 11,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 309.375022847522,\n        \"min\": 17.0,\n        \"max\": 1071.0,\n        \"num_unique_values\": 40,\n        \"samples\": [\n          1027.0,\n          745.0,\n          956.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 12,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 296.0334601422777,\n        \"min\": 9.0,\n        \"max\": 981.0,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          559.0,\n          839.0,\n          212.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 13,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 344.6723001714738,\n        \"min\": 56.0,\n        \"max\": 1075.0,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          133.0,\n          420.0,\n          688.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 14,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 360.3903439327974,\n        \"min\": 57.0,\n        \"max\": 889.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          57.0,\n          889.0,\n          356.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 15,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 57.0,\n        \"max\": 57.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          57.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 16,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":83}]},{"cell_type":"code","source":["# Premier document\n","tokens[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e89LWvbjl5Mt","executionInfo":{"status":"ok","timestamp":1745333111690,"user_tz":-120,"elapsed":19,"user":{"displayName":"Kévin Duranty","userId":"17936416485008719452"}},"outputId":"6d15bba5-9b89-4cc5-d7d5-797fed7c8daa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[138, 215, 980, 969, 94]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Index aléatoire\n","random_index = random.randint(1, len(tokens[0]))\n","random_index"],"metadata":{"id":"2GzxPCxP3pjU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Target aléatoire\n","target = tokens[0][random_index]\n","target"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A_lCNfNcl8TH","executionInfo":{"status":"ok","timestamp":1745330844393,"user_tz":-120,"elapsed":11,"user":{"displayName":"Kévin Duranty","userId":"17936416485008719452"}},"outputId":"1ebf4430-5dd7-4b04-9187-720ec4484ccf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["969"]},"metadata":{},"execution_count":86}]},{"cell_type":"code","source":["# Features sans la target\n","features = tokens[0][:random_index]\n","features"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m9QKfHVSmMEw","executionInfo":{"status":"ok","timestamp":1745330866231,"user_tz":-120,"elapsed":12,"user":{"displayName":"Kévin Duranty","userId":"17936416485008719452"}},"outputId":"a8046f52-abd5-43ad-e00c-c49766f42a36"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[138, 215, 980]"]},"metadata":{},"execution_count":87}]},{"cell_type":"code","source":["tokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"DIwS4Ynal8Qs","executionInfo":{"status":"ok","timestamp":1745327861276,"user_tz":-120,"elapsed":47,"user":{"displayName":"Kévin Duranty","userId":"17936416485008719452"}},"outputId":"9049cb53-9cff-411c-856c-49c13702756f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[138, 215, 980, 969, 94],\n"," [577, 726, 942, 28, 771, 514, 912, 805],\n"," [621, 41, 93, 569, 17, 296, 557, 447],\n"," [359, 276, 974, 473, 93, 194, 726, 558, 55, 288, 862, 920],\n"," [534, 184, 325, 917, 534, 156, 363, 844, 327],\n"," [487, 961, 917, 974, 761, 490, 726, 894, 379],\n"," [621, 814, 534, 259, 288, 890, 291, 527, 933],\n"," [969, 544, 974, 547, 678, 917, 558, 481, 52],\n"," [488, 518, 93, 442, 284, 534, 657, 109, 541, 46],\n"," [526, 1052, 975, 538, 1029, 590, 257, 1071],\n"," [527, 1004, 845, 799, 917, 558, 102],\n"," [534, 982, 897, 445, 284, 537, 76, 363, 101],\n"," [621, 117, 995, 974, 600, 356, 82, 585, 480],\n"," [359, 285, 464, 917, 527, 872, 330, 937],\n"," [969, 1047, 288, 527, 599, 207, 726, 928, 354],\n"," [488, 1015, 904, 1029, 558, 1071, 726, 341, 288, 625, 280],\n"," [514, 773, 974, 153, 185, 726, 129, 213, 527, 524],\n"," [534, 152, 325, 653, 284, 894, 126],\n"," [621, 418, 330, 1023, 534, 550, 288, 527, 841],\n"," [359, 177, 975, 173, 326, 726, 369, 894, 370],\n"," [969, 84, 18, 330, 652, 1029, 527, 144, 160, 571],\n"," [487, 299, 974, 682, 560, 109, 296, 273, 288, 260],\n"," [621, 67, 975, 624, 532, 374, 558, 56, 748],\n"," [359, 516, 330, 700, 182, 887, 108, 356, 39, 873, 259],\n"," [969, 266, 974, 566, 534, 588, 747],\n"," [488, 808, 537, 1070, 284, 534, 204, 345, 480, 887],\n"," [514, 243, 975, 561, 363, 135, 93, 141, 330, 528],\n"," [534, 750, 406, 527, 542, 109, 680, 394, 205],\n"," [621, 1048, 91, 558, 481, 794, 655, 619, 467],\n"," [359, 685, 975, 449, 597, 284, 894, 87],\n"," [969, 1055, 947, 296, 732, 783, 969, 1068, 370],\n"," [488, 670, 363, 1012, 74, 541, 396],\n"," [514, 417, 904, 330, 155, 363, 1074, 109, 579, 271],\n"," [534, 415, 60, 975, 538, 289, 571],\n"," [621, 115, 975, 315, 508, 917, 527, 697],\n"," [359, 992, 661, 687, 537, 979],\n"," [969, 106, 346, 463, 160, 710, 108, 94],\n"," [488, 568, 917, 527, 704, 93, 259, 330, 890],\n"," [526, 106, 647, 590, 656, 1029, 527, 561],\n"," [534, 193, 520, 284, 534, 513, 951, 527, 524],\n"," [621, 67, 537, 848, 288, 465, 363, 269],\n"," [359, 435, 894, 297, 553, 636, 558, 9, 58],\n"," [969, 811, 160, 433, 109, 621, 289, 887],\n"," [488, 852, 527, 1004, 783, 527, 715, 9, 214],\n"," [514, 614, 284, 527, 701, 687, 537, 979],\n"," [534, 982, 896, 445, 480, 887, 687, 558, 640],\n"," [621, 115, 947, 861, 288, 416, 534, 948, 330, 591],\n"," [359, 170, 288, 958, 1029, 527, 434, 330, 588],\n"," [969, 545, 974, 547, 783, 534, 971, 9, 895],\n"," [488, 68, 1029, 754, 363, 780, 165, 56],\n"," [514, 277, 974, 710, 953, 726, 579, 46],\n"," [534, 603, 397, 534, 681, 109, 90],\n"," [621, 985, 974, 430, 356, 83, 1029, 527, 456, 615],\n"," [359, 722, 975, 788, 306, 1029, 894, 750],\n"," [969, 1050, 975, 319, 917, 160, 915, 289],\n"," [488, 959, 927, 726, 931, 540, 761],\n"," [514, 737, 974, 114, 726, 549, 527, 876, 748],\n"," [534, 890, 148, 445, 164, 75],\n"," [621, 67, 1029, 519, 356, 974, 505, 288, 599],\n"," [359, 176, 284, 527, 200, 288, 558, 1038],\n"," [969, 563, 296, 451, 74, 534, 826],\n"," [488, 89, 534, 150, 902, 527, 715],\n"," [514, 993, 974, 202, 604, 687, 537, 979],\n"," [534, 184, 869, 917, 527, 923, 726, 92, 527, 620],\n"," [621, 521, 105, 1034, 160, 1026, 1, 367],\n"," [359, 1013, 904, 363, 955, 726, 39, 1000, 880, 659],\n"," [969, 1044, 527, 795, 687, 784, 969, 278],\n"," [488, 245, 975, 128, 726, 527, 990],\n"," [514, 853, 590, 1023, 783, 969, 385, 80],\n"," [534, 982, 60, 288, 527, 448, 164, 1074],\n"," [621, 567, 374, 284, 527, 446],\n"," [359, 966, 975, 1033, 726, 894, 452],\n"," [969, 811, 537, 1070, 109, 974, 970],\n"," [488, 708, 296, 76, 284, 534, 657, 596],\n"," [514, 612, 368, 904, 363, 1040, 288, 527, 599],\n"," [534, 750, 373, 975, 624, 542, 289],\n"," [621, 543, 974, 843, 158, 363, 206],\n"," [359, 921, 476, 1060, 726, 527, 888],\n"," [969, 65, 1029, 231, 332, 784, 969, 97, 558, 1030],\n"," [488, 263, 284, 534, 907, 551, 288, 558, 377],\n"," [514, 178, 1029, 527, 456, 288, 558, 1038],\n"," [534, 193, 11, 783, 787, 974, 70, 288, 527, 561],\n"," [621, 287, 951, 527, 628, 551, 330, 570],\n"," [359, 516, 288, 527, 472, 284, 974, 470, 288, 599],\n"," [969, 664, 53, 264, 74, 717, 57, 288, 733],\n"," [488, 1054, 296, 539, 1029, 541, 46, 548],\n"," [514, 782, 284, 527, 841, 687, 558, 1074],\n"," [534, 890, 873, 258, 536, 295, 537, 593],\n"," [621, 67, 537, 120, 288, 527, 698, 363, 269],\n"," [359, 298, 296, 721, 288, 880, 46],\n"," [969, 414, 974, 162, 1, 1005, 109, 330, 654, 210],\n"," [488, 335, 527, 561, 726, 626],\n"," [514, 810, 974, 321, 917, 527, 616, 160, 887],\n"," [534, 982, 896, 363, 796, 769, 288, 527, 281],\n"," [621, 798, 296, 256, 917, 527, 704],\n"," [359, 849, 974, 731, 301, 951, 527, 206],\n"," [969, 219, 581, 165, 542, 74, 527, 859],\n"," [488, 32, 1029, 527, 241, 356, 975, 1038, 363, 24],\n"," [514, 1018, 1029, 965, 558, 395, 363, 955],\n"," [534, 184, 183, 975, 901, 284, 534, 513],\n"," [621, 67, 527, 272, 109, 619, 467],\n"," [359, 405, 534, 745, 363, 351],\n"," [969, 806, 165, 605, 489],\n"," [488, 684, 537, 598, 288, 540, 624, 561],\n"," [514, 720, 974, 565, 185, 363, 483],\n"," [534, 415, 546, 534, 267, 182, 571],\n"," [621, 1045, 974, 229, 363, 712, 36],\n"," [359, 792, 975, 481, 329, 726, 354, 558, 88],\n"," [969, 197, 974, 547, 284, 527, 128],\n"," [488, 613, 284, 527, 576, 902, 974, 121, 890],\n"," [514, 993, 534, 600, 356, 82, 252, 289],\n"," [534, 982, 119, 537, 431, 594, 917, 527, 846],\n"," [621, 67, 1029, 519, 93, 930, 164, 1074],\n"," [359, 336, 534, 473, 109, 288, 527, 275, 181],\n"," [969, 822, 288, 625, 692, 1029, 165, 234],\n"," [488, 174, 363, 203, 551, 330, 429],\n"," [514, 572, 764, 93, 141, 330, 438, 93, 743],\n"," [534, 143, 772, 330, 652, 447, 182, 571],\n"," [621, 812, 974, 433, 363, 422, 311, 887],\n"," [359, 20, 537, 1070, 284, 534, 204, 345],\n"," [969, 65, 1029, 286, 109, 974, 750],\n"," [488, 386, 975, 592, 363, 1074],\n"," [514, 707, 296, 437, 284, 590, 513, 93, 743],\n"," [534, 279, 772, 974, 826, 460, 726, 880, 509],\n"," [621, 31, 618, 1003, 1029, 348],\n"," [359, 270, 975, 842, 726, 558, 1074],\n"," [969, 72, 160, 906, 288, 285, 954],\n"," [488, 631, 537, 635, 109, 296, 525],\n"," [514, 243, 974, 580, 363, 135, 109, 590, 781],\n"," [534, 686, 38, 537, 294, 945, 1029, 894, 924],\n"," [621, 994, 974, 1028, 726, 1000, 537, 54, 870],\n"," [514, 221, 660, 165, 885, 394, 526, 1027, 850, 365],\n"," [221, 1, 969, 160, 784, 514, 988, 313, 642, 322, 5, 807, 559, 688],\n"," [617, 218, 1, 969, 672, 346, 165, 847, 108, 356, 79, 485],\n"," [621, 304, 66, 1029, 1043, 537, 104, 109, 90],\n"," [305, 6, 1022, 914, 165, 847, 642, 728, 6, 558, 19],\n"," [617, 303, 6, 672, 1078, 346, 671, 108, 784, 527, 628, 941],\n"," [359, 188, 975, 892, 357, 726, 854, 160, 745],\n"," [190, 7, 2, 974, 622, 958, 74, 116, 932, 880, 1073],\n"," [629, 96, 2, 672, 346, 967, 974, 360, 881, 359, 107, 581, 775, 894, 381],\n"," [969, 1001, 534, 890, 789, 873, 556, 295, 537, 593],\n"," [983, 1, 969, 165, 872, 309, 881, 969, 235, 951, 558, 481],\n"," [617, 1019, 1, 969, 672, 346, 537, 882, 108, 791, 488, 617, 302, 1075],\n"," [487, 249, 974, 12, 726, 768, 880, 54, 330, 450],\n"," [242, 7, 3, 975, 624, 561, 642, 851, 7, 3, 161],\n"," [617, 248, 3, 672, 346, 786, 201, 356, 103, 108, 160, 761],\n"," [621, 392, 974, 110, 573, 726, 949, 537, 695, 330, 591],\n"," [390, 8, 1022, 784, 165, 885, 921, 50, 799],\n"," [629, 391, 8, 672, 875, 974, 103, 855, 288, 165, 412],\n"," [488, 265, 182, 571, 726, 458, 527, 443, 394, 834, 363, 139, 867],\n"," [268, 4, 365, 558, 483, 747, 562, 534, 450, 462],\n"," [617, 263, 4, 672, 716, 904, 108, 784, 540, 360, 330, 929, 617, 168],\n"," [514, 177, 284, 975, 200, 949, 537, 312, 109, 375],\n"," [179, 1, 969, 301, 950, 534, 778, 551, 330, 906, 288, 434, 356, 56],\n"," [617, 175, 1, 969, 672, 346, 165, 173, 552, 621, 1069, 371],\n"," [969, 198, 947, 537, 575, 300, 726, 1016],\n"," [196, 1, 969, 975, 103, 639, 881, 161, 617, 440, 672],\n"," [617, 199, 1, 969, 672, 918, 537, 611, 261, 95],\n"," [359, 1053, 975, 538, 1029, 894, 45, 667, 998, 1029, 558, 1071],\n"," [1049, 7, 2, 974, 547, 974, 522, 726, 793, 894, 495, 111],\n"," [629, 1056, 2, 672, 346, 288, 694, 482, 284, 894, 523, 507],\n"," [621, 1021, 537, 1070, 149, 284, 534, 204, 345, 165, 628],\n"," [985, 6, 974, 522, 975, 103, 709, 477, 284, 558, 976],\n"," [617, 1020, 6, 672, 346, 537, 735, 496, 288, 165, 338],\n"," [488, 741, 296, 334, 491, 726, 540, 379, 182, 522],\n"," [739, 4, 363, 225, 952, 537, 911, 296, 361, 108, 288, 956],\n"," [617, 736, 4, 672, 346, 163, 770, 108, 558, 81, 330, 745],\n"," [514, 961, 109, 677, 917, 182, 761, 784, 526, 378],\n"," [963, 1, 969, 109, 586, 917, 160, 622, 761, 44],\n"," [617, 960, 1, 969, 672, 346, 917, 974, 915, 883, 95],\n"," [969, 33, 904, 935, 46, 553, 488, 637, 127, 288, 940],\n"," [30, 1, 969, 942, 1002, 1029, 348, 160, 1026, 1, 367],\n"," [629, 27, 1, 969, 672, 346, 787, 974, 356, 103, 108, 288, 981, 485],\n"," [359, 63, 288, 625, 227, 726, 1076, 284, 894, 609],\n"," [64, 7, 2, 716, 996, 881, 359, 913, 296, 269, 916],\n"," [629, 61, 2, 672, 346, 165, 532, 108, 288, 348],\n"," [621, 223, 581, 165, 746, 74, 717, 404],\n"," [220, 6, 974, 522, 949, 537, 601, 288, 558, 976],\n"," [617, 222, 6, 672, 346, 160, 228, 108, 791, 487, 617, 889, 407],\n"," [488, 340, 288, 625, 280, 363, 1014, 1029, 965, 534, 591],\n"," [342, 4, 130, 975, 1079, 365, 494],\n"," [617, 339, 4, 672, 346, 296, 496, 917, 160, 699, 487, 1027, 9, 296, 57],\n"," [514, 188, 240, 296, 893, 105, 344, 784, 514, 820],\n"," [191, 1, 969, 975, 624, 638, 751, 130],\n"," [617, 187, 1, 969, 672, 346, 975, 43, 108, 288, 195, 165, 639],\n"," [969, 135, 947, 974, 153, 108, 288, 213, 922, 524],\n"," [134, 1, 969, 330, 936, 1029, 527, 703, 881, 514, 973, 363, 773, 974],\n"," [617, 151, 1, 969, 672, 718, 330, 194, 185, 783, 621, 1069, 371],\n"," [359, 649, 527, 719, 726, 530, 380, 527, 554, 330, 522],\n"," [650, 7, 2, 894, 766, 216, 974, 522],\n"," [629, 648, 2, 672, 947, 527, 423, 182, 571, 95],\n"," [621, 1058, 374, 975, 481, 713, 356, 112, 394, 288, 802],\n"," [1051, 6, 974, 522, 974, 547, 789, 501, 296, 582, 288, 535],\n"," [629, 1057, 6, 672, 346, 974, 761, 883, 558, 51, 292],\n"," [488, 663, 717, 533, 394, 217, 37, 109, 537, 1072],\n"," [665, 4, 130, 975, 624, 532, 726, 540, 958],\n"," [617, 662, 4, 672, 346, 264, 388, 108, 356, 66, 558, 511],\n"," [514,\n","  830,\n","  975,\n","  468,\n","  515,\n","  1029,\n","  558,\n","  486,\n","  288,\n","  840,\n","  579,\n","  46,\n","  74,\n","  926,\n","  356,\n","  57],\n"," [832, 1, 969, 527, 610, 1062, 552, 969, 838, 922, 422],\n"," [617, 831, 1, 969, 672, 346, 165, 400, 108, 610, 356, 17, 942, 133],\n"," [969, 645, 904, 651, 969, 84, 583, 935, 23],\n"," [644, 1, 969, 365, 942, 863, 289, 571],\n"," [629, 643, 1, 969, 672, 346, 935, 209, 182, 876, 95],\n"," [359, 1012, 904, 726, 341, 288, 623, 683],\n"," [1017, 7, 2, 974, 522, 284, 558, 387],\n"," [617, 1013, 2, 672, 346, 904, 108, 288, 921, 502, 485],\n"," [621, 169, 618, 478, 726, 21, 974, 584, 288, 989, 716, 864],\n"," [171, 6, 974, 522, 944, 619, 564, 288, 239],\n"," [617, 172, 6, 672, 346, 758, 108, 165, 744, 288, 237],\n"," [488, 809, 537, 627, 343, 284, 534, 204, 109, 1061],\n"," [813, 4, 974, 433, 160, 887, 374],\n"," [617, 808, 4, 672, 346, 165, 919, 527, 876, 293],\n"," [514, 246, 974, 761, 44, 109, 590, 1067],\n"," [244, 1, 969, 974, 522, 527, 561, 288, 935, 860],\n"," [617, 247, 1, 969, 672, 346, 974, 706, 108, 288, 213, 160, 180],\n"," [969, 427, 947, 527, 719, 1029, 208, 108, 288, 669],\n"," [426, 8, 527, 145, 716, 972, 94],\n"," [617, 425, 4, 672, 346, 527, 423, 108, 784, 527, 715, 617, 212],\n"," [359, 773, 974, 826, 347, 726, 951, 862, 422],\n"," [774, 7, 2, 974, 428, 726, 537, 457, 288, 434, 356, 56],\n"," [617, 772, 2, 672, 346, 160, 710, 527, 876, 293],\n"," [621, 759, 182, 522, 363, 62, 288, 618, 384],\n"," [756, 6, 716, 799, 109, 975, 574, 641],\n"," [617, 757, 6, 672, 346, 108, 288, 914, 165, 624, 608],\n"," [488, 1042, 91, 182, 595, 330, 314],\n"," [1046, 4, 109, 100, 356, 90, 527, 748, 439],\n"," [629, 1039, 4, 672, 346, 537, 238, 108, 288, 738, 165, 333],\n"," [514, 991, 182, 504, 109, 506, 394, 677],\n"," [984, 1, 969, 527, 123, 288, 527, 989, 284, 182, 351],\n"," [617, 1019, 1, 969, 672, 346, 165, 1024, 108, 791, 636, 928, 558, 406],\n"," [969, 973, 49, 947, 363, 517, 109, 935, 46],\n"," [973, 48, 1, 969, 100, 527, 748, 439],\n"," [617, 973, 47, 1, 969, 672, 346, 108, 610, 784, 527, 456, 212],\n"," [359, 1036, 527, 702, 363, 42, 975, 142],\n"," [1037, 7, 2, 619, 186, 109, 862, 531, 943],\n"," [629, 1035, 2, 672, 346, 527, 865, 108, 784, 558, 1059, 617, 839],\n"," [621, 410, 182, 803, 288, 165, 1079, 602],\n"," [408, 6, 130, 974, 622, 934, 493],\n"," [617, 409, 6, 672, 346, 160, 228, 108, 784, 165, 338, 617, 889, 420],\n"," [138, 215, 40, 1011],\n"," [140, 526, 389, 784, 1011, 676, 975, 139, 888],\n"," [866, 215, 873, 673, 1008, 524],\n"," [364, 288, 416, 1008, 236],\n"," [132, 192, 621, 503, 1011, 233],\n"," [514, 1011, 816, 497, 726, 1008, 28, 771],\n"," [577, 122, 726, 1008, 461, 394, 1008, 903],\n"," [514, 938, 1029, 411, 951, 559, 469, 726, 1008, 474],\n"," [109, 949, 579, 817, 726, 1008, 680],\n"," [514, 1011, 912, 805, 726, 950, 160, 784, 1011, 113, 419],\n"," [658, 586, 514, 617, 1009, 672, 1011, 349],\n"," [403, 586, 726, 590, 836, 526, 26, 1074, 837],\n"," [514, 912, 350, 881, 579, 765, 1011, 637, 633],\n"," [987, 612, 401, 726, 165, 383],\n"," [514, 1011, 742, 356, 13, 579, 716, 884, 402],\n"," [514, 1011, 898, 975, 399, 524],\n"," [676, 975, 25, 888],\n"," [139, 628, 828, 1011, 129],\n"," [136, 73, 752, 288, 1008, 826],\n"," [139, 167, 726, 1008, 381, 514, 274, 363, 1011],\n"," [949, 579, 1025, 288, 137, 394, 288, 858, 726, 1008, 110],\n"," [526, 389, 784, 950, 873, 675, 129, 726, 1011],\n"," [514, 1011, 22, 579, 716, 884, 455],\n"," [147, 726, 1008, 909, 1011, 558, 113, 129, 607],\n"," [455, 726, 165, 124, 690],\n"," [514, 912, 479, 726, 1011, 283, 393, 975, 124, 858],\n"," [952, 579, 455, 726, 165, 399, 624],\n"," [514, 1011, 776, 579, 230, 363, 163, 589, 307],\n"," [514, 912, 288, 950, 282, 109, 1011, 284, 165, 1066],\n"," [952, 579, 689, 1006, 986, 1011, 394, 1008, 422],\n"," [514, 666, 1008, 328, 394, 1011, 382, 950, 590, 903],\n"," [740, 886, 288, 1011, 394, 288, 1007, 749],\n"," [881, 514, 696, 416, 790, 784, 160, 889, 726, 1011, 29, 421, 534, 586, 871],\n"," [779, 514, 1011, 29, 356, 975, 785, 564],\n"," [629, 484, 672, 1029, 572, 891, 363, 159, 288, 127],\n"," [881, 1011, 113, 527, 587, 788, 514, 833, 317],\n"," [877, 487, 725, 356, 116, 974, 825],\n"," [727, 1011, 572, 323, 716, 288, 352, 917, 160, 915],\n"," [526, 34, 738, 823, 1011, 1029, 1008, 255],\n"," [98, 1011, 527, 461, 288, 572, 957, 163, 498],\n"," [779, 514, 1011, 362, 974, 908, 921, 487, 1011, 711],\n"," [514, 1011, 363, 742, 421, 211, 192, 1011],\n"," [74, 1011, 514, 1011, 529, 674, 363, 734],\n"," [160, 453, 974, 705, 288, 316, 109, 1011],\n"," [514, 1011, 816, 288, 1008, 90],\n"," [514, 1011, 898, 975, 139, 253],\n"," [740, 886, 288, 1011, 394, 1029, 130],\n"," [1029, 968, 130, 526, 389],\n"," [93, 840, 394, 1029, 527, 748],\n"," [514, 1011, 898, 975, 124, 394, 25, 524],\n"," [676, 974, 398, 1026, 367],\n"," [784, 165, 524, 1011, 59, 122, 288, 515],\n"," [526, 389, 784, 1011, 113, 679, 975, 139, 628],\n"," [215, 779, 514, 1011, 29, 94],\n"," [784, 779, 514, 416, 726, 1011],\n"," [779, 514, 1011, 634, 974, 153, 642, 974, 936],\n"," [1010, 1011, 784, 514, 1011, 14],\n"," [899, 1011, 974, 825, 668],\n"," [283, 393, 109, 705, 784, 514, 1011, 824, 879],\n"," [514, 912, 801, 288, 730, 1011, 29],\n"," [514, 1011, 1041, 320, 586, 363, 790, 514, 696, 1078, 977],\n"," [514, 912, 1029, 1008, 318, 726, 951, 290],\n"," [514, 1011, 86, 784, 514, 424, 288, 590, 581, 726, 1011, 868],\n"," [1011, 729, 226, 917, 586, 726, 1011, 85],\n"," [514, 833, 1029, 1008, 318, 726, 951, 103, 788],\n"," [617, 1011, 499, 672, 950, 978, 129, 873, 674],\n"," [514, 1011, 898, 122, 288, 262, 726, 165, 1066],\n"," [459, 232, 363, 1011, 1011, 113, 952, 537, 157, 726, 857],\n"," [182, 358, 784, 1011, 421, 1011, 800, 288, 1008, 630],\n"," [629, 10, 512, 182, 308, 393, 975, 638, 356, 66],\n"," [514, 274, 363, 1011, 254, 917, 165, 999],\n"," [835, 723, 394, 617, 118, 672, 537, 146],\n"," [617, 1011, 337, 672, 950, 436, 655, 921, 77],\n"," [950, 745, 9, 975, 892, 487, 910, 288, 527, 189],\n"," [1011, 421, 330, 968, 136, 958, 254, 35],\n"," [1011, 113, 1064, 760, 455],\n"," [1011, 606, 165, 858, 1011, 113, 964, 331, 726, 1027, 79],\n"," [514, 912, 492, 655, 1008, 925, 394, 1008, 355],\n"," [160, 784, 1011, 421, 393, 815, 254, 35],\n"," [1011, 729, 1078, 432, 288, 1011, 1008, 909, 393, 607],\n"," [740, 886, 288, 1008, 867, 283, 393, 160, 789, 225, 534, 716],\n"," [629, 646, 672, 288, 738, 330, 929, 726, 1011],\n"," [15, 1011, 330, 827, 1011, 363, 113, 129, 127],\n"," [829, 753, 394, 353, 1011, 950, 510, 129],\n"," [835, 878, 394, 475, 527, 885, 109, 154],\n"," [487, 629, 1027, 9, 672, 288, 745, 784, 330, 723, 1029, 939],\n"," [950, 78, 726, 975, 797, 459, 232, 363, 558, 110],\n"," [182, 522, 393, 975, 624, 638, 288, 755],\n"," [534, 909, 393, 975, 788, 288, 693, 394, 288, 958],\n"," [1011, 1077, 975, 900, 356, 500, 726, 166, 789, 1011, 376],\n"," [1008, 461, 394, 1008, 131, 441, 527, 310],\n"," [577, 726, 1008, 680, 394, 1008, 224],\n"," [514, 912, 946, 655, 1008, 474, 394, 1008, 903],\n"," [514, 938, 1029, 1011, 411, 951, 559, 804],\n"," [577, 497, 726, 534, 929, 784, 1011, 612, 113, 16],\n"," [526, 71, 1064, 1008, 28, 771],\n"," [1008, 28, 612, 9, 1074, 356, 974, 466, 874, 365, 577],\n"," [109, 951, 559, 469, 726, 1008, 131],\n"," [1011, 1077, 975, 691, 444, 577, 356, 1078, 555],\n"," [514, 912, 801, 356, 116, 777, 1011, 29],\n"," [160, 453, 974, 705, 288, 962, 109, 1011],\n"," [526, 26, 69, 122, 471, 1029, 1011, 577, 726, 950],\n"," [618, 1032, 637, 1074, 968, 372, 577],\n"," [514, 1011, 898, 950, 534, 909, 784, 1011, 606],\n"," [784, 1008, 110, 889, 818, 288, 137, 394, 288, 767],\n"," [514, 1011, 382, 579, 575, 689, 394, 366],\n"," [905, 479, 394, 1065, 182, 522],\n"," [997, 714, 182, 504, 394, 752, 288, 527, 989],\n"," [784, 165, 624, 111, 1011, 59, 288, 125, 413],\n"," [514, 1011, 898, 950, 534, 573, 726, 1007, 762, 454],\n"," [526, 389, 784, 621, 99, 130, 558, 632, 288, 621, 840],\n"," [629, 484, 672, 1029, 572, 251, 881, 1011, 113, 127, 288, 790, 784, 160, 889],\n"," [526, 389, 784, 621, 728, 962, 374, 1029, 622],\n"," [526, 26, 1074, 801, 288, 1011, 821, 394, 356, 1031, 109, 1011],\n"," [514, 1011, 898, 974, 398, 1012, 752, 129],\n"," [828, 1011, 129, 394, 740, 330, 929, 726, 1011],\n"," [514, 1011, 898, 974, 763, 856, 740, 886, 288, 1011],\n"," [881, 1011, 113, 127, 288, 790, 784, 160, 889, 514, 912, 555],\n"," [835, 363, 250, 394, 324, 586, 288, 1007, 625],\n"," [514, 1011, 382, 951, 590, 1063, 724],\n"," [514, 1011, 898, 975, 578, 524, 819, 288, 137],\n"," [1029, 968, 996, 394, 740, 129, 886, 288, 1011]]"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["import random\n","\n","\n","# Création des target random\n","tokens_random = []\n","target_random = []\n","\n","for u in range(100):\n","    for n in range(len(tokens)):\n","        doc = tokens[n]\n","        random_index = random.randint(1, len(doc)-1)\n","\n","        target_random.append(doc[random_index])\n","        tokens_random.append(doc[:random_index])"],"metadata":{"id":"MV1aLTKZ1fxm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame(tokens_random).fillna(0).astype(int)\n","df['target'] = target_random\n","\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"dPtpKqb_14d1","executionInfo":{"status":"ok","timestamp":1745333119047,"user_tz":-120,"elapsed":114,"user":{"displayName":"Kévin Duranty","userId":"17936416485008719452"}},"outputId":"41288758-c138-4869-a64a-7c8055990cdc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["          0     1    2    3    4     5    6    7  8  9  10  11  12  13  14  \\\n","0       138   215  980  969    0     0    0    0  0  0   0   0   0   0   0   \n","1       577   726  942   28  771   514    0    0  0  0   0   0   0   0   0   \n","2       621    41   93  569   17   296  557    0  0  0   0   0   0   0   0   \n","3       359   276  974  473   93   194  726  558  0  0   0   0   0   0   0   \n","4       534   184  325  917  534   156  363  844  0  0   0   0   0   0   0   \n","...     ...   ...  ...  ...  ...   ...  ...  ... .. ..  ..  ..  ..  ..  ..   \n","36095   881  1011  113  127  288   790  784    0  0  0   0   0   0   0   0   \n","36096   835   363  250  394    0     0    0    0  0  0   0   0   0   0   0   \n","36097   514  1011  382  951  590  1063    0    0  0  0   0   0   0   0   0   \n","36098   514  1011  898  975  578   524    0    0  0  0   0   0   0   0   0   \n","36099  1029   968  996    0    0     0    0    0  0  0   0   0   0   0   0   \n","\n","       target  \n","0          94  \n","1         912  \n","2         447  \n","3          55  \n","4         327  \n","...       ...  \n","36095     160  \n","36096     324  \n","36097     724  \n","36098     819  \n","36099     394  \n","\n","[36100 rows x 16 columns]"],"text/html":["\n","  <div id=\"df-9e32add5-6679-4d17-961a-45e5bf0c87ef\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>138</td>\n","      <td>215</td>\n","      <td>980</td>\n","      <td>969</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>94</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>577</td>\n","      <td>726</td>\n","      <td>942</td>\n","      <td>28</td>\n","      <td>771</td>\n","      <td>514</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>912</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>621</td>\n","      <td>41</td>\n","      <td>93</td>\n","      <td>569</td>\n","      <td>17</td>\n","      <td>296</td>\n","      <td>557</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>447</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>359</td>\n","      <td>276</td>\n","      <td>974</td>\n","      <td>473</td>\n","      <td>93</td>\n","      <td>194</td>\n","      <td>726</td>\n","      <td>558</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>534</td>\n","      <td>184</td>\n","      <td>325</td>\n","      <td>917</td>\n","      <td>534</td>\n","      <td>156</td>\n","      <td>363</td>\n","      <td>844</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>327</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>36095</th>\n","      <td>881</td>\n","      <td>1011</td>\n","      <td>113</td>\n","      <td>127</td>\n","      <td>288</td>\n","      <td>790</td>\n","      <td>784</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>160</td>\n","    </tr>\n","    <tr>\n","      <th>36096</th>\n","      <td>835</td>\n","      <td>363</td>\n","      <td>250</td>\n","      <td>394</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>324</td>\n","    </tr>\n","    <tr>\n","      <th>36097</th>\n","      <td>514</td>\n","      <td>1011</td>\n","      <td>382</td>\n","      <td>951</td>\n","      <td>590</td>\n","      <td>1063</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>724</td>\n","    </tr>\n","    <tr>\n","      <th>36098</th>\n","      <td>514</td>\n","      <td>1011</td>\n","      <td>898</td>\n","      <td>975</td>\n","      <td>578</td>\n","      <td>524</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>819</td>\n","    </tr>\n","    <tr>\n","      <th>36099</th>\n","      <td>1029</td>\n","      <td>968</td>\n","      <td>996</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>394</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>36100 rows × 16 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e32add5-6679-4d17-961a-45e5bf0c87ef')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9e32add5-6679-4d17-961a-45e5bf0c87ef button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9e32add5-6679-4d17-961a-45e5bf0c87ef');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-dcaf9510-eacd-41e1-963a-87d8847c5c20\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dcaf9510-eacd-41e1-963a-87d8847c5c20')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-dcaf9510-eacd-41e1-963a-87d8847c5c20 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_98a7b295-0263-4399-8923-e5fa3eef6933\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_98a7b295-0263-4399-8923-e5fa3eef6933 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 36100,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 233,\n        \"min\": 15,\n        \"max\": 1051,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          244,\n          1049,\n          403\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 391,\n        \"min\": 0,\n        \"max\": 1077,\n        \"num_unique_values\": 238,\n        \"samples\": [\n          199,\n          773,\n          479\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 401,\n        \"min\": 0,\n        \"max\": 1078,\n        \"num_unique_values\": 135,\n        \"samples\": [\n          946,\n          726,\n          672\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 384,\n        \"min\": 0,\n        \"max\": 1074,\n        \"num_unique_values\": 190,\n        \"samples\": [\n          881,\n          827,\n          421\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 333,\n        \"min\": 0,\n        \"max\": 1079,\n        \"num_unique_values\": 186,\n        \"samples\": [\n          955,\n          949,\n          99\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 316,\n        \"min\": 0,\n        \"max\": 1071,\n        \"num_unique_values\": 179,\n        \"samples\": [\n          1012,\n          513,\n          674\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 6,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 271,\n        \"min\": 0,\n        \"max\": 1079,\n        \"num_unique_values\": 160,\n        \"samples\": [\n          510,\n          819,\n          601\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 7,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 208,\n        \"min\": 0,\n        \"max\": 1078,\n        \"num_unique_values\": 130,\n        \"samples\": [\n          703,\n          1000,\n          1029\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 8,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 148,\n        \"min\": 0,\n        \"max\": 1026,\n        \"num_unique_values\": 76,\n        \"samples\": [\n          552,\n          160,\n          965\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 9,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 119,\n        \"min\": 0,\n        \"max\": 1078,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          0,\n          487,\n          834\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 10,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 73,\n        \"min\": 0,\n        \"max\": 1069,\n        \"num_unique_values\": 37,\n        \"samples\": [\n          487,\n          29,\n          715\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 11,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 62,\n        \"min\": 0,\n        \"max\": 1069,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0,\n          581,\n          363\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 12,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 39,\n        \"min\": 0,\n        \"max\": 981,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          302,\n          784,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 13,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24,\n        \"min\": 0,\n        \"max\": 926,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0,\n          926,\n          160\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 14,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 356,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          356,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 319,\n        \"min\": 1,\n        \"max\": 1079,\n        \"num_unique_values\": 1027,\n        \"samples\": [\n          741,\n          776\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","\n","# 🔹 Paramètres\n","max_features =  len(vocabulaire) +1                                   # Taille du vocabulaire\n","maxlen =  15                                                      # Longueur des séquences\n","embedding_dim =    128                                            # Dimension des embeddings\n","\n","# 🔹 Transformation des données (Many-to-Many)\n","X = df.drop(['target'], axis=1)\n","y = df.values[:, 1:]                                            # Décalage des targets (Many-to-Many)\n","y = tf.keras.utils.to_categorical(y, num_classes=max_features)  # Encodage One-Hot\n","\n","# 🔹 Modèle Many-to-Many\n","model = Sequential([\n","    Embedding(input_dim=max_features, output_dim=embedding_dim, input_length=maxlen),\n","    SimpleRNN(64, activation='relu', return_sequences=True),\n","    SimpleRNN(64, activation='relu', return_sequences=True),# Embedding\n","    SimpleRNN(64, activation='relu', return_sequences=True),  # RNN Many-to-Many\n","    Dense(max_features, activation='softmax')  # Prédiction d’une séquence complète\n","])\n","\n","\n","# 🔹 Compilation\n","model.compile(optimizer='adam', metrics=['accuracy', 'recall'], loss='binary_crossentropy')\n","\n","# 🔹 Résumé du modèle\n","model.summary()\n","\n","# 🔹 Entraînement\n","\n","model.fit(X, y, epochs=20, batch_size=64)\n"],"metadata":{"id":"5HCvYw9VeLVb","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"64e6bc78-4adc-4a29-eb5b-fde9a87ee1a9","executionInfo":{"status":"ok","timestamp":1745333600760,"user_tz":-120,"elapsed":397755,"user":{"displayName":"Kévin Duranty","userId":"17936416485008719452"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - accuracy: 0.6350 - loss: 0.1081 - recall: 0.5587\n","Epoch 2/20\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 30ms/step - accuracy: 0.6988 - loss: 0.0022 - recall: 0.6600\n","Epoch 3/20\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - accuracy: 0.6989 - loss: 0.0020 - recall: 0.6492\n","Epoch 4/20\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.7015 - loss: 0.0019 - recall: 0.6489\n","Epoch 5/20\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - accuracy: 0.7050 - loss: 0.0018 - recall: 0.6497\n","Epoch 6/20\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 30ms/step - accuracy: 0.7146 - loss: 0.0018 - recall: 0.6588\n","Epoch 7/20\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - accuracy: 0.7186 - loss: 0.0017 - recall: 0.6639\n","Epoch 8/20\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.7255 - loss: 0.0016 - recall: 0.6673\n","Epoch 9/20\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.7366 - loss: 0.0014 - recall: 0.6763\n","Epoch 10/20\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - accuracy: 0.7563 - loss: 0.0012 - recall: 0.6884\n","Epoch 11/20\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.7801 - loss: 0.0011 - recall: 0.7115\n","Epoch 12/20\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - accuracy: 0.8041 - loss: 9.7505e-04 - recall: 0.7469\n","Epoch 13/20\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - accuracy: 0.8225 - loss: 8.8148e-04 - recall: 0.7742\n","Epoch 14/20\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - accuracy: 0.8347 - loss: 8.0809e-04 - recall: 0.7952\n","Epoch 15/20\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - accuracy: 0.8432 - loss: 7.5634e-04 - recall: 0.8082\n","Epoch 16/20\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.8490 - loss: 7.2375e-04 - recall: 0.8164\n","Epoch 17/20\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.8562 - loss: 6.8609e-04 - recall: 0.8258\n","Epoch 18/20\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 30ms/step - accuracy: 0.8611 - loss: 6.5802e-04 - recall: 0.8319\n","Epoch 19/20\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - accuracy: 0.8652 - loss: 6.3640e-04 - recall: 0.8386\n","Epoch 20/20\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - accuracy: 0.8685 - loss: 6.1902e-04 - recall: 0.8433\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7e9dda6a19d0>"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["model.fit(X, y, epochs=10, batch_size=64)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PwmDBUog6FGw","executionInfo":{"status":"ok","timestamp":1745333959336,"user_tz":-120,"elapsed":195108,"user":{"displayName":"Kévin Duranty","userId":"17936416485008719452"}},"outputId":"40d1ec7a-9c37-4cd6-a8a8-40095e794a2a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 30ms/step - accuracy: 0.8715 - loss: 6.0361e-04 - recall: 0.8482\n","Epoch 2/10\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 29ms/step - accuracy: 0.8756 - loss: 5.8450e-04 - recall: 0.8540\n","Epoch 3/10\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 30ms/step - accuracy: 0.8759 - loss: 5.8318e-04 - recall: 0.8558\n","Epoch 4/10\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - accuracy: 0.8777 - loss: 5.7043e-04 - recall: 0.8585\n","Epoch 5/10\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - accuracy: 0.8792 - loss: 5.5938e-04 - recall: 0.8607\n","Epoch 6/10\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 30ms/step - accuracy: 0.8781 - loss: 5.7023e-04 - recall: 0.8599\n","Epoch 7/10\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - accuracy: 0.8827 - loss: 5.4112e-04 - recall: 0.8654\n","Epoch 8/10\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 29ms/step - accuracy: 0.8833 - loss: 5.3783e-04 - recall: 0.8669\n","Epoch 9/10\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - accuracy: 0.8830 - loss: 5.3552e-04 - recall: 0.8669\n","Epoch 10/10\n","\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - accuracy: 0.8847 - loss: 5.2879e-04 - recall: 0.8687\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7e9d66318390>"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N1EnEJ2_6Brl","executionInfo":{"status":"ok","timestamp":1745332330367,"user_tz":-120,"elapsed":59,"user":{"displayName":"Kévin Duranty","userId":"17936416485008719452"}},"outputId":"182a57b8-da16-4de8-9f84-833bf9b1eaa3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[138, 950, 534, 591,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0]], dtype=int32)"]},"metadata":{},"execution_count":118}]},{"cell_type":"code","source":[],"metadata":{"id":"TUGpXUyv7lRP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iGSOFwlw7kzB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict(promt, max_token=5):\n","    promt.lower()\n","\n","    for n in range(max_token):\n","        token_pred = decoder([int(model.predict(tokenizer(promt), verbose=0)[0][-1].argmax())])[0]\n","        promt += ' ' + token_pred\n","\n","    return promt"],"metadata":{"id":"3iiRX6fh7kvM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict('Bonjour', 4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"tjEHBvfv7krX","executionInfo":{"status":"ok","timestamp":1745333985750,"user_tz":-120,"elapsed":504,"user":{"displayName":"Kévin Duranty","userId":"17936416485008719452"}},"outputId":"f5702101-47b2-4f1b-e6ce-7d669c9a4f01"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Bonjour comment allez vous vous'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":[],"metadata":{"id":"3KBb0lLj7kkA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1t-T79ro7kgW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ApeUmNuE7kct"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cDOWMGpy7kY1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BUw1zp7ueLSj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f752a20e-4990-4d00-fa32-e313fceb7a11","executionInfo":{"status":"ok","timestamp":1745332361726,"user_tz":-120,"elapsed":74,"user":{"displayName":"Kévin Duranty","userId":"17936416485008719452"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["np.int64(94)"]},"metadata":{},"execution_count":122}]},{"cell_type":"code","source":["decoder([int(model.predict(tokenizer('Tu choisiras un livre dans'))[0][-1].argmax())])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eYryyuI-6ma9","executionInfo":{"status":"ok","timestamp":1745332582099,"user_tz":-120,"elapsed":74,"user":{"displayName":"Kévin Duranty","userId":"17936416485008719452"}},"outputId":"2663b52b-9d34-4b5e-8e6f-6c284bd9fb7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["['années']"]},"metadata":{},"execution_count":143}]},{"cell_type":"code","source":["# Predictionzz\n","pred =  ..."],"metadata":{"id":"1nBMLqgpeMM5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dTLdvluTeMKB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"w3egL-MHeMHK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vcYer1PJeMEY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **🎯 Bonus : Création de la Classe `SimpleLLM` pour la Génération de Séquences de Mots**  \n","\n","---\n","\n","## **📌 Objectif du Projet**  \n","L'objectif est de créer une **classe `SimpleLLM`** qui permet :  \n","✅ De **tokenizer un texte** pour le convertir en séquence de nombres.  \n","✅ De **décoder une séquence** de nombres pour retrouver le texte original.  \n","✅ D'utiliser une **couche d'Embedding** pour apprendre des représentations vectorielles des mots.  \n","✅ De **prédire une séquence complète** en générant les tokens **de manière itérative**.  \n","\n","Le modèle doit être capable de **générer du texte mot par mot** en **prenant en compte les prédictions précédentes** pour construire une phrase cohérente.  \n","\n","---\n","\n","## **🛠️ Fonctionnalités de la Classe `SimpleLLM`**  \n","\n","### **1️⃣ `fit_tokenizer(corpus)`**  \n","👉 **Crée un vocabulaire** à partir d’un corpus de texte donné.  \n","👉 Associe **chaque mot à un index unique**.  \n","👉 Ajoute un **token de padding (`<PAD>`)** pour gérer les séquences de longueur variable.  \n","\n","### **2️⃣ `tokenize(sentence)`**  \n","👉 Convertit **une phrase en une liste d’indices** correspondant aux mots dans le vocabulaire.  \n","\n","### **3️⃣ `decode(tokens)`**  \n","👉 Convertit **une liste d’indices en une phrase** en retrouvant les mots du vocabulaire.  \n","\n","### **4️⃣ `embedding(tokens)`**  \n","👉 Transforme une **séquence de tokens en vecteurs denses** via une **couche Embedding**.  \n","\n","### **5️⃣ `predict(seed_text, max_tokens=10)`**  \n","👉 Génère une **séquence complète** en **prédiction itérative** :  \n","   - Utilise **les mots précédemment générés** pour continuer la phrase.  \n","   - Arrête la génération lorsqu’un **token de fin (`<PAD>`)** est atteint.  "],"metadata":{"id":"4Z-LNuXPeMwU"}},{"cell_type":"code","source":["pip install tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"onRF98wxpjuc","outputId":"9f6d22da-8d09-4d5f-c4a7-86c6da075dc9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow\n","  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Collecting astunparse>=1.6.0 (from tensorflow)\n","  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n","Collecting flatbuffers>=24.3.25 (from tensorflow)\n","  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Collecting google-pasta>=0.1.1 (from tensorflow)\n","  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n","Collecting libclang>=13.0.0 (from tensorflow)\n","  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n","Collecting tensorboard~=2.19.0 (from tensorflow)\n","  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n","Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n","Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n","  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n","Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n","  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.3.6)\n","Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n","  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n","Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n","  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n","Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m582.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n","Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n","Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: libclang, flatbuffers, wheel, werkzeug, tensorflow-io-gcs-filesystem, tensorboard-data-server, google-pasta, tensorboard, astunparse, tensorflow\n","Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 google-pasta-0.2.0 libclang-18.1.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 werkzeug-3.1.3 wheel-0.45.1\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","\n","import random\n","import requests\n","\n","import pandas as pd\n","import numpy as np\n","\n","class SimpleLLM:\n","    def __init__(self, path_model=None):\n","        self.pad_sequence = 12\n","        self.path_model = path_model\n","        if path_model:\n","            try:\n","                self.model = load_model(path_model)\n","            except:\n","                self.model = None\n","\n","\n","    def build_model(self, path_train_file=None, url_train_file=None, embedding_dim=128, train=False, epochs=10):\n","        self.embedding_dim = embedding_dim\n","        tokens_random, target_random = [], []\n","\n","\n","        if path_train_file:\n","            self.model = load_model(path_train_file)\n","\n","        elif url_train_file:\n","            corpus = requests.get(url_train_file).text.lower().replace('  ', '')\n","\n","        # Création du corpus d'entrainement\n","        self.docs = [doc.split() for doc in corpus.split('\\n')]\n","\n","        # Création du vocabulaire\n","        self.vocabulaire = ['<end>'] + list(sorted(set([token for token in corpus.replace('\\n', ' ').split()])))\n","        self.vocabulaire = {i: self.vocabulaire[i] for i in range(0, len(self.vocabulaire))}\n","        self.vocab_size = len(self.vocabulaire)\n","\n","\n","        # Création des tokens\n","        self.tokens = [self.tokenizer(doc) for doc in corpus.split('\\n')]\n","        self.tokens_with_out_padding = [[self.get_index(token) for token in doc.split() ]for doc in corpus.split('\\n')]\n","\n","\n","        for n in range(100):\n","            for doc in self.tokens_with_out_padding:\n","                random_int = random.randint(1, len(doc)-1)\n","                tokens_random.append(doc[:random_int])\n","                target_random.append(doc[random_int])\n","\n","\n","        self.X = pd.DataFrame(tokens_random).fillna(0).astype(int).values\n","        self.pad_sequence = self.X.shape[1]\n","        print(\"Pad sequence : \",self.pad_sequence)\n","\n","\n","        # Décalage des targets (Many-to-Many)\n","        self.y = pd.DataFrame(self.X[:, 1:]).fillna(0).astype(int)\n","        self.y['target'] = target_random\n","\n","        self.y = to_categorical(self.y.values, num_classes=self.vocab_size)  # Encodage One-Ho\n","\n","\n","        if self.path_model is not None:\n","            # 🔹 Modèle Many-to-Many\n","            self.model = Sequential([\n","                Embedding(input_dim=self.vocab_size, output_dim=embedding_dim, input_length=self.pad_sequence),  # Embedding\n","                SimpleRNN(64, activation='relu', return_sequences=True),\n","                SimpleRNN(64, activation='relu', return_sequences=True),  # RNN Many-to-Many\n","                Dense(self.vocab_size, activation='softmax')  # Prédiction d’une séquence complète\n","        ])\n","\n","        if train:\n","            self.model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","            self.fit(self.X, self.y, epochs=epochs, batch_size=64)\n","            self.model.save('my_llm.keras')\n","\n","\n","    def fit(self, X, y, epochs=10, batch_size=64):\n","        self.model.fit(X, y, epochs=epochs, batch_size=batch_size)\n","\n","    def get_index(self, text):\n","        return list(self.vocabulaire.values()).index(text.lower())\n","\n","\n","    def tokenizer(self, text:str):\n","        return pad_sequences([[self.get_index(token) for token in text.split()]], self.pad_sequence, padding='post')[0]\n","\n","\n","    def decoder(self, tokens):\n","        return [self.vocabulaire[u] for u in tokens]\n","\n","\n","    def embedding(self, tokens):\n","        sefl.model.layers[0].get_weights()[0][self.get_index(tokens)]\n","\n","    def predict(self, prompt, max_tokens):\n","        for i in range(max_tokens):\n","            pred = int(self.model.predict(np.array([self.tokenizer(prompt)]), verbose=False)[0][-1].argmax())\n","            prompt += ' ' +self.decoder([pred])[0]\n","        print(prompt)"],"metadata":{"id":"9InBVhI4xscI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.predict('Ils regardaient', 8)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NO9xxwS5nMOF","outputId":"862f07fd-a670-4517-cb66-86d1697411e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ils regardaient les étoiles dans le ciel dégagé hier soir\n"]}]},{"cell_type":"code","source":["model.predict('Bonjour', 4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OTnGky6DoOMX","outputId":"cf42fc92-5e1f-4265-c6c1-b493c7b8bc1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Bonjour comment allez vous vous\n"]}]},{"cell_type":"code","source":["model.predict('Tu apprendras', 7)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vc006v_loOJd","outputId":"77368eb4-96f7-49b0-942c-ec1bc482e170"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tu apprendras à conduire dès que tu auras l’âge\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"81h_DwPdsMeN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"TzQRK-oBeDBN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ND7OAcNceC-w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZPvJVN56eC75"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nXbEtOIMxwNe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"y7L6H6w0xwKB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_fEVMKYlw81o"},"source":["# 2. LSTM : Long Short Term Memory\n","\n","## 2.1 Défaillance des RNN\n","\n","Les RNN sont particulièrement adaptés à la prédiction de séquences temporelles, car ils peuvent prendre en compte l'ordre des données. Ils sont donc souvent utilisés pour la prédiction de séries temporelles, comme la prédiction de la demande de produits, la prédiction des prix des actions, la prédiction de la consommation d'énergie, etc.\n","\n","<img src='https://quera.fr/wp-content/uploads/2023/12/RNN_cell.png'>\n","\n","LSTM (Long Short-Term Memory) est une architecture de réseau de neurones récurrents (RNN) qui a été proposée pour résoudre le problème de la disparition du gradient dans les RNN classiques. Contrairement aux RNN classiques, qui ont des problèmes de rétention de l'information à long terme, les LSTM sont conçus pour permettre à l'information de se propager sans entrave.\n","\n","\n","# 2.2 LSTM : Architecture\n","\n","\n","LSTM est une architecture créée en 1997, elle vise à résoudre les limitations des RNN. La formulation du LSTM peut être considérée comme assez complexe, mais en réalité, les LSTM sont simples et assez intuitifs.\n","\n","<img src='https://quera.fr/wp-content/uploads/2023/12/LSTM_cell.png'>\n","\n","LSTM possède également un état caché qui modélise le signal à court terme , mais il introduit également ce que l'on appelle l'état cellulaire qui modélise la dépendance à long terme (ce qui manquait aux RNN !).\n","\n","Il s'appuie sur le concept de portes qui permet de décider de ce qu'il faut garder. LSTM a trois portes :\n","\n","oublier la porte décider de ce qui est important à partir des informations passées stockées dans l'état de la cellule\n","la porte d'entrée décide de ce qui est important à partir de l'entrée du pas de temps actuel\n","la porte de sortie décide de ce qui doit être conservé pour le signal à court terme (état caché)\n","Et voilà ! La combinaison de tous ces éléments permet d’avoir un réseau bien plus puissant que le RNN standard (en pratique plus personne n’utilise de RNN !)\n","\n","Les équations du LSTM peuvent être exprimées comme suit :\n","\n","- Porte d'oubli ($f_t$) :\n","$ f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f) $\n","\n","- Porte d'entrée ($i_t$) :\n","$ i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i) $\n","\n","- Porte de mise à jour ($u_t$) :\n","$ u_t = \\tanh(W_u \\cdot [h_{t-1}, x_t] + b_u) $\n","\n","- État de cellule mis à jour ($c_t$) :\n","$ c_t = f_t \\cdot c_{t-1} + i_t \\cdot u_t $\n","\n","- Porte de sortie ($o_t$) :\n","$ o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o) $\n","\n","- État caché mis à jour ($h_t$) :\n","$ h_t = o_t \\cdot \\tanh(c_t) $\n","\n","Où :\n","- $x_t$ est l'entrée à l'instant $t$,\n","- $h_{t-1}$ est l'état caché à l'instant $t-1$,\n","- $[h_{t-1}, x_t]$ représente la concaténation de l'état caché et de l'entrée,\n","- $W_f, b_f, W_i, b_i, W_u, b_u, W_o, b_o$ sont les poids et biais associés à chaque porte,\n","- $\\sigma$ est la fonction sigmoïde,\n","- $\\tanh$ est la fonction tangente hyperbolique.\n","\n","Ces équations décrivent le fonctionnement des portes et des mises à jour de l'état dans un LSTM, permettant au modèle de gérer efficacement les dépendances à long terme dans les séquences."]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"colab":{"provenance":[{"file_id":"1bjQYZUnpkmTGIC6qQhYqPEahfEusVYqb","timestamp":1746294204031}],"gpuType":"V28"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}